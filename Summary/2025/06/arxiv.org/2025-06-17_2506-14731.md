---
title: 'Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs'
source: https://arxiv.org/html/2506.14731
author:
  - arxiv.org
published: '2025-06-17T00:00:00+00:00'
fetched: '2025-06-18T11:21:04.045381+00:00'
tags:
  - codex
  - arxiv
image: 
---

## è¦ç´„

Ring-liteã¯Mixture-of-Experts(MoE)ã‚’ç”¨ã„ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã§åŠ¹æœçš„ã‹ã¤å®‰å®šçš„ã«è¨“ç·´ã™ã‚‹æ‰‹æ³•ã€‚å…¬é–‹æ¸ˆã¿ã®Ling-liteã‚’åœŸå°ã«ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿16.8Bã§å®Ÿåƒ2.75Bã¨ã„ã†è»½é‡æ§‹æˆãªãŒã‚‰ã€AIMEã‚„LiveCodeBenchãªã©é›£åº¦ã®é«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SOTAãƒ¬ãƒ™ãƒ«ã‚’å®Ÿç¾ã™ã‚‹ã€‚è’¸ç•™ã¨RLã‚’çµ±åˆã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ¡ç”¨ã—ã€å­¦ç¿’ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚**C3PO**æ³•ã‚’å°å…¥ã€‚ã•ã‚‰ã«**ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±**ã«åŸºã¥ããƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠã‚„äºŒæ®µéšå­¦ç¿’ã§å¤šé ˜åŸŸãƒ‡ãƒ¼ã‚¿ã‚’èª¿å’Œã•ã›ã€é«˜åŠ¹ç‡ã§æ±åŒ–æ€§ã®é«˜ã„æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ã‚³ãƒ¼ãƒ‰ã‚‚å…¬é–‹äºˆå®šã§ã€MoEÃ—RLç ”ç©¶ã‚’åŠ é€Ÿã™ã‚‹ã€‚

## æœ¬æ–‡

**G**roup **R**elative **P**olicy **O**ptimization (**GRPO**) algorithm is widely used such as DeepSeek-R1, Qwen3 and so on. For each question-answer pair (q,a)ğ‘ğ‘(q,a)( italic\_q , italic\_a ) in the training dataset ğ’Ÿğ’Ÿ\mathcal{D}caligraphic\_D, we generate
Kğ¾Kitalic\_K responses (i.i.d.) through the policy model Ï€Î¸oldsubscriptğœ‹subscriptğœƒold\pi\_{\theta\_{\text{old}}}italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ start\_POSTSUBSCRIPT old end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT. The reward Risubscriptğ‘…ğ‘–R\_{i}italic\_R start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT of the response yisubscriptğ‘¦ğ‘–y\_{i}italic\_y start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT is determined by the reward model or rule-based verifier.
GRPO estimates the advantage via group-normalized rewards instead of the value model, Ai,t=Riâˆ’meanâ¢({Ri}i=1K)stdâ¢({Ri}i=1K)subscriptğ´

ğ‘–ğ‘¡subscriptğ‘…ğ‘–meansuperscriptsubscriptsubscriptğ‘…ğ‘–ğ‘–1ğ¾stdsuperscriptsubscriptsubscriptğ‘…ğ‘–ğ‘–1ğ¾{A}\_{i,t}=\frac{R\_{i}-\text{mean}(\{R\_{i}\}\_{i=1}^{K})}{\text{std}(\{R\_{i}\}\_{%
i=1}^{K})}italic\_A start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT = divide start\_ARG italic\_R start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT - mean ( { italic\_R start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT } start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_K end\_POSTSUPERSCRIPT ) end\_ARG start\_ARG std ( { italic\_R start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT } start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_K end\_POSTSUPERSCRIPT ) end\_ARG. Specifically, the GRPO loss is formulated as:

|  |  |  |  |  |
| --- | --- | --- | --- | --- |
|  | â„’GRPOâ¢(Î¸)subscriptâ„’GRPOğœƒ\displaystyle\mathcal{L}\_{\text{GRPO}}(\theta)caligraphic\_L start\_POSTSUBSCRIPT GRPO end\_POSTSUBSCRIPT ( italic\_Î¸ ) | =âˆ’ğ”¼(q,a)âˆ¼ğ’Ÿ,{yi}i=1Kâˆ¼Ï€Î¸old(â‹…âˆ£q)\displaystyle=-\mathbb{E}\_{(q,a)\sim\mathcal{D},\{y\_{i}\}\_{i=1}^{K}\sim\pi\_{% \theta\_{\text{old}}}(\cdot\mid q)}= - blackboard\_E start\_POSTSUBSCRIPT ( italic\_q , italic\_a ) âˆ¼ caligraphic\_D , { italic\_y start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT } start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_K end\_POSTSUPERSCRIPT âˆ¼ italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ start\_POSTSUBSCRIPT old end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT ( â‹… âˆ£ italic\_q ) end\_POSTSUBSCRIPT |  | (1) |
|  |  | [1Kâˆ‘i=1K1|yi|âˆ‘t=1|yi|(min(ri,t(Î¸)Ai,t,clip(ri,t(Î¸),1âˆ’Îµ,1+Îµ)Ai,t)âˆ’Î²DKL(Ï€Î¸||Ï€ref))],\displaystyle\Bigg{[}\frac{1}{K}\sum\_{i=1}^{K}\frac{1}{|y\_{i}|}\sum\_{t=1}^{|y\_% {i}|}\Bigg{(}\min\Big{(}r\_{i,t}(\theta){A}\_{i,t},\ \ \text{clip}\Big{(}r\_{i,t}% (\theta),1-\varepsilon,1+\varepsilon\Big{)}{A}\_{i,t}\Big{)}-\beta D\_{\text{KL}% }(\pi\_{\theta}||\pi\_{\text{ref}})\Bigg{)}\Bigg{]},[ divide start\_ARG 1 end\_ARG start\_ARG italic\_K end\_ARG âˆ‘ start\_POSTSUBSCRIPT italic\_i = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT italic\_K end\_POSTSUPERSCRIPT divide start\_ARG 1 end\_ARG start\_ARG | italic\_y start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT | end\_ARG âˆ‘ start\_POSTSUBSCRIPT italic\_t = 1 end\_POSTSUBSCRIPT start\_POSTSUPERSCRIPT | italic\_y start\_POSTSUBSCRIPT italic\_i end\_POSTSUBSCRIPT | end\_POSTSUPERSCRIPT ( roman\_min ( italic\_r start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT ( italic\_Î¸ ) italic\_A start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT , clip ( italic\_r start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT ( italic\_Î¸ ) , 1 - italic\_Îµ , 1 + italic\_Îµ ) italic\_A start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT ) - italic\_Î² italic\_D start\_POSTSUBSCRIPT KL end\_POSTSUBSCRIPT ( italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ end\_POSTSUBSCRIPT | | italic\_Ï€ start\_POSTSUBSCRIPT ref end\_POSTSUBSCRIPT ) ) ] , |  |

where ri,tâ¢(Î¸)=Ï€Î¸â¢(yi,tâˆ£q,yi,<t)Ï€Î¸oldâ¢(yi,tâˆ£q,yi,<t)subscriptğ‘Ÿ

ğ‘–ğ‘¡ğœƒsubscriptğœ‹ğœƒconditionalsubscriptğ‘¦

ğ‘–ğ‘¡

ğ‘subscriptğ‘¦

ğ‘–absentğ‘¡subscriptğœ‹subscriptğœƒoldconditionalsubscriptğ‘¦

ğ‘–ğ‘¡

ğ‘subscriptğ‘¦

ğ‘–absentğ‘¡r\_{i,t}(\theta)=\frac{\pi\_{\theta}(y\_{i,t}\mid q,y\_{i,<t})}{\pi\_{\theta\_{\text%
{old}}}(y\_{i,t}\mid q,y\_{i,<t})}italic\_r start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT ( italic\_Î¸ ) = divide start\_ARG italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ end\_POSTSUBSCRIPT ( italic\_y start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT âˆ£ italic\_q , italic\_y start\_POSTSUBSCRIPT italic\_i , < italic\_t end\_POSTSUBSCRIPT ) end\_ARG start\_ARG italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ start\_POSTSUBSCRIPT old end\_POSTSUBSCRIPT end\_POSTSUBSCRIPT ( italic\_y start\_POSTSUBSCRIPT italic\_i , italic\_t end\_POSTSUBSCRIPT âˆ£ italic\_q , italic\_y start\_POSTSUBSCRIPT italic\_i , < italic\_t end\_POSTSUBSCRIPT ) end\_ARG and Îµğœ€\varepsilonitalic\_Îµ is the clip bound. DKL(Ï€Î¸||Ï€ref)D\_{\text{KL}}(\pi\_{\theta}||\pi\_{\text{ref}})italic\_D start\_POSTSUBSCRIPT KL end\_POSTSUBSCRIPT ( italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ end\_POSTSUBSCRIPT | | italic\_Ï€ start\_POSTSUBSCRIPT ref end\_POSTSUBSCRIPT ) is the token-level KL loss, keeping the policy model Ï€Î¸subscriptğœ‹ğœƒ\pi\_{\theta}italic\_Ï€ start\_POSTSUBSCRIPT italic\_Î¸ end\_POSTSUBSCRIPT not far from the reference policy Ï€râ¢eâ¢fsubscriptğœ‹ğ‘Ÿğ‘’ğ‘“\pi\_{ref}italic\_Ï€ start\_POSTSUBSCRIPT italic\_r italic\_e italic\_f end\_POSTSUBSCRIPT.
