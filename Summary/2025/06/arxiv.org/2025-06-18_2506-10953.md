---
title: 'Build the web for agents, not agents for the web'
source: https://arxiv.org/html/2506.10953
author:
  - arxiv.org
published: ''
fetched: '2025-06-18T11:45:15.800472+00:00'
tags:
  - codex
  - arxiv
image: 
---

## 要約

LLMとマルチモーダルモデルの進化で自律的にウェブを操作するエージェントが注目されているが、現状のブラウザUIやAPIは人間向けに作られており、DOMツリー処理やスクリーンショット解析などで非効率・安全面の課題が残る。そこで著者らはエージェント専用の**Agentic Web Interface(AWI)**を提唱し、安全性・効率・標準化など6原則に基づく設計指針を提示する。AWIはエージェントの能力を最大化し研究者や開発者の連携を促す新たな枠組みとして、広いMLコミュニティの協力を呼びかけている。AWIの普及は安全で透明性の高いウェブエージェント開発を促進し、従来の人間中心UIとのギャップを解消して研究基盤を前進させると結論づける。

## 本文

###### Abstract

Recent advancements in Large Language Models (LLMs) and multimodal counterparts have spurred significant interest in developing web agents—AI systems capable of autonomously navigating and completing tasks within web environments.
While holding tremendous promise for automating complex web interactions, current approaches face substantial challenges due to the fundamental mismatch between human-designed interfaces and LLM capabilities.
Current methods struggle with the inherent complexity of web inputs, whether processing massive DOM trees, relying on screenshots augmented with additional information, or bypassing the user interface entirely through API interactions.
This position paper advocates for a paradigm shift in web agent research: rather than forcing web agents to adapt to interfaces designed for humans, we should develop a new interaction paradigm specifically optimized for agentic capabilities.
To this end, we introduce the concept of an Agentic Web Interface (AWI), an interface specifically designed for agents to navigate a website. We establish six guiding principles for AWI design, emphasizing safety, efficiency, and standardization, to account for the interests of all primary stakeholders.
This reframing aims to overcome fundamental limitations of existing interfaces, paving the way for more efficient, reliable, and transparent web agent design, which will be a collaborative effort involving the broader ML community.

1 Introduction
--------------

Rapid advancements in the capabilities of large language models (LLMs), including multimodal models, have resulted in an increased interest in designing digital agents: artificial intelligence systems that, unlike conventional LLMs, can not only respond to user input, but also execute a range of actions directly, from booking flight tickets to sending emails.
For example, if a user requests to book a flight from Montreal to Boston, an LLM may suggest options and provide approximate durations, whereas a digital agent can actually complete the booking on the user’s behalf, and have the booking details sent to the user’s inbox.
To this end, recent works have focused on the problem of designing agents for different type of interfaces, including web APIs (Schick et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib51); Qin et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib47)), mobile UIs (Rawles et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib49), [2024](https://arxiv.org/html/2506.10953v1#bib.bib50)), desktop UIs (Xie et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib63); Qin et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib48)), and web browsers (Liu et al., [2018](https://arxiv.org/html/2506.10953v1#bib.bib32); Nakano et al., [2022](https://arxiv.org/html/2506.10953v1#bib.bib40); Gur et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib17); He et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib19)).
The focus of this position paper is on one specific type of digital agents that specializes on navigating websites through mediums like the web browser; we refer to them to as web agents.

Acquiring this autonomy unlocks crucial capabilities in web agents that basic chat assistants lack, enabling users to complete web-related tasks that would otherwise not be possible with standard LLM assistants.
One clear advantage is their ability to execute user-defined tasks independently, whether these involve making online purchases or sending messages.
On top of these novel capabilities, web agents also offer more response-adaptability to user inputs than standard LLM-based assistants, due to their ability to interact with online environments.
For example, web agents can address user queries by directly accessing and interacting with websites, making them more suitable for situations where some desired knowledge is not present in text format, is frequently updated, or requires explicit online interaction (such as asking online vendors for price estimates).

Current approaches to building web agents range from zero-shot prompting of LLMs through visual grounding (Zheng et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib69)) to finetuning-based approaches that leverage planning (Gur et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib17); Sodhi et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib56)), multimodality (Shaw et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib52); Furuta et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib12)), and reinforcement learning (Liu et al., [2018](https://arxiv.org/html/2506.10953v1#bib.bib32); Qi et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib46)).
Across all approaches, however, browser states are presented to the agent (i) as screenshots of the browser; (ii) via the underlying web page, as a tree structure refined from the HTML elements present on the page; or (iii) through a combination of the two.
These means of presenting information to the web agent, however, face fundamental drawbacks.
Screenshots do not directly provide agents with all comprehensive webpage information that may be required (for instance, elements in a collapsed dropdown menu will not be visible), while providing web agents full DOM trees is often inefficient and computationally expensive, as these can include details that are irrelevant to the user, and used only to render the webpage.
Similarly, web APIs—which may not face these representational issues—encounter limitations in other areas, due to their developer-oriented design.
Additionally, in both cases, safety concerns arise, given that web agents may have access to sensitive personal information required to execute actions (e.g., payment and login information).

While the approaches discussed above are valid approaches for building web agents, their limitations point to a deeper way in which these approaches are ultimately misguided: they involve trying to build web agents that interact with the web the same way that humans do.
More specifically, the tools that agents are trained to interact with—e.g., the web browser, or web APIs—are designed for human users and developers, and not for agentic AI systems.
In this position paper, we argue that agents should not be forced to interact with the web in the same way as human users.
**Beyond designing web agents for human web interfaces, we argue that the research community should be deeply involved in the design of web interfaces for web agents.**

To this end, we present the concept of the **Agentic Web Interface** (**AWI**): a new type of interface specifically designed to be used by web agents. This mirrors how user interfaces are designed to be used by humans, who do not have the same requirements as web agents. Given the nature of this work, we explicitly do not provide a prototype or specific implementation details, as we believe designing AWIs will be a collective and iterative effort involving a broad range of stakeholders.

We structure this paper as follows: in [Section 2](https://arxiv.org/html/2506.10953v1#S2 "2 How are web agents currently designed? ‣ Build the web for agents, not agents for the web"), we describe current approaches to designing web agents and highlight limitations and safety concerns.
We then introduce AWIs in [Section 3](https://arxiv.org/html/2506.10953v1#S3 "3 Rethinking how agents interact with the web ‣ Build the web for agents, not agents for the web"), discuss how they can be designed to solve the current issues faced by web agents, and offer guiding principles that should inform their design.
Next, in [Section 4](https://arxiv.org/html/2506.10953v1#S4 "4 Why must the broader ML community be involved? ‣ Build the web for agents, not agents for the web"), we argue that this effort is relevant to and requires contributions from the broader ML community. Finally, we discuss how AWIs differ from the model context protocol (MCP) in [Section 5](https://arxiv.org/html/2506.10953v1#S5 "5 Is an AWI another communication protocol for LLM agents? ‣ Build the web for agents, not agents for the web") and summarize our position in [Section 6](https://arxiv.org/html/2506.10953v1#S6 "6 Conclusion ‣ Build the web for agents, not agents for the web").

2 How are web agents currently designed?
----------------------------------------

Web agents are designed to perform goal-directed tasks through programmatic interaction with web interfaces. To enable this, recent implementations utilize LLMs as a core component of these agents (Gur et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib17); Zheng et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib69); Drouin et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib11); Boisvert et al., [2025b](https://arxiv.org/html/2506.10953v1#bib.bib6)); however, they are only a part of a bigger system, which interacts with websites through a browser.
Following Zhou et al. ([2024](https://arxiv.org/html/2506.10953v1#bib.bib71)), we define web agents within a sequential decision-making framework where, given a task described as a natural language intent i𝑖iitalic\_i, e.g., find all white shoes in size 10 and add them to my wishlist, the agent issues an action at∈𝒜subscript𝑎𝑡𝒜a\_{t}\in\mathcal{A}italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ∈ caligraphic\_A at time step t𝑡titalic\_t according to a policy π⁢(at|i,ot,a1,o1)𝜋conditionalsubscript𝑎𝑡

𝑖subscript𝑜𝑡subscript𝑎1subscript𝑜1\pi(a\_{t}|i,o\_{t},a\_{1},o\_{1})italic\_π ( italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT | italic\_i , italic\_o start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT , italic\_a start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , italic\_o start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT ).
This policy conditions on the intent i𝑖iitalic\_i, the current observation ot∈𝒪subscript𝑜𝑡𝒪o\_{t}\in\mathcal{O}italic\_o start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT ∈ caligraphic\_O, the action history a1subscript𝑎1a\_{1}italic\_a start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT, and the observation history o1subscript𝑜1o\_{1}italic\_o start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT.
The execution of action atsubscript𝑎𝑡a\_{t}italic\_a start\_POSTSUBSCRIPT italic\_t end\_POSTSUBSCRIPT in the environment results in a state transition to st+1∈𝒮subscript𝑠𝑡1𝒮s\_{t+1}\in\mathcal{S}italic\_s start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ∈ caligraphic\_S with a corresponding observation ot+1∈𝒪subscript𝑜𝑡1𝒪o\_{t+1}\in\mathcal{O}italic\_o start\_POSTSUBSCRIPT italic\_t + 1 end\_POSTSUBSCRIPT ∈ caligraphic\_O.
The action space 𝒜𝒜\mathcal{A}caligraphic\_A of web agents includes operations analogous to human web interactions: element selection (clicking), text input, URL navigation, and browser tab management.
These actions are executed via programmatic automation frameworks such as Playwright, which return updated browser states after each agent intervention.
The effectiveness of task completion can then be evaluated through a reward function r⁢(a1,s1)𝑟subscript𝑎1subscript𝑠1r(a\_{1},s\_{1})italic\_r ( italic\_a start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT , italic\_s start\_POSTSUBSCRIPT 1 end\_POSTSUBSCRIPT ) that assesses whether the final state satisfies the intent criteria. The reward function be an automatic evaluator that programmatically determine success of a final state based on a human-defined rules (Zhou et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib71); Koh et al., [2024a](https://arxiv.org/html/2506.10953v1#bib.bib24); Drouin et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib11)), or a specialized reward model that can determine the success of a trajectory without having access to the underlying environment or rules (Murty et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib38); Lù et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib37); Xue et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib64)).

In this section, we provide an overview of web agents by examining two approaches: agents that solely rely on web browser UIs, (§[2.1](https://arxiv.org/html/2506.10953v1#S2.SS1 "2.1 Browser-based agents ‣ 2 How are web agents currently designed? ‣ Build the web for agents, not agents for the web")), and agents that additionally incorporate web APIs (§[2.2](https://arxiv.org/html/2506.10953v1#S2.SS2 "2.2 API-based hybrid agents ‣ 2 How are web agents currently designed? ‣ Build the web for agents, not agents for the web")).
We briefly cover each category and highlight the limitations they each face as a result of having to interact with interfaces designed for humans.

### 2.1 Browser-based agents

Web agents that rely on the browser’s UI may leverage visual representations from the screen (Shi et al., [2017](https://arxiv.org/html/2506.10953v1#bib.bib53); Shaw et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib52)), the Document Object Model (DOM) tree (Deng et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib10)), the accessibility tree (Zhou et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib71)), or a combination of them (e.g., Furuta et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib12); Lù et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib36); Boisvert et al., [2025b](https://arxiv.org/html/2506.10953v1#bib.bib6); Gou et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib15)).
In addition to the raw visual and textual inputs, additional annotations like bounding boxes are sometimes added onto the screenshots (e.g., Yang et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib66); Koh et al., [2024a](https://arxiv.org/html/2506.10953v1#bib.bib24); Chezelles et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib9)).
This multimodal representation allows a holistic representation of the webpage, with the DOM showing the structure of the webpage and screenshots showing images that are not displayed inside the DOM. This paradigm enables the development of agents capable of predicting and executing browser actions, such as element selection, text input, URL navigation, and tab management operations.

#### Representational limitations

Browser-based web agents face limitations imposed by both DOM-based and screenshot-based representations.
Screenshots provide token-efficient representations of browser state, but lack comprehensive DOM information that may be visually occluded —i.e., not rendered or hidden inside a dropdown.
On the other hand, DOM-based representations, despite usually containing the most decision-relevant information, are extremely inefficient due to excessive structural tokens and supplementary attributes (such as server-side identifiers).
This inefficiency in turn leads to higher computational and operational costs when using LLMs; for instance, with DOM trees potentially exceeding 1M tokens (Chezelles et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib9)), deploying a GPT-4.1-based agent for a single 20-step task could cost roughly $40.
While previous research has attempted various mitigation strategies (e.g., Deng et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib10); Tiwary et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib58); Lù et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib36)), these solutions typically do not generalize well across websites and novel task scenarios.

#### Resource challenges and defensive designs

Beyond representational limitations, the proliferation of browser-based agents introduces additional resource challenges.
Serving web pages can often be resource-intensive, and repeated rendering by browser automation tools (e.g., for web crawling) can lead to a strain on web infrastructure, leading to performance degradation for end users.
As web agents begin to constitute a larger and larger proportion of web traffic, we can expect this resource consumption issue to increase in severity.
In response to such challenges, website operators implement defense mechanisms like CAPTCHA; but as agent capabilities have become increasingly sophisticated, CAPTCHA systems have similarly become increasingly complex, creating accessibility barriers for legitimate human users. Although exclusion protocols like robots.txt could be enforced by regulatory bodies for major providers, they will penalize agents used as an assistive technology indistinguishably from agents built for web crawling.
More generally, challenges arise in distinguishing between malicious automation and beneficial human-in-the-loop applications, leading to difficulties in web resource management.

#### Safety and privacy concerns

Since they are integrated within the browser, browser-based web agents introduce major safety and privacy concerns.
If the web agent has access to the user’s personal accounts, as well as other sensitive information stored in the browser—such as passwords and credit card information—agents that lack adequate safeguards may cause severe harm to users through their actions.
A web agent may, for example, use the user’s personal information to send harmful messages or make unauthorized online purchases (Tur et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib60); Boisvert et al., [2025a](https://arxiv.org/html/2506.10953v1#bib.bib5)).

### 2.2 API-based hybrid agents

Agents that use tools like web APIs offer high potential benefits to users, particularly when considering tools like Deep Research (OpenAI, [2025](https://arxiv.org/html/2506.10953v1#bib.bib42)), that can themselves inform agent behavior.
Song et al. ([2025](https://arxiv.org/html/2506.10953v1#bib.bib57)) defines a hybrid agent that extends the browser-based agent by giving it access to the underlying web API of the websites.
Their agent alternates between API calls and browser interactions to complete a web navigation task from the WebArena benchmark (Zhou et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib71)).
While the incorporation of web APIs by hybrid agents opens new possibilities, it also raises questions about fundamental limitations of web APIs in agentic contexts.
Most crucially, it begs the question: can web agents solely rely on the internal web API offered by websites?
We argue that besides the previously discussed limitations that solely browser-based agents face, this approach will face limitations and safety concerns specific to web APIs used to power websites.

#### Limitations of web APIs

API-based agents are limited by the range of actions offered by the web APIs, which are far narrower than the range of actions offered by webpage UIs.
Similarly, web APIs are typically not designed to directly manipulate stateful objects, such as sorting a list of products on a online shopping website. This limits the potential actions that an API-based agent could utilize. One could add state-centric actions, but such an endeavour would require substantial refactoring effort from the developers, which would solely benefit API-calling agents.
Additionally, web APIs tend to be heavily controlled by the developers, and frequent usage of the APIs in a short period can lead to request denials.
These factors hold back the effectiveness of incorporating web APIs into web agents, as they have to fall back to using the UI when an action cannot be completed using the web API, which face the limitations discussed in [Section 2.1](https://arxiv.org/html/2506.10953v1#S2.SS1 "2.1 Browser-based agents ‣ 2 How are web agents currently designed? ‣ Build the web for agents, not agents for the web").

#### Safety concerns

Internal web APIs are designed to strictly communicate with browsers, as opposed to external APIs that are designed as a service. If used directly, internal APIs may pose security risks, as agents may lack essential safeguards to avoid unintended side effects (Levy et al., [2024](https://arxiv.org/html/2506.10953v1#bib.bib28); Boisvert et al., [2025a](https://arxiv.org/html/2506.10953v1#bib.bib5)) and are prone to follow malicious and harmful instructions (Andriushchenko et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib1); Tur et al., [2025](https://arxiv.org/html/2506.10953v1#bib.bib60)). More concretely, guardrails like password prompts and two-factor authentication can be bypassed if the agent directly communicates with the web API through an elevated API key. This could lead to high API usage if uncontrolled, which could results in unexpectedly high expenses.

5 Is an AWI another communication protocol for LLM agents?
----------------------------------------------------------

Tool use for LLMs is a well researched topic (Qin et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib47); Schick et al., [2023](https://arxiv.org/html/2506.10953v1#bib.bib51)), which paved the way for providers to integrate tool use into popular LLM assistants, such as Search for ChatGPT (OpenAI, [2024](https://arxiv.org/html/2506.10953v1#bib.bib41)) and Function Calling for Gemini (Google, [2025](https://arxiv.org/html/2506.10953v1#bib.bib14)).
As adoption grows, a need to standardize interactions between LLM agents (i.e., hosts) and tools (i.e., servers), led to the introduction of the Model Context Protocol (MCP) (Anthropic, [2024](https://arxiv.org/html/2506.10953v1#bib.bib3)).
The protocol aims to standardize how LLM assistants, such as Claude (Anthropic, [2023](https://arxiv.org/html/2506.10953v1#bib.bib2)), communicate with externally-hosted systems like PostgresSQL databases, Slack workspaces, and GitHub accounts.
The protocol enables LLM assistants to use a client to access MCP servers, where they can send a query using the JSON-RPC 2.0 (JSON-RPC, [2013](https://arxiv.org/html/2506.10953v1#bib.bib21)) format, and receive a response in the same format.
By standardizing how information is sent and received, the protocol enables MCP servers to be effortlessly compatible with any MCP-compatible LLM agent, avoiding the need for wrappers around API endpoints provided by web services.
However, although MCP serves as a major catalyst for developing tool use agents, it fundamentally differs from AWIs, which are interfaces—not a protocol—designed for web agents that navigates stateful representation of websites.
Below, we highlight two key differences between MCP and AWIs, which further motivate the need for the latter.

#### State tracking

Since MCP uses JSON-RPC 2.0—a stateless protocol—it will not directly support client-side state tracking, thus limiting state-dependent actions.
For instance, if an agent is tasked to purchase white shoes, it may first request the list of all shoes fitting a certain size, which it can easily receive from an AWI or from a MCP server; this becomes its latest state.
Given this state, an AWI-based agent can request the list to be sorted by price.
On the other hand, an MCP client would have to reformulate a query that requests the same list again, this time sorted by price.
This overhead would lead to substantially higher bandwidth cost (since the entire list needs to be sent again) and slowing down the task completion.
Unlike MCP servers, AWIs are designed to universally track states, enabling more efficient ways of executing actions that depends on the state of a website.

#### Standardized interface vs protocol

Although the communication protocol is standardized, the actual implementation may differ based on the server.
For instance, an implementation for GitHub may have a function get\_file\_contents that takes as inputs owner and repo and return the content of a file; the same function for GitLab may instead require project\_id as input.
This difference stems from the flexibility of the protocol, which allows MCP servers to specify their own methods and parameters.
On the other hand, AWIs will be standardized across implementations, similar to how a FileReader object in JavaScript will behave the same across different browsers.

Overall, Agentic Web Interfaces enable agents to navigate websites, whereas MCP provides a unified approach for LLM assistants to communicate with a wide range of web services.
That being said, AWIs and MCPs need not be mutually exclusive; AWIs can be designed to communicate with a web service through MCP, whereas an MCP server could access websites through AWIs and a server-side agent, enabling MCP-compatible LLM assistants to navigate websites autonomously.
Ultimately, we believe that MCP and AWIs will both be crucial for developing more capable tool use and web agents, though, once again, the two are fundamentally different.

6 Conclusion
------------

Web agents represent one of the most exciting current areas in AI research, with a high potential for impact on the daily lives of everyday users.
As we have argued, however, research in the field is currently being held back by limitations imposed by interfaces that are built for human users, and not web agents.
These limitations not only act as a bottleneck for research on web agents, but also obscure their potential capabilities, introduce safety risks, and will lead to major resource challenges.
Consequently, we argue that it is imperative that the broader research community helps design agentic web interfaces (AWIs): interfaces designed specifically to be used by web agents.
In this position paper, we highlighted the need for AWIs (§[2](https://arxiv.org/html/2506.10953v1#S2 "2 How are web agents currently designed? ‣ Build the web for agents, not agents for the web"),§[3.1](https://arxiv.org/html/2506.10953v1#S3.SS1 "3.1 Addressing issues faced by agents through AWIs ‣ 3 Rethinking how agents interact with the web ‣ Build the web for agents, not agents for the web")), and offered both high-level principles (§[3.2](https://arxiv.org/html/2506.10953v1#S3.SS2 "3.2 Guiding principles for designing AWIs ‣ 3 Rethinking how agents interact with the web ‣ Build the web for agents, not agents for the web")) and concrete design suggestions (§[3.3](https://arxiv.org/html/2506.10953v1#S3.SS3 "3.3 Concrete suggestions for AWIs ‣ 3 Rethinking how agents interact with the web ‣ Build the web for agents, not agents for the web")) that we believe should be held in mind when building them.
We underscored the relevance of AWIs to the wider ML community, stressing that designing better interfaces for web agents is not a concern only for web developers and web agent researchers (§[4](https://arxiv.org/html/2506.10953v1#S4 "4 Why must the broader ML community be involved? ‣ Build the web for agents, not agents for the web")), but the research community at large. Finally, we highlight the difference between a protocol like MCP and web interfaces dedicated for agents (§[5](https://arxiv.org/html/2506.10953v1#S5 "5 Is an AWI another communication protocol for LLM agents? ‣ Build the web for agents, not agents for the web")).

Given the technical challenges discussed in [Section 4](https://arxiv.org/html/2506.10953v1#S4 "4 Why must the broader ML community be involved? ‣ Build the web for agents, not agents for the web"), the development of web standards requires ML expertise from the outset.
In our view, the machine learning community should be actively involved in the design of AWIs from their inception—ensuring that elements to facilitate testing, debugging, and safety are incorporated into the standard.
Treating these capabilities as first-class considerations, rather than retrofitting them onto systems designed primarily for human interaction, should be one of the main priorities in the design of agentic web interface standards.
Web agents hold the potential for major societal impact; it is important that we design interfaces that reflect this importance.
