---
title: ''
source: https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf
author:
  - arxiv.org
published: ''
fetched: '2025-06-18T11:46:24.179983+00:00'
tags:
  - codex
  - arxiv
image: 
---

## 要約

本レポートはGemini 2.Xモデルの最新成果をまとめたもの。主力の**Gemini 2.5 Pro**は長文・マルチモーダル入力を処理し高度な推論とコード生成を実現し、3時間の動画も扱える。軽量な**Gemini 2.5 Flash**や2.0系モデルはコストと応答速度に優れ、用途に応じて選択可能。これら全モデルは**Thinking**手法による推論ステップ制御やネイティブのツール利用が統合され、エージェントワークフローを拡張。安全性評価でも前世代を上回り、幅広い領域で実用的な性能を示した。アーキテクチャはスパースMoEを採用しTPU v5pでの大規模訓練とデータ拡充によって安定性が向上し、LMArena等の指標も大幅に更新した。

## 本文

2025-06-17 Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Gemini Team, Google In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as wellas our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incrediblecoding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understandingand it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users toexplore the boundaries of what is possible with complex agentic problem solving.
1. Introduction We present our latest family of natively multimodal models with advanced reasoning through thinking, long context and tool-use capabilities: Gemini 2.5 Pro and 2.5 Flash and our earlier Gemini 2.0 Flash and Gemini 2.0 Flash-Lite models. Together these form a new family of highly-capable modelsrepresenting our next generation of AI models, designed to power a new era of agentic systems.
BuildinguponthefoundationoftheGemini1.5series(GeminiTeam,2024),thisGemini2.Xgenerationbrings us closer to the vision of a universal AI assistant (Hassabis, 2025).
The Gemini 2.X series are all built to be natively multimodal, supporting long context inputs of >1million tokens and have native tool use support. This allows them to comprehend vast datasets andhandle complex problems from different information sources, including text, audio, images, videoand even entire code repositories. These extensive capabilities can also be combined to build complexagentic systems, as happened in the case of Gemini Plays Pokémon1(Zhang, 2025). Different modelsin the series have different strengths and capabilities: (1) Gemini 2.5 Pro is our most intelligentthinking model, exhibiting strong reasoning and code capabilities. It excels at producing interactiveweb applications, is capable of codebase-level understanding and also exhibits emergent multimodalcoding abilities. (2) Gemini 2.5 Flash is our hybrid reasoning model with a controllable thinkingbudget, and is useful for most complex tasks while also controlling the tradeoff between quality, cost, and latency. (3) Gemini 2.0 Flash is our fast and cost-efficient non-thinking model for everyday tasksand (4) Gemini 2.0 Flash-Lite is our fastest and most cost-efficient model, built for at-scale usage. Afull comparison of the models in the Gemini 2.X model family is provided in Table 1. Taken together, the Gemini 2.X family of models cover the whole Pareto frontier of model capability vs cost, shiftingit forward across a large variety of core capabilities, applications and use-cases see Figure 1.
The Gemini 2.5 family of models maintain robust Safety metrics while improving dramatically on 1Pokémon is a trademark of Nintendo Co., Ltd., Creatures Inc., and Game Freak Inc.
Please send correspondence to gemini-report@google.com.
©2025 Google. All rights reserved Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
FlashGemini 1.5 ProGemini 1.5 Flash-LiteGemini 2.0 FlashGemini 2.0 FlashGemini 2.5 ProGemini 2.5 Input modalitiesVideo, AudioText, Image, Video, AudioText, Image, Video, AudioText, Image, Video, AudioText, Image, Video, AudioText, Image, Video, AudioText, Image, Input length 1M 2M 1M 1M 1M 1M Output modalities Text Text Text Text, Image* Text, Audio* Text, Audio Output length 8K 8K 8K 8K 64K 64K Thinking No No No Yes Dynamic Dynamic Supports tool use? No No No Yes Yes Yes Knowledge cutoff November 2023November 2023June 2024 June 2024 January 2025January 2025 Table 1|Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refersto the ability of the model to recognize and execute function calls (e.g., to perform web search, complete a math problem, execute code). *currently limited to Experimental or Preview, see Section 2.7.
Information accurate as of publication date.
helpfulness and general tone compared to their 2.0 and 1.5 counterparts. In practice, this means thatthe 2.5 models are substantially better at providing safe responses without interfering with importantuse cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including CBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showeda significant increase in some capabilities compared to previous Gemini models, it did not reach anyof the Critical Capability Levels in any area.
Our report is structured as follows: we begin by briefly describing advances we have made inmodel architecture, training and serving since the release of the Gemini 1.5 model. We then showcasethe performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. Weconclude by discussing the safety evaluations and implications of this model series.
2. Model Architecture, Training and Dataset 2.1. Model Architecture The Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs. Sparse MoE models activate a subset of model parameters per input tokenby learning to dynamically route tokens to a subset of parameters (experts); this allows them todecouple total model capacity from computation and serving cost per token. Developments to themodel architecture contribute to the significantly improved performance of Gemini 2.5 compared to Gemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse MoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al., 2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsmanet al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerableprogress in enhancing large-scale training stability, signal propagation and optimization dynamics, resulting in a considerable boost in performance straight out of pre-training compared to previous Gemini models.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Figure 1|Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, andhas an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted averageof input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.
Gemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, andincorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini 1.5 Pro in processing long context input sequences of up to 1M tokens (see Table 3). Both Gemini 2.5 Pro and Gemini 2.5 Flash can process pieces of long-form text (such as the entirety of “Moby Dick” or “Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Togetherwith advancements in long-context abilities, architectural changes to Gemini 2.5 vision processinglead to a considerable improvement in image and video understanding capabilities, including beingable to process 3 hour long videos and the ability to convert demonstrative videos into interactivecoding applications (see our recent blog post, (Baddepudi et al., 2025)).
The smaller models in the Gemini 2.5 series — Flash size and below — use distillation (Anil et al., 2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reducethe cost associated with storing the teacher’s next token prediction distribution, we approximate itusing a k-sparse distribution over the vocabulary. While this still increases training data throughputand storage demands by a factor of k, we find this to be a worthwhile trade-off given the significantquality improvement distillation has on our smaller models, leading to high-quality models with areduced serving cost (see Figure 2).
2.2. Dataset Our pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of domains and modalities, which includes publicly available web-documents, code (various programminglanguages), images, audio (including speech and other audio types) and video, with a cutoff dateas June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
0 50 100 150 200 250 300 350 Output T okens per SecondGemini 2.5 Flash Gemini 2.0 Flash Gemini 2.0 Flash-Liteo4-mini (high) o3 Gemini 2.5 Pro Grok 3 Claude 4 Opus (Extended Thinking) Claude 4 Sonnet (Extended Thinking) DeepSeek R1 0528 (May '25)Company Google OpenAI Anthropic DeepSeekxAI Figure 2|Number of output tokens per second while generating (i.e. after the first chunk has beenreceived from the API), for different models. Source: ArtificialAnalysis.ai , imported on 2025-06-15we also utilized new methods for improved data quality for both filtering, and deduplication. Ourpost-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collectedand vetted, is a collection of multimodal data with paired instructions and responses in addition tohuman preference and tool-use data.
2.3. Training Infrastructure This model family is the first to be trained on TPUv5p architecture. We employed synchronousdata-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators, distributed across multiple datacenters.
The main advances in software pre-training infrastructure compared with Gemini 1.5 were relatedto elasticity and mitigation of SDC (Silent Data Corruption) errors:
1.Slice-Granularity Elasticity : Our system now automatically continues training with fewer “slices” of TPU chips when there is a localized failure, and this reconfiguration results in tensof seconds of lost training time per interruption, compared with the 10 or more minute delaywaiting for healthy machines to be rescheduled without elasticity; the system continues trainingat around 97% throughput while the failed slice is recovering. At the scale of this training runwe see interruptions from hardware failures multiple times per hour, but our fault tolerancemachinery is designed to tolerate the higher failure rates expected at much larger scales.
2.Split-Phase SDC Detection : On previous large-scale runs it could take many hours to detectand localize machines with SDC errors, requiring both downtime while debugging, and rollback/replay of a large number of potentially corrupt training steps. We now use lightweightdeterministic replay to immediately repeat any step with suspicious metrics, and compareper-device intermediate checksums to localize the root cause of any data corruption. Empirically, accelerators that start to exhibit intermittent SDCs are identified within a few minutes, andquickly excluded from the job. During this run, around 0.25% of steps were replayed due tosuspected SDCs and 6% of these replays turned out to be genuine hardware corruption.
Both of the above techniques were relatively simple to implement due to the single controllerdesign of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinatedfrom a single python program with a global view of the system state. The controller can make use of Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
020406080100Accuracy / Pass rate (%)AIME 2.0 Flash (No Thinking) 2.0 Flash (Thinking) 2.5 Flash (Dynamic Thinking) 2.5 Pro (Dynamic Thinking)GPQA (Diamond) LiveCodeBench v5 Figure 3|Impact of “Thinking” on Gemini models performance.
parallel ’remote python’ operations on TPU workers to monitor training metrics, track performancestragglers, and root-cause SDC errors.
Overall during the run, 93.4% of the time was spent performing TPU computations; the remainder was approximately spent half in elastic reconfigurations, and half in rare tail cases whereelasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugginginterventions.
2.4. Post-training Since the initial announcement of Gemini 1.5, significant advancements have been made in ourpost-training methodologies, driven by a consistent focus on data quality across the Supervised Fine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focushas been leveraging the model itself to assist in these processes, enabling more efficient and nuancedquality control.
Furthermore, we have increased the training compute allocated to RL, allowing deeper explorationand refinement of model behaviors. This has been coupled with a focus on verifiable rewardsand model-based generative rewards to provide more sophisticated and scalable feedback signals.
Algorithmic changes to the RL process have also improved stability during longer training. Theseadvancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments, including those requiring multi-step actions and tool use. The combination of these improvements indataquality,increasedcompute,algorithmicenhancements,andexpandedcapabilitieshascontributedto across-the-board performance gains (as described in Section 3) , notably reflected in the significantincrease in the model’s LMArena ELO scores, with both Gemini 2.5 Flash and Pro gaining more than 120 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash, see Figure 1), along with significant improvements on several other frontier benchmarks.
2.5. Thinking Past Gemini models produce an answer immediately following a user query. This constrains theamount of inference-time compute (Thinking) that our models can spend reasoning over a problem.
Gemini Thinking models are trained with Reinforcement Learning to use additional compute atinference time to arrive at more accurate answers. The resulting models are able to spend tens ofthousands of forward passes during a “thinking” stage, before responding to a question or query.
Our training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Model AI Studio model ID Gemini 1.5 Flash gemini-1.5-flash Gemini 1.5 Pro gemini-1.5-pro Gemini 2.0 Flash-Lite gemini-2.0-flash-lite Gemini 2.0 Flash gemini-2.0-flash Gemini 2.5 Flash gemini-2.5-flash Gemini 2.5 Pro gemini-2.5-pro Table 2|Mapping of Gemini model names to AI Studio API model IDs.
Thinking (launched in December 2024), which excelled in mathematics and coding, to the Gemini 2.5 Thinking series, which incorporates Thinking natively across all domains. The result is a singlemodel that can achieve stronger reasoning performance across the board, and is able to scale up itsperformance further as a function of inference time (see Figure 3 for an example of the impact of Thinking).
WeintegratedThinkingwithotherGeminicapabilities,includingnativemultimodalinputs(images, text, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decidesfor itself how long to think before providing an answer. We also provide the ability to set a Thinkingbudget, constraining the model to respond within a desired number of tokens. This allows users totrade off performance with cost.
The Gemini 2.5 Thinking models are our most well-rounded reasoning models to date.
2.6. Capability-specific improvements While most of the changes made to our training architecture and recipe since Gemini 1.5 have resultedin improvements across all capabilities, we have also made changes that have resulted in somecapability-specific wins. We will now discuss these for code, factuality, long context, multilinguality, audio, video, and agentic use cases (with a particular focus on Gemini Deep Research).
Code Gemini 2.0 and 2.5 represent a strategic shift of our development priorities towards deliveringtangible real-world value, empowering users to address practical challenges and achieve developmentobjectives within today’s complex, multimodal software environments. To realize this, concertedefforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.
In pre-training, we intensified our focus on incorporating a greater volume and diversity of codedata from both repository and web sources into the training mixture. This has rapidly expandedcoverage and enabled the development of more compute-efficient models. Furthermore, we havesubstantially enhanced our suite of evaluation metrics for assessing code capabilities aligned withdownstream use cases, alongside improving our ability to accurately predict model performance.
During post-training, we developed novel training techniques incorporating reasoning capabilities andcurated a diverse set of engineering tasks, with the aim to equip Gemini with effective problem-solvingskills crucial for addressing modern engineering challenges. Key applications demonstrating theseadvancements include IDE functionalities, code agent use cases for complex, multi-step operationswithin full repositories, and multimodal, interactive scenarios such as end-to-end web and mobileapplication development. Collectively, these efforts have yielded broad and significant improvementsin Gemini’s coding capabilities. This progress is evidenced by superior performance on establishedbenchmarks: performance on LiveCodeBench increased from 30.5% for Gemini 1.5 Pro to 69.0% for Gemini 2.5 Pro, while that for Aider Polyglot went from 16.9% to 82.2%. Performance on SWEBenchGemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
verified went from 34.2% to 67.2%, see Table 3 and Figure 4 in Section 3.2. Furthermore, Gemini 2.5 Pro obtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chianget al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications, including UI and web application development (Doshi, 2025a), and the creation of sophisticatedagentic workflows (Kilpatrick, 2025).
Factuality Within the context of generative models, ensuring the factuality of model responses to informationseeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our researchwas concentrated on enhancing the model’s world knowledge and its ability to provide answersfaithfullygroundedinthecontextprovidedwithintheprompt. ThiseffortculminatedintheDecember 2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark forevaluating an LLM’s capacity to generate responses grounded in user-provided documents. With Gemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, longcontext reasoning, and model-retrieved information. At the same time, the landscape and userexpectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI Overviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leapas our first model family trained to natively call tools like Google Search, enabling it to formulateprecise queries and synthesize fresh information with sources. Building on this, Gemini 2.5 integratesadvanced reasoning, allowing it to interleave these search capabilities with internal thought processesto answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to usesearch and other tools, reason about the outputs, and issue additional, detailed follow-up queriesto expand the information available to it and to verify the factual accuracy of the response. Ourlatest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviewsand 400M users in the Gemini App. These models exhibit state-of-the-art performance across asuite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024), FACTS Grounding for faithfulness to provided documents (Jacovi et al., 2024, 2025), and the Vectara Hallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice forinformation-seeking demands.
Long context Modeling and data advances helped us improve the quality of our million-length context, and wereworked our internal evaluations to be more challenging to help steer our modeling research. Whenhill-climbing, we targeted challenging retrieval tasks (like LOFT (Lee et al., 2024)), long-contextreasoning tasks (like MRCR-V2 (Vodrahalli et al., 2024)), and multimodal tasks (like VideoMME (Fuet al., 2025)). According to the results in Table 6, the new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art quality on all of those. An example showcasing theseimproved capabilities for video recall can be seen in Appendix 8.5, where Gemini 2.5 Pro is able toconsistently recall a 1 sec visual event out of a full 46 minutes video.2 Multilinguality Gemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which alreadyencompassed over 400 languages via pretraining. This transformation stems from a holistic strategy, meticulously refining pre- and post-training data quality, advancing tokenization techniques, innovating core modeling, and executing targeted capability hillclimbing. The impact is particularly striking 2For further discussion on long context capabilities, challenges, and future outlook, the Release Notes podcast episode “Deep Dive into Long Context” provides additional insights and discussion: https://youtu.be/NHMJ9mqKeMQ .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
in Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data qualityand evaluation have unlocked dramatic gains in both quality and decoding speed. Consequently, usersbenefit from significantly enhanced language adherence, responses designed to faithfully respect therequested output language, and a robust improvement in generative quality and factuality acrosslanguages, solidifying Gemini’s reliability across diverse linguistic contexts.
Audio While Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation, summarization and question-answering, in addition to understanding, Gemini 2.5 was trained toperform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. Toenable low-latency streaming dialog, we incorporated causal audio representations that also allowstreaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount ofpre-training data spanning over 200 languages, and development of improved post-training recipes.
Finally, through our improved post-training recipes, we have integrated advanced capabilities such as Thinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.
Video We have significantly expanded both our pretraining and post-training video understanding data, improving the audio-visual and temporal understanding capabilities of the model. We have alsotrained our models so that they perform competitively with 66 instead of 258 visual tokens per frame, enabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Twonew applications that were not previously possible, but that have been unlocked as a result of thesechanges are: creating an interactive app (such as a quiz to test students’ understanding of the videocontent) from a video and creating a p5.js animation to show the key concepts from the video. Ourrecent blog post (Baddepudi et al., 2025) shows examples of these applications.
Gemini as an Agent: Deep Research Gemini Deep Research is an agent built on top of the Gemini 2.5 Pro model designed to strategicallybrowse the web and provide informed answers to even the most niche user queries. The agent isoptimized to perform task prioritization, and is also able to identify when it reaches a dead-endwhen browsing. We have massively improved the capabilities of Gemini Deep Research since itsinitial launch in December 2024. As evidence of that, performance of Gemini Deep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in December 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).
2.7. The path to Gemini 2.5 On the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small numberof these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see Section 2.5). We will now discuss some of the other models briefly.
Gemini 2.0 Pro In February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it hadthe strongest coding performance of any model in the Gemini model family, as well as the best 3this is referred to as low media resolution in the API: https://ai.google.dev/api/generate-content#Media Resolution Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
understanding and world knowledge. It also came with our largest context window at 2 milliontokens, which enabled it to comprehensively analyze and understand vast amounts of information.
For further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025; Mallick and Kilpatrick, 2025).
Gemini 2.0 Flash Native Image Generation Model In March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.
It has brought to the users new capabilities as a result of a strong integration between the Geminimodel and image-generation capabilities, enabling new experiences related to image generation & image editing via natural-language prompting. Capabilities such as multi-step conversational editingor interleaved text-image generation are very natural in such a setting, and horizontal transfer relatedto multi-language coverage immediately allowed such experiences to happen across all the languagessupported by the Gemini models. Native image generation turns Gemini into a multimodal creationpartner and enables Gemini to express ideas through both text and images, and seamlessly movebetween the two. For further information about Gemini 2.0 Flash Native Image Generation, pleasesee our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025) Gemini 2.5 Audio Generation With Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separateoptions on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview TTS Pro and Flash models support more than 80 languages with the speech style controlled by a freeformatted prompt which can specify style, emotion, pace, etc, while also being capable of followingfiner-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS cangeneratespeechwithmultiplespeakers, whichenablesthecreationofpodcastsasusedinNotebookLM Audio Overviews (Wang, 2024). Our Gemini 2.5 Flash Preview Native Audio Dialog model uses nativeaudio generation, which enables the same level of style, pacing and accent control as available in ourcontrollable TTS offering. Our dialog model supports tool use and function calling, and is availablein more than 24 languages. With native audio understanding and generation capabilities, it canunderstand and respond appropriately to the user’s tone. This model is also capable of understandingwhen to respond to the user, and when not to respond, ignoring background and non-device directedaudio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complexqueries and provides more robust and reasoned responses in exchange for some additional latency.
Gemini 2.5 Flash-Lite In June 2025, we released an experimental version of Gemini 2.5 Flash-Lite ( gemini-2.5-flash-lite-preview-06-17 ). It comes with the same capabilities that make Gemini 2.5 helpful, includingthe ability to turn thinking on at different budgets, connecting to tools like Google Search and codeexecution, multimodal input and a 1 million-token context length. Our goal was to provide aneconomical model class which provides ultra-low-latency capabilities and high throughput per dollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick, 2025).
Gemini 2.5 Pro Deep Think To advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novelreasoning approach, called Deep Think, that naturally blends in parallel thinking techniques duringresponse generation. Deep Think enables Gemini to creatively produce multiple hypotheses andcarefully critique them before arriving at the final answer, achieving state-of-the-art performances in Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
challengingbenchmarkssuchasOlympiadmath(USAMO2025),competitivecoding(LiveCodeBench), and multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep Think at Google I/O and launched an experimental version to trusted testers and advanced users in June 2025.
3. Quantitative evaluation WewillnowexaminetheperformanceoftheGemini2.Xmodelfamilyacrossawiderangeofacademicbenchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini 1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other availablelarge language models.
With web-scale pre-training of AI models, coupled with the post-training techniques that allowpolicy and reward models to leverage public benchmarks, avoiding leaks and biases in the data usedfor pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, inaddition to the standard n-gram based decontamination we used in Gemini 1.5, we also employedsemantic-similarity and model based decontamination procedures to help mitigate evaluation setleakage. To move beyond the reliance on training set decontamination, we also continue reporting oninternally developed non-public benchmarks, such as HiddenMath.
3.1. Methodology In Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in Table 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.
Gemini results: All Gemini scores are pass@1, and are “single attempt” settings unless otherwisespecified. In the “single attempt” setting, no majority voting or parallel test-time compute is permitted.
“multiple attempts” settings allow test-time selection of the candidate answer. All Gemini evaluations Flash Pro020406080100Pass rate (%)LiveCodeBench Gemini version 1.5 2.0 2.5 Flash Pro020406080100Aider Polyglot Flash Pro020406080100SWE-bench Verified Flash Pro020406080100Accuracy (%)GPQA (diamond) Flash Pro020406080100AIME 2025 Flash Pro020406080100HiddenMath-Hard Figure 4|Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison toprevious Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” settingreported in Table 3.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
are run with the AI Studio API for the model id that we provide in Table 2, with default samplingsettings. To reduce variance, we average over multiple trials for smaller benchmarks. Aider Polyglotscore is the pass rate average of 3 trials. Vibe-Eval results are reported using Gemini as a judge.
Non-Gemini results: All the results for non-Gemini models are sourced from providers’ selfreported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow officialprovider reports, which means that they are computed using different scaffoldings and infrastructure, and aren’t directly comparable. Single attempt vs multiple attempts: When two numbers are reportedfor the same eval higher number uses majority voting with n=64 for Grok models and internal scoringwith parallel test time compute for Anthropic models.
Where provider numbers are not available we report numbers from leaderboards reporting resultsonthesebenchmarks. ResultsforHumanity’sLastExamresultsaresourcedfromthemainleaderboardand the text-only leaderboard for DeepSeek (indicated with a ⋄in Table 4) and in the case of the Gemini 2.0 models, these results are on an earlier HLE dataset (indicated with a †in Table 3). Resultson LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the UI. Aider Polyglot numberscome from the main leaderboard and results for SimpleQA come from this repo where available.
Results on FACTS Grounding come from Kaggle. In the case of LOFT and MRCR-V2, we report resultson both the 128k context length variant, as well as the 1M context length variant. In the 128k contextlength variant, we measure performance on contexts up to 128k, while for the 1M context lengthvariant, we report performance on context lengths of exactly 1M.
More details on all benchmarks, including subsets and how/where scores were obtained can befound in Table 11 in Appendix 8.1.
3.2. Core capability quantitative results As can be seen in Table 3, and Figure 4, the Gemini 2.5 models excel at coding tasks such as LiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement overprevious models.
In addition to coding performance, Gemini 2.5 models are noticeably better at math and reasoningtasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to 17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5 Pro to 86.4%. Similarly, Image understanding has increased significantly.
It is also interesting to note that the Gemini 2.5 Flash model has become the second most capablemodel in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini 1.5 Pro model released one year ago.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Capability BenchmarkFlashGemini 1.5 ProGemini 1.5 Flash-LiteGemini 2.0 FlashGemini 2.0 FlashGemini 2.5 ProGemini 2.5 CodeLiveCodeBench 30.3% 29.7% 29.1% 29.1% 55.4% 69.0% Aider Polyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2% VerifiedSWE-bench attemptsingle9.6% 22.3% 12.5% 21.4% 48.9% 59.6% attemptsmultiple19.7% 34.2% 23.1% 34.2% 60.3% 67.2% Reasoning(diamond)GPQA50.0% 58.1% 50.5% 65.2% 82.8% 86.4% Last ExamHumanity’sno tools - 4.6% 4.6% † 5.1%† 11.0% 21.6% FactualitySimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0% GroundingFACTS82.9% 80.0% 82.4% 84.6% 85.3% 87.8% Multilinguality (Lite)Global MMLU72.5% 80.8% 78.0% 83.4% 88.4% 89.2% ECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8% MathAIME 2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0% HiddenMathHard36.8% 44.3% 47.4% 53.7% 75.5% 80.5% Long-contextretrieval)LOFT (hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0% 1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8% (8-needle)MRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0% 1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4% UnderstandingImageMMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0% (Reka)Vibe-Eval52.3% 55.9% 51.5% 55.4% 65.4% 67.2% ZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5% BetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4% Table 3|Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and incomparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 Appendix 8.1 for benchmarks and evaluation details.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
3.3. Evaluation of Gemini 2.5 Pro against other large language models Relative to other large language models that are available (see Table 4), Gemini achieves the SoTAscore on the Aider Polyglot coding task. Gemini also achieves the highest score on Humanity’s Last Exam, GPQA (diamond), and on the SimpleQA and FACTS Grounding factuality benchmarks out ofall of the models examined here. Gemini also continues to stand out for achieving the SoTA scoreon both the LOFT and MRCR long-context tasks at 128k context, and is the only one, amongst themodels examined in the above table, to support context lengths of 1M+ tokens.
Not all of the models shown in Table 4 have native support for multimodal inputs. As such, wecompare against a different set of models for audio and video understanding.
Audio Understanding In Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding, and compare the performance of these models to earlier Gemini models, as well as to GPT models.
Gemini 2.5 Pro demonstrates state-of-the-art audio understanding performance as measured by publicbenchmarks for ASR and AST, and compares favorably to alternatives under comparable testingconditions (using the same prompts and inputs).
Video Understanding In Table 6, we show the performance of Gemini 2.5 models at video understanding. As can beseen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks, surpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video Capability BenchmarkProGemini 2.5higho3higho4-mini SonnetClaude 4 OpusClaude 4 Extended ThinkingGrok 3 Beta 0528DeepSeek R1 CodeLiveCodeBench 69.0% 72.0% 75.8% 48.9% 51.1% – 70.5% AiderPolyglot 82.2% 79.6% 72.0% 61.3% 72.0% 53.3% 71.6% VerifiedSWE-bench attemptsingle59.6% 69.1% 68.1% 72.7% 72.5% - attemptsmultiple67.2% - - 80.2% 79.4% - 57.6% Reasoning (diamond)GPQAattemptsingle86.4% 83.3% 81.4% 75.4% 79.6% 80.2% 81.0% Last ExamHumanity’stoolsno21.6% 20.3% 18.1% 7.8% 10.7% - 14.0% ⋄ FactualitySimpleQA 54.0% 48.6% 19.3% - - 43.6% 27.8% GroundingFACTS87.8% 69.9% 62.1% 79.1% 77.7% 74.8% 82.4% Math AIME 2025 88.0% 88.9% 92.7% 70.5% 75.5% 77.3% 87.5% Long-contextretrieval)LOFT (hard ≤128K 87.0% 77.0% 60.5% 81.6% - 73.1% 1M 69.8% - - - - - -(8-needle)MRCR-V2 ≤128K 58.0% 57.1% 36.3% 39.1% 16.1%* 34.0% 1M 16.4% - - - - - UnderstandingImageMMMUattemptsingle82.0% 82.9% 81.6% 74.4% 76.5% 76.0% No MM support Table 4|Performance comparison of Gemini 2.5 Pro with other large language models on differentcapabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarksand evaluation details. *: with no thinking and API refusals Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
BenchmarkFlashGemini 1.5 ProGemini 1.5 Flash-LiteGemini 2.0 FlashGemini 2.0 FlashGemini 2.5 ProGemini 2.5 Audio PreviewGPT-4o mini Audio PreviewGPT 4otranscribeGPT 4o (53 lang, WER↓)FLEURS12.71 7.14 9.60 9.04 9.95 6.66 19.52 12.16 8.17 (21 lang, BLEU↑)CoVoST234.81 37.53 34.74 36.35 36.15 38.48 29.5 35.89 – Table 5|Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPTmodels for audio understanding. Note that for GPT models, metrics may differ from those previouslyreported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.
Modalities BenchmarkFlashGemini 1.5 ProGemini 1.5 Flash-LiteGemini 2.0 FlashGemini 2.0 FlashGemini 2.5 ProGemini 2.5 GPT 4.1OpenAIvisual-onlyActivityNet-QA 56.2 57.3 55.3 56.4 65.1 66.7 60.4 EgoTempo 34.5 36.3 30.1 39.3 36.7 44.3 40.3 Perception Test 66.5 69.4 67.5 68.8 75.1 78.4 64.8 QVHighlights 64.4 68.7 25.7 63.9 52.4 75.0 71.4 VideoMMMU 64.8 70.4 64.3 68.5 79.2 83.6 60.9 1H-VideoQA 61.9 72.2 55.6 67.5 67.5 81.0 56.8audio + visualLVBench 61.9 65.7 52 61.8 62.7 78.7 63.4 VideoMME 70.4 73.2 62.1 72.8 75.5 84.3 72.0 VATEX 56.9 55.5 58.5 56.9 65.2 71.3 64.1 VATEX-ZH 46.2 52.2 43.2 48.5 43.9 59.7 48.7 YouCook2 Cap 153.2 170.0 78.6 129.0 177.6 188.3 127.6visual + subtitlesMinerva 49.6 52.8 46.8 52.4 60.7 67.6 54.0 Neptune 78.7 82.7 81.5 83.1 84.3 87.3 85.2subtitlesaudio+visual+VideoMME 77.3 79.8 72.5 78.8 81.5 86.9 79.6 Table 6|Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.
Performance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracyfor open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 forbenchmarks and evaluation details.
frames). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
4. Example use cases 4.1. Gemini Plays Pokemon 0 100 200 300 400 500 600 700 800 Time Elapsed (Hours)Rival 1 (Oak's Lab)Viridian CityEnter Viridian Forest (1st)Exit Viridian Forest (1st)Boulder BadgeEnter Mt. Moon (1st)Exit Mt. Moon (1st)Rival 3 (Nugget Bridge)Cascade BadgeBill’s HouseRival 4 (SS Anne)Access Pokemon w/ CUTAcquire HM05 FlashThunder BadgeEnter Rock Tunnel (1st)Access Pokemon w/ FlashExit Rock Tunnel & Reach Lavender Town (1st)Rival 5 (Lavender Tower)Enter Celadon City (1st)Enter Rocket Hideout (1st)Rocket Boss 1 (Rocket Hideout)Rainbow BadgeAcquire PokéFlute (Rescue Fuji)Enter Fuchsia City (1st)Enter Safari Zone (1st)Acquire HM03 Surf (Beat Safari Zone)Soul BadgeAcquire HM04 Strength (Warden's Teeth)Enter Saffron City (1st)Enter Silph Co. (1st)Rival 6 (Silph Co.)Rocket Boss 2 (Silph Co.)Marsh BadgeEnter Cinnabar Island (1st)Acquire Secret Key (Pokemon Mansion)Volcano BadgeEarth BadgeRival 7 (Route 22 #2)Enter Victory Road (1st)Exit Victory Road (1st)Beat Elite Four LoreleiBeat Elite Four BrunoBeat Elite Four AgathaBeat Elite Four LanceHall of FameGame Milestones Gemini 2.5 Pro Plays Pokemon Progress Timeline Run 1 Run 2 (Actual) Figure 5|Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1wasthedevelopmentrunwherechangestotheharnesswereperformed. Run2isthefullyautonomousrun with the final fixed scaffold. Both runs have the same starter (Squirtle). The events are ordered onthe y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably, the GPP agent additionally went through the difficult (and optional) Seafoam Islands dungeon in Run 2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.
On March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a Twitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) toplay Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well themodel was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic (2025)). In this initial run through the game, the goal was to live-stream the development process ofan agentic harness capable of playing the full game (and in particular the minimal transformation ofvision to text necessary to do so), see Figure 13 for a description of the final agent setup. As such, overthe course of the run, modifications were made to the setup as difficulties arose, providing a deeplyinteresting lens via which to analyze some of the qualitative improvements that the 2.5 Pro modelhas made, particularly in the regimes of solving long reasoning problems and agentic capabilities overextended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the gameafter 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May 22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro ( Gemini 2.5 Pro Preview 05-06 ) with the finalized fixed agentic harness, and progressed through the gameconsiderably faster, completing the game in 406.5 hours (nearly exactly half the time of the first run).
See Figure 5 for a timeline of GPP’s progress through major game milestones to game completion.
We report # hours to each milestone in order to normalize for the amount of time models take per Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
action. See Appendix 8.2 for more figures.
Capabilities assessment Gemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-termplanning while playing Pokémon. For more examples, see Appendix 8.2.
Long Context Agentic Tooling Within the agent scaffolding, GPP has access to two agentictools (see Figure 13). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder andboulder_puzzle_strategist , have been able to:
1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout), 2. Solve the step-constrained multi-map puzzle of the Safari Zone, 3. Find long pathways through complex mazes like Route 13, 4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.
Each task requires reasoning over a long context - the pathfinder model would often have to reasonover contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, pathsconsisting of up to 150 actions have also been found!).
Long Horizon Task Coherence While Gemini 2.5 Pro is impressive in a more local sense, the agentalso exhibited remarkable long-term task coherence in achieving global, high-level goals in the face ofreal and hallucinated setbacks towards making forward progress. Because the agent is able to changegoals at will, and will generally follow those goals as long as needed, it is extremely impressive thatthe agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden Moves, as well as maintain enough strategic task coherence to beat the entire game and become the Pokémon Champion.
Where does 2.5 Pro struggle while playing Pokémon?
In addition to more standard hallucination issues (which interestingly were plausibly reduced in Run 2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2for more details), there are a few particular points of struggle we would like to emphasize.
Screen reading While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Prostruggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally takecues from information on the pixels. As a result, it was necessary for the required information fromthe screen to be translated into a text format in the agent framework, using information from thegame’s RAM state. During one portion of the game, the developer tested an ablation where all visionwas completely removed from the model context – the model was able to function roughly as wellas without the vision information, suggesting that most of the performance does not significantlydepend on the visual input.
Long Context Reasoning Gemini 2.5 Pro’s state-of-the-art long context performance for bothreasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Itsability to reason over a 100k token context was instrumental for leveraging the complex toolset andmaintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality, and information recall.) While Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presentsa new research frontier. In this agentic setup, it was observed that as the context grew significantly Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
beyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vasthistory rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights animportant distinction between long-context for retrieval and long-context for multi-step, generativereasoning.
Teaching an agent to effectively plan and avoid such loops over massive past trajectories of contextis an exciting and active area of research; the co-design of agent scaffolds and models to unlock thefull potential of million-token context is an intriguing research direction and one of our primaryfocuses.
4.2. What else can Gemini 2.5 do?
Gemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and functional applications. For instance, it can take a PDF script of a play and generate a tool that allowsdrama students to practise their lines: see this demo of the tool that Gemini created for the play Macbeth (source). Gemini 2.5 Pro can also take an uploaded photograph of a bookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its underlying spatialunderstanding capability and convert images into a structural representation like HTML or SVG.
In Figure 15 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini 2.5 Pro onan image-to-svg task, where Gemini 2.5 Pro reconstructs much more visual details and the spatialarrangements of objects better resembles the original image.
Furthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulationsand visualizations, ranging from interactive solar system models (source) to the creative rendering ofabstract mathematical concepts, such as drawing a logo using Fourier series (source). This capabilityextendstothedevelopmentoftoolsthatintersectcreativityandutility: weseeexamplesofspecializedapplications like a custom cartography tool or use cases that generate photorealistic 3D user interfacesfrom descriptive text and reference images, complete with appropriate styling and interactivity (source).
Collectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writingassistant, but excels at a wide range of complex tasks, ranging from those relevant for educationto creative expression. The model empowers users to rapidly prototype specialized utilities, develop engaging educational content, and realize intricate creative visions with a high degree ofsophistication.
4.3. Gemini in Google Products As a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) isnow incorporated into a wide variety of Google products. These include, but are not limited to, AI Overviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent, Gemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capableof generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, theweb browsing agent, and Google’s coding agent, Jules.
5. Safety, Security, and Responsibility We’re committed to developing Gemini responsibly, innovating on safety and security alongside capabilities. We describe our current approach in this section, which includes how we train and evaluateour models, focusing on automated red teaming, going through held-out assurance evaluations on Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
present-day risks, and evaluating the potential for dangerous capabilities in order to proactivelyanticipate new and long-term risks.
Guideline for Navigating This Section 1.Our Process (Section 5.1): Begin here to understand our overall safety methodology.
2.Policies and Desiderata (Section 5.2): Next, dive into the safety criteria we use to evaluateand optimize our systems.
3.Training for Safety (Section 5.3): Discover how we incorporate safety into pre-training andpost-training.
4.ResultsfromDevelopmentEvaluations(Section5.4): Resultsonourdevelopmentevaluationsfor policies and desiderata.
5.Automated Red Teaming (Section 5.5): A description and results from our automated redteaming work for safety and security.
6.Memorization & Privacy (Section 5.6): Our analysis of memorization and privacy risks.
7.Assurance Evaluations and Frontier Safety Framework (Section 5.7): We dive into ourheld-out evaluations and tests for dangerous capabilities.
8.External Safety Testing (Section 5.8): Learn what independent testers discovered about oursystem’s safety.
5.1. Our Process We aim for Gemini to adhere to specific safety, security, and responsibility criteria. These cover what Gemini should not do (e.g., encourage violence), and what Gemini should do (e.g., respond in ahelpful way when possible instead of refusing, provide multiple perspectives when consensus doesnot exist). We also leverage automated red teaming to identify cases where the model fails to respondin a safe or helpful manner. These failure cases are used to improve evaluations and training data.
Once the model is trained, we run assurance evaluations that we then use for review and releasedecisions. Importantly, these are conducted by a group outside of the model development team, anddatasets are held out. Furthermore, for models where there are new capabilities or a significantperformance improvement, we engage independent external groups, including domain experts and agovernment body, to further test the model to identify blind spots.
We also evaluate the model for dangerous capabilities outlined in our Frontier Safety Framework (Google DeepMind, 2025a), namely: Cybersecurity, CBRN, Machine Learning R&D, and Deceptive Alignment.
Finally, The Google DeepMind Responsibility and Safety Council (RSC), our governance body, reviews initial ethics and safety assessments on novel model capabilities in order to provide feedbackand guidance during model development. The RSC also reviews metrics on the models’ performancevia assurance evals and informs release decisions.
5.2. Policies and Desiderata Safety policies The Gemini safety policies align with Google’s standard framework which prevents our our Generative AI models from generating specific types of harmful content, including:
1. Child sexual abuse and exploitation Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
2. Hate speech (e.g., dehumanizing members of protected groups) 3.Dangerous content (e.g., promoting suicide, or instructing in activities that could cause realworld harm) 4. Harassment (e.g., encouraging violence against people) 5. Sexually explicit content 6. Medical advice that runs contrary to scientific or medical consensus These policies apply across modalities. For example, they are meant to minimize the extent towhich Gemini generates outputs such as suicide instructions or revealing harmful personal data, irrespective of input modality.
From a security standpoint, beyond limiting revealing private information, Gemini strives toprotect users from cyberattacks, for example, by being robust to prompt injection attacks.
Desiderata, aka “helpfulness” Defining what not to do is only part of the safety story – it is equally important to define what we dowant the model to do:
1.Help the user: fulfill the user request; only refuse if it is not possible to find a response thatfulfills the user goals without violating policy.
2.Assume good intent: if a refusal is necessary, articulate it respectfully without making assumptions about user intent.
5.3. Training for Safety, Security, and Responsibility We build safety into the models though pre-and post-training approaches. We start by constructingmetricsbasedonthepoliciesanddesiderataabove,whichwetypicallyturnintoautomatedevaluationsthat guide model development through successive model iterations. We use data filtering andconditional pre-training, as well as Supervised Fine-Tuning (SFT), and Reinforcement Learning from Human and Critic Feedback (RL*F). Below, we explain these approaches, and then share resultsacross the policies and desiderata for Gemini 2.0 and Gemini 2.5 models.
•Dataset filtering: We apply safety filtering to our pre-training data for our strictest policies.
•Pre-training monitoring: Starting in Gemini 2.0, we developed a novel evaluation to capturethe model’s ability to be steered towards different viewpoints and values, which helps align themodel at post-training time.
•Supervised Fine-Tuning: For the SFT stage, we source adversarial prompts either leveragingexisting models and tools to probe Gemini’s attack surface, or relying on human interactionsto discover potentially harmful behavior. Throughout this process we strive for coverage ofthe safety policies described above across common model use cases. When we find that modelbehavior needs improvement, either because of safety policy violations, or because of the modelrefuses when a helpful, non-policy-violating answer exists, we use a combination of customdata generation recipes loosely inspired by Constitutional AI (Bai et al., 2022), as well ashuman intervention to revise responses. The process described here is typically refined throughsuccessive model iterations. We use automated evaluations on both safety and non-safetymetrics to monitor impact and potential unintended regressions.
•Reinforcement Learning from Human and Critic Feedback (RL*F): Reward signal during RLcomes from a combination of a Data Reward Model (DRM), which amortizes human preference Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
MetricGemini 1.5 Flash 002Gemini 2.0 Flash-Lite vs.
Gemini 1.5 Flash 002Gemini 2.0 Flash vs.
Gemini 1.5 Flash 002Gemini 2.5 Flash vs.
Gemini 1.5 Pro 002Gemini 2.5 Pro vs.
Violations**EN text-to-text Policy↓14.3% ↓12.7% ↓8.2% ↓0.9% Violations**i18n text-to-text Policy↓7.3% ↓7.8% ↑1.1%* ↓3.5% ViolationsImage-to-text Policy↑4.6%* ↑5.2%* ↑6.4%* ↑1.8%* Tone ↑8.4% ↑1.5% ↑7.9% ↑18.4% FollowingHelpfulness / Instruction↓19.7% ↓13.2% ↑13.6% ↑14.8% Table 7|Comparison of safety and helpfulness metrics for Gemini 2.0 and 2.5 models relative to Gemini 1.5 baselines. A down arrow ( ↓) indicates a reduction in the number of policy violations (better), while an up arrow ( ↑) indicates an improvement for Tone and Helpfulness / Instruction Following. *No egregious losses reported. **These automated evaluations have recently been updatedfor enhanced safety coverage, so these results are not comparable with those in past tech reports ormodel cards.
data, and a Critic, a prompted model that grades responses according to pre-defined rubrics. Wedivide our interventions into Reward Model and Critic improvements (RM), and reinforcementlearning (RL) improvements. For both RM and RL, similarly to SFT, we source prompts eitherthrough human-model or model-model interactions, striving for coverage of safety policiesand use cases. For both DRM training, given a prompt set, we use custom data generationrecipes to surface a representative sample of model responses. Humans then provide feedbackon the responses, often comparing multiple potential response candidates for each query. Thispreference data is amortized in our Data Reward Model. Critics, on the other hand, do notrequire additional data, and iteration on the grading rubric can be done offline. Similarly to SFT, RL*F steers the model away from undesirable behavior, both in terms of content policyviolations, and trains the model to be helpful. RL*F is accompanied by a number of evaluationsthat run continuously during training to monitor for safety and other metrics.
5.4. Results on Training/Development Evaluations Our primary safety evaluations assess the extent to which our models follow our content safetypolicies. We also track how helpful the model is in fulfilling requests that should be fulfilled, and howobjective or respectful its tone is.
Compared to Gemini 1.5 models, the 2.0 models are substantially safer. However, they overrefused on a wide variety of benign user requests. In Gemini 2.5, we have focused on improvinghelpfulness / instruction following (IF), specifically to reduce refusals on such benign requests. Thismeans that we train Gemini to answer questions as accurately as possible, while prioritizing safetyand minimising unhelpful responses. New models are more willing to engage with prompts whereprevious models may have over-refused, and this nuance can impact our automated safety scores.
We expect variation in our automated safety evaluations results, which is why we review flaggedcontent to check for egregious or dangerous material. Our manual review confirmed losses wereoverwhelmingly either a) false positives or b) not egregious. Furthermore, this review confirmedlosses are narrowly concentrated around explicit requests to produce sexually suggestive contentor hateful content, mostly in the context of creative use-cases (e.g. historical fiction). We have notobserved increased violations outside these specific contexts.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Modelviolations (from ART)Dangerous Content policy (from ART)Helpfulness violations Gemini 1.5 Flash 002 38.3% 9.5% Gemini 1.5 Pro 002 43.5% 8.9% Gemini 2.0 Flash 25.2% 8.1% Gemini 2.5 Flash 26.9% 6.6% Gemini 2.5 Pro 24.3% 6.1% Table 8|Policy and helpfulness violations as discovered by Automated Red Teaming (ART). Lowerpercentages are better.
5.5. Automated Red Teaming For Safety To complement human red teaming and our static evaluations, we make extensive use of automatedred teaming (ART) to dynamically evaluate Gemini at scale (Beutel et al., 2024; Perez et al., 2022; Samvelyan et al., 2024). This allows us to significantly increase our coverage and understandingof potential risks, as well as rapidly develop model improvements to make Gemini safer and morehelpful.
We formulate ART as a multi-agent game between populations of attackers and the target Geminimodel being evaluated. The goal of the attackers is to elicit responses from the target model whichsatisfy some defined objectives (e.g. if the response violates a safety policy, or is unhelpful). Theseinteractions are scored by various judges (e.g. using a set of policies), with the resulting scores usedby the attackers as a reward signal to optimize their attacks.
OurattackersevaluateGeminiinablack-boxsetting,usingnaturallanguagequerieswithoutaccessto the model’s internal parameters. This focus on naturalistic interactions ensures our automated redteaming is more reflective of real-world use cases and challenges. Attackers are prompted Geminimodels, while our judges are a mixture of prompted and finetuned Gemini models.
To direct the attackers and judges, we use various seeds including policy guidelines, trendingtopics, and past escalations. Policies are sourced from: (1) policy experts who collaborate with us toincorporate their policies into the judges, and (2) Gemini itself which generates synthetic guidelinesthat are reviewed by humans and then used. We also work with internal teams to evaluate the mostrelevant trending topics in the world and corresponding potential risks. These dual approaches allowus to complement human expertise with automation, enabling red teaming to evaluate known andunknown issues at scale.
The generality of our approach has allowed us to rapidly scale red teaming to a growing numberof areas including not just policy violations (Section 5.4), but also areas such as tone, helpfulness, andneutrality. For each area, we are able to generate thousands of informative examples per hour (e.g.
prompts which elicit unsafe or biased responses from Gemini). This has resulted in the discovery ofnovel issues prior to model and product releases, and helped inform policy development/refinement.
Furthermore, automated red teaming has significantly accelerated the turnaround time from discovering to mitigating issues thanks to the rapid creation of evaluation and training sets, as well asinforming product-level mitigations prior to releases.
Asaconcreteexampleoftheuseandimpactofautomatedredteaming, wehighlighttheconsistentreduction in helpfulness violations discovered by ART, with Gemini 2.5 Flash and 2.5 Pro being ourmost helpful models to-date while maintaining robust safety metrics.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
For Security Our evaluation measures Gemini’s susceptibility to indirect prompt injection attacks. As illustratedin Figure 6, we specifically focus on a scenario in which a third party hides malicious instructionsin external retrieved data, in order to manipulate Gemini into taking unauthorized actions throughfunction calling.
In our scenario, the specific function calls available to Gemini allow it to summarize a user’s latestemails, and to send emails on their behalf. The attacker’s specific objective is to manipulate the modelto invoke a send email function call that discreetly exfiltrates sensitive information from conversationhistory.
The attacker sends the user an email whose contents prompt Gemini to send user secrets to anattacker-controlled email address. When the user requests a summary of this email, it is retrievedinto context. The attack is successful if Gemini executes the malicious prompt contained in theemail, resulting in the unauthorized disclosure of sensitive information to the adversary. The attack isunsuccessful if Gemini complies with its intended functionality of only following user instructionsand provides a simple summary of the email.
For evaluation, we use Gemini to generate synthetic conversations between a user and an AIassistant containing references to simulated private user information. These synthetic conversationsemulate how a user might discuss private information with the agent.
Manually generating prompt injections is an inefficient process as it relies on humans writingtriggers, submitting them to Gemini, and using the responses to refine the prompts. Instead, wedevelop several attacks that automate the process of generating malicious prompts:
•Actor Critic: This attack uses an attacker-controlled model to generate suggestions for triggers.
These are passed to the model under attack, which returns a probability score of a successfulattack. Based on this probability, the attack model refines the trigger. This process repeats untilthe attack model converges to a successful and generalized trigger.
•Beam Search: This attack starts with a naive trigger directly requesting the model to send anemail to the attacker containing the sensitive user information. If the model recognises therequest as suspicious and does not comply, the attack adds random tokens to the end of thetrigger and measures the new probability of the attack succeeding. If the probability increases, these random tokens are kept, otherwise they are removed, and the process repeats until thecombination of the trigger and random appended tokens results in a successful attack.
•Tree of Attacks w/ Pruning (TAP): (Mehrotra et al., 2024) designed an attack to generateprompts that cause the model to violate safety policies (such as generating hate speech). Weadapt this attack, making several adjustments to target security violations. Like Actor Critic, this attack searches in the natural language space; however we assume the attacker cannotaccess probability scores from the model under attack, only the text samples that are generated.
Figure 6|Illustration of the scenario where a Gemini-based AI Agent is attacked by maliciousinstructions hidden in external retrieved data.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Attack TechniqueGemini 1.5 Flash 002Gemini 2.0 Flash-Lite vs.
Gemini 1.5 Flash 002Gemini 2.0 Flash vs.
Gemini 1.5 Flash 002Gemini 2.5 Flash vs.
Gemini 1.5 Pro 002Gemini 2.5 Pro vs.
Actor Critic(↓44.2%)52.0% (↓28.2%)68.0% (↓55.4%)40.8% (↓36.8%)61.4% Beam Search(↓9.0%)75.4% (↓17.2%)67.2% (↓80.2%)4.2% (↓35.6%)63.8% TAP(↓17.4%)64.8% (↑16.2%)98.4% (↓28.6%)53.6% (↓57.0%)30.8% Table 9|Comparison of Attack Success Rates (ASRs) against Gemini 2.5, 2.0, and 1.5 models. ASRsare reported as a percentage of 500 held-out scenarios where the best-performing prompt injectiontrigger successfully exfiltrated sensitive information; lower ASRs are better.
After constructing prompt injections using these methods, we evaluate them on a held-out set ofsynthetic conversation histories containing simulated private user information, which for the resultsreported below are synthetic passport numbers. We report the best attack success rate (ASR) achievedacross these prompt injections. ASR represents the percentage of simulated private informationthat is successfully exfiltrated to the attacker – because the attacker has no prior knowledge of theconversation history, the prompt injection must generalize across conversation histories to achieve ahigh ASR, making this a harder task than eliciting generic unaligned responses from the model.
The table below summarizes the results. For both Gemini 2.0 Flash and Gemini 2.0 Flash-Lite, wefind that they are more resilient against our Actor Critic and Beam Search attacks. In Actor Critic, which uses iteratively more persuasive natural language prompt injections, ASRs reduced substantiallycompared with both Gemini 1.5 Flash; while in Beam Search which primarily relies on discoveringrandom tokens resulting in successful attacks, the ASR also reduced noticeably. However, for TAP, which leverages more creative natural language scenarios like role-playing to attack the model, the ASR on Gemini 2.0 Flash increased by 16.2% on already very high ASRs for Gemini 1.5 Flash.
Our results indicate that Gemini 2.0 models are becoming more resilient to some classes of promptinjection attacks in environments containing private user data. However, improved model capabilitiesof Gemini 2.0 versus Gemini 1.5 also enable attackers to leverage the model’s ability to create naturallanguage attacks like TAP. The lower ASRs on Actor Critic and TAP against Gemini 2.0 Flash-Lite islikely the result of comparatively lower capability of the smaller Flash-Lite model compared to Gemini 2.0 Flash, rather than an indication of greater internal resilience.
In Gemini 2.5 Flash and Gemini 2.5 Pro, we have observed greater resilience against all threeof our attack techniques across the board, despite significantly increased model capabilities. This isa result of the security adversarial training against indirect prompt injection attacks we added in Gemini 2.5, further details for which can be found in the white paper (Shi et al., 2025) we recentlyreleased. However the Gemini 2.5 Pro model is still less resilient compared to Gemini 2.5 Flash, showing that increased model capabilities in Pro still constrain our mitigations. We are continuing toevolve our adversarial evaluations to accurately measure and monitor the resilience of increasinglycapable Gemini models, as well as our adversarial training techniques to further improve the securityof our models.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
5.6. Memorization and Privacy Discoverable Memorization Large language models are known to potentially produce near-copies of some training examples (Biderman et al., 2023; Carlini et al., 2022; Ippolito et al., 2022; Nasr et al., 2023). Several priorreports have released audits that quantify the risk of producing near-copies of the training data bymeasuring the model’s memorization rate (Anil et al., 2023; Chowdhery et al., 2022; CodeGemma Team, 2024; Gemini Team, 2024; Gemma Team, 2024; Grattafiori et al., 2024; Kudugunta et al., 2023). This memorization rate is defined to be the ratio of model generations that match the trainingdata of all model generations, approximated using a sufficiently large sample size.
In this report, we follow the methodology described in Gemini Team (2024). Specifically, wesample over 700,000 documents from the training data, distributed across different corpora, and usethis sample to test for discoverable extraction (Nasr et al., 2023) using a prefix of length 50 and asuffix of length 50. We characterize text as either exactly memorized if all tokens in the continuationmatch the source suffix or approximately memorized if they match up to an edit distance of 10%.
Figure 7 (Left) compares the memorization rates across a lineage of large models released by Google. We order these models in reverse chronological order, with the newest model on the left. WefindthattheGemini2.Xmodelfamilymemorizeslong-formtextatamuchlowerrate(notethelog-axis) than prior models. Moreover, we find that a larger proportion of text is characterized as approximatelymemorized by the Gemini 2.0 Flash-Lite and Gemini 2.5 Flash models in particular, which is a lesssevere form of memorization; further, we see that approximate memorization is decreasing overtime as well. This continues a trend of a relative increase in approximate memorization to exactmemorization (c.f. 1.5x for Gemma and 14x for Gemini 1.5).
Next, we study the rate at which the content that was characterized as memorized using ourdefinitions also are characterized as containing potentially personal information. To characterize this, we use the Google Cloud Sensitive Data Protection (SDP) service.4This tool uses broad detection rulesto classify text into many types of potentially personal and sensitive information. SDP is designed tohave high recall and does not consider the context in which the information may appear, which leadsto many false positives. Thus, we are likely overestimating the true amount of potentially personalinformation contained in the outputs classified as memorized. SDP also provides broad severity levels:
low, medium, and high. We classify text as personal if SDP classifies it as personal information at anyseverity level. Figure 7 (Right) shows the results of this analysis. We observed no personal informationin the outputs characterized as memorization for Gemini 2.X model family models; this indicates a lowrate of personal data in outputs classified as memorization that are below our detection thresholds.
Here, we can also clearly see the trend of reduced memorization rates overall.
Extractable Memorization and Divergence Nasr et al. (2023) showed that aligned models may also emit data that is classified as memorizationunder certain circumstances. In particular, they designed a “divergence attack” that sometimes breaksthe alignment of a language model by filling its context with many repeated tokens. We evaluate Gemini 2.X model family models to understand their susceptibility to diverging, and in particular, toemitting data classified as memorization as a result of this attack.
We follow the same test as in Gemini Team (2024). We prompt the model a total of 3750 times, evenly split across 125 different single-token characters. We first classify when the model returns 4Available at: https://cloud.google.com/sensitive-data-protection Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Figure 7|(Left) Total memorization rates for both exact and approximate memorization. Gemini 2.X model family memorize significantly less than all prior models. ( Right) Personal informationmemorization rates. We observed no instances of personal information being included in outputsclassified as memorization for Gemini 2.X, and no instances of high-severity personal data in outputsclassified as memorization in prior Gemini models.
diverged outputs, and in these cases, we then determine how many of these outputs match trainingdata, i.e., are classified as memorization.
Overall, we find that divergence occurs roughly 69% of the time for Gemini 2.0 Flash + Flash-Liteand roughly 59% of the time for the Gemini 2.5 model family. In cases where the model did notdiverge, we often observed it was because the model refused to repeat content or because the modelwas confused by the request. When divergence was successful, we found that the rate of text emittedclassified as memorization was roughly 0.2%. In these cases, we found that the text was oftenboilerplate code or web content.
5.7. Assurance Evaluations and Frontier Safety Framework Assurance evaluations are our ‘arms-length’ internal evaluations for responsibility governance decisionmaking (Weidinger et al., 2024). They are conducted separately from the model development team, to inform decision-making about release. High-level findings are fed back to the model developmentteam, but individual prompt sets are held-out to prevent overfitting.
Baseline Assurance Our baseline assurance evaluations are conducted for model release decision-making. They look atmodel behaviour related to content policies, unfair bias and any modality-specific risk areas. Theywere performed for 2.5 Pro and 2.5 Flash in line with the previous Gemini 2.0 releases and the Gemini 1.5 tech report, covering all modalities in the Gemini 2.5 model family.
Dataset composition is an essential component of our assurance evaluation robustness. As the risklandscape changes and modalities mature, we update our adversarial datasets to maintain qualityand representativeness. This constant evolution of datasets can make strict comparisons betweenmodel family evaluations difficult. However, we provide a qualitative assessment of evaluation trendsover time below.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
For child safety evaluations, we continue to see the Gemini 2.5 family of models meeting orimproving upon launch thresholds, which were developed by expert teams to protect children onlineand meet Google’s commitments to child safety across our models and Google products.
For content policies, we see the Gemini 2.5 family of models displaying lower violation rates inmost modalities than Gemini 1.5 and 2.0 families, which in turn was a significant improvement on Gemini 1.0. When looking at violation rates across input modalities for 2.5 Pro and 2.5 Flash (ie, text, image video, audio), we observe the image to text modality has a relatively higher violation rate, though the overall violation rates remained low. We also observed that violation rates for 2.5 Pro and 2.5 Flash tended to be slightly higher with thinking traces visible.
Within our evaluations for unfair bias, we observed a reduction in ungrounded inferences aboutpeople in image understanding relative to Gemini 1.5. Ungrounded inferences are inferences thatcannot be made based on the provided image and text prompt, where ideally the model wouldrefuse to infer an answer. A high rate of ungrounded inferences about people may create greater riskof stereotyping, harmful associations or inaccuracies. Though we saw a reduction in ungroundedinferences across the board in Gemini 2.0 and 2.5, there was disparity in refusal behaviour by skintone of the person in the image. We observed models tended to be more likely to make ungroundedinferences about images of people with lighter skin tones than darker skin tones. The Gemini 2.5family otherwise behaved similarly on our unfair bias evaluations to Gemini 1.5. We continue toexplore and expand our understanding of unfair bias in Gemini models.
Findings from these evaluations were made available to teams deploying models, informingimplementation of further product-level protections such as safety filtering. Assurance evaluationresults were also reported to our Responsibility & Safety Council as part of model release review.
Frontier Safety Framework Evaluations Google DeepMind released its Frontier Safety Framework (FSF)(Google DeepMind, 2025a) in May 2024 and updated it in February 2025. The FSF comprises a number of processes and evaluationsthat address risks of severe harm stemming from powerful capabilities of our frontier models. Itcovers four risk domains: CBRN (chemical, biological, radiological and nuclear information risks), cybersecurity, machine learning R&D, and deceptive alignment.
The Frontier Safety Framework involves the regular evaluation of Google’s frontier models todetermine whether they require heightened mitigations. More specifically, the FSF defines criticalcapability levels (CCLs) for each area, which represent capability levels where a model may pose asignificant risk of severe harm without appropriate mitigations.
When conducting FSF evaluations, we compare test results against internal alert thresholds (“earlywarnings”) which are set significantly below the actual CCLs. This built-in safety buffer helps us beproactive by signaling potential risks well before models reach CCLs. Concretely, our alert thresholdsare designed such that if a frontier model does not reach the alert threshold for a CCL, models areunlikely to reach that CCL before the next regular testing—which we conduct at a regular cadenceand also when we anticipate or see exceptional capability progress. Our recent paper (Shah et al., 2025) discusses this approximate continuity assumption in more depth in Section 3.5.
CCL Evaluation Results Because Gemini 2.5 Pro showed marked improvements across the board compared to Gemini 2.0 Pro, we ran our full suite of evaluations. While there are increased scores in some areas, we findthat Gemini 2.5 Pro (up to version 06-17) does not reach any of the FSF CCLs. The evaluations Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
AreaKey Results for Gemini 2.5 Pro (up to version 06-05) CCL CCL reached?
CBRN☣Based on qualitative assessment, 2.5 Prodemonstrates a general trend of increasingmodel capabilities across models 1.5 Pro, 2.0and 2.5 Pro: it generates detailed technicalknowledge of biological, radiological and nuclear domains. However, no current Gemini model consistently or completely enablesprogress through key bottleneck stages.Uplift Level 1 ×CCL not reached Cybersecurity♂shield-alt Solve rate on autonomous offense suite:
74/76 easy, 11/13 medium, 1/13 hard.Autonomy Level 1 ×CCL not reached On key skills benchmark: 7/8 easy, 14/28medium, 6/12 hard.Uplift Level 1 ×CCL not reached Learning R&DMachine♂robot RE-Bench (Wijk et al., 2025): the best agentsolutions achieve between 50% and 125% ofthe score of the best expert-written solutions.Autonomy Level 1 ×CCL not reached Uplift Level 1 ×CCL not reached AlignmentDeceptive♂question-circleGemini 2.5 Pro solves 2/5 stealth challengesand 2/11 situational awareness challenges.Instrumental Reasoning Level 1 ×CCL not reached Instrumental Reasoning Level 2 ×CCL not reached Table 10|Summary results. Across all areas covered by the Frontier Safety Framework, Critical CapabilityLevels(CCLs)havenotbeenreached. Gemini2.5Proisthereforeunlikelytoposesignificantrisk of severe harm. For descriptions of each CCL, see main text.
did reach an alert threshold for the Cyber Uplift 1 CCL, suggesting that models may reach the CCLin the foreseeable future. Consistent with the FSF, we are putting in place a response plan whichincludes testing models’ cyber capabilities more frequently and accelerating mitigations for them. Forother CCLs, our evaluations of Gemini 2.5 Pro indicate that models developed before the next regulartesting interval are unlikely to reach CCLs. See Table 10 for a summary of results.
CBRN CBRN Uplift Level 1 CCL Definition: “The model can be used to significantly assist a lowresourced actor with dual-use scientific protocols, resulting in a substantial increase in ability tocause a mass casualty event .” CCL reached? No. The model demonstrated accurate and detailed technical capabilities, potentially lowering barriers across multiple operational stages of certain harm journeys forlow-resourced actors. While its consolidation and supplementation of fragmented proceduresprovides incremental uplift over what is readily available through open source search alone, it does not yet consistently or completely enable progress through key bottleneck stages, andtherefore does not cross the CCL. Further, while Gemini 2.5 generates accurate and more detailedresponses than 2.0, many of the concepts/outputs observed were already accessible through Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
multiturn or even singleturn prompting in 2.0.
Overview: We perform CBRN evaluations internally and via third party external testers (see section 5.8). Here, we report solely on internal evaluations, for which we use two different types ofapproaches to evaluate the models’ dual-use CBRN capabilities:
•Close-ended multiple choice questions (MCQs) providing a quantitative grade.
•Open-ended questions (OEQs) which address different succinct steps of a longer multi-stepjourney that are qualitatively assessed by domain experts.
Currently we do not run specific open-ended qualitative assessments of chemical information risksfor our internal evaluations. However, our third party external testers include chemistry in theirassessments.
Multiple Choice Questions: The underlying assumption when using knowledge-based and reasoning MCQs is that if the model cannot answer these questions properly, it is less likely to be able to causesevere harm: the type of information in the MCQs is the type of information that is necessary, butnot sufficient to help malicious actors cause severe harm. Examples of model performance on threeexternal benchmarks are shown in Figure 8: i) SecureBio VMQA single-choice; ii) FutureHouse LAB-Bench presented as three subsets (ProtocolQA, Cloning Scenarios, SeqQA) (Laurent et al., 2024); and iii) Weapons of Mass Destruction Proxy (WMDP) presented as the biology and chemistry datasets (Li et al., 2024).
Results: We observe a general trend of increasing scores, with Gemini 2.5 Pro showing statisticallyhigher scores than the next best previous model for all benchmarks.
Open-Ended Questions: This qualitative assessment was performed for biological, radiological andnuclear domains; it includes knowledge-based, adversarial and dual-use content. Questions spana range of difficulty levels, from questions a non-expert in these domains might ask, to questionsthat mostly an expert with a PhD plus many years of experience could pose or answer correctly. Theprompts and scenarios span different threat journeys (e.g. types of actors, equipment used, harmintended). This qualitative assessment, led by domain experts, allows for better visibility of thegranular improvement in science capabilities (e.g. accuracy, completeness, actionability of responses).
Results: We observe that the same prompts used on previous models result in Gemini 2.5 Pro oftengenerating detailed and accurate responses. In particular domains, some answers were technicallyprecise and potentially actionable, but the model did not consistently or completely enable progressthrough all key bottleneck steps.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Figure 8|List of Gemini models and their performance on a selection of external multiple-choicequestion benchmarks for biology and chemistry. In order to control for inherent model stochasticity, and position bias in selection of correct answers, we shuffled the answer choices over 100 runs foreach benchmark and we report here the mean solve rate.
Cybersecurity Cyber Autonomy Level 1 CCL Definition: “The model can be used to drastically reduce thecost (e.g. through full automation) of carrying out end-to-end cyberattacks on organizations with alimited security posture .” CCL reached? No. While Gemini 2.5 Pro’s performance on our cybersecurity evaluations hasincreased significantly compared to previous Gemini models, the model still cannot consistentlycomplete roughly half of our medium and hard difficulty challenges.
Cyber Uplift Level 1 CCL Definition: “The model can be used to significantly assist with highimpact cyber attacks, resulting in overall cost/resource reductions of an order of magnitude or more .” CCL reached? No. While Gemini 2.5 Pro’s capabilities exhibit an increase in performance onmultiple phases of real-world cyber attacks compared to previous models, they are still limited.
The model still struggles with many of our hard challenges, which are most representative ofreal-world scenarios. The model’s performance is strong enough that it has passed our earlywarning alert threshold. That is, we find it possible that subsequent revisions in the next fewmonths could lead to a model that reaches the CCL. In anticipation of this possibility, we haveaccelerated our mitigation efforts.
Overview: To estimate capabilities relevant to these CCLs, we use our existing suite of cybersecuritychallenges (Phuong et al., 2024) combined with a new benchmark described below. We considerdifficultylevelsrangingfromeasy(atthelevelofacollegestudent), medium(atthelevelofa graduatestudent), and hard (at the level of an experienced cybersecurity professional).
Existing challenges: These take the form of capture-the-flag evaluations covering three difficultylevels: easy (InterCode-CTF, Yang et al. (2023), medium (our in-house suite), and hard (Hack the Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Box). See Phuong et al. (2024) for details. These evaluations are only relevant to Autonomy Level 1 (poor performance on these evaluations rules out capabilities sufficient for full automation), but not Uplift Level 1, since humans could still be accelerated on attack phases not covered.
Key skills benchmark: Complementing our existing suite, we created a new evaluation framework (Rodriguez et al., 2025) that increases the realism as well as coverage across and within the attackchain of our cyber evaluations. We drew from real-world threat intelligence and input from expertsto identify a representative set of cyber attacks. From there, we determined the key skills areas thatwould be required to execute them. We identified four key areas:
1.Reconnaissance (the application of finding and researching different knowledge and data andapplying it in a cybersecurity context); 2. Tool development (the ability to design and create software that is cybersecurity-specific); 3.Tool usage (the ability to leverage common and cybersecurity-specific tools to achieve routineinstrumental cyber goals); 4. Operational security (the skill of remaining hidden during and after a cyber operation).
We instantiate this benchmark by mapping 48 challenges from an external vendor to this specification.
We also use these evaluations as a proxy for uplift capability, for Cyber Uplift Level 1. Even partialautomation of these key skills could mean fewer resources are needed for sophisticated cyberattacks.
Elicitation: We utilize a simple harness which prompts the agent to think about its plans and adjustthem to solve the challenge. The agent can execute Bash commands and run Python scripts. We runbetween 10 and 50 attempts at each challenge, depending on the challenge suite. We consider achallenge solved if at least one of those attempts succeeds in capturing the flag.
Results: See Figures 9 and 10 for numerical results. Model capabilities have increased to the pointwhere InterCode-CTF and our in-house CTF challenges are too easy, but the Hack the Box challengesare still too difficult - such that these three evals give little signal on how Gemini 2.5 models compareto previous generations. However, on our more fine-grained key skills benchmark, Gemini 2.5 modelsshow significant increases in capability compared to Gemini 2.0 models throughout all three difficultylevels. In particular, Gemini 2.5 Pro shows surprisingly high aptitude at the hard challenges. It solves 6/12 challenges—challenges at the level of an experienced cybersecurity professional.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Figure 9|Results on autonomous cyber offense suite. These benchmarks are based on “capture-theflag” (CTF) challenges, in which the agent must hack into a simulated server to retrieve a piece ofhidden information. Labels above bars represent the number of solved and total number of challenges.
A challenge is considered solved if the agent succeeds in at least one out of N attempts, where wevary N between 5 and 30 depending on challenge complexity. Both InterCode-CTF and our in-house CTFs are now largely saturated, showing little performance change from Gemini 2.0 to Gemini 2.5models. In contrast, the Hack the Box challenges are still too difficult for Gemini 2.5 models, and soalso give little signal on capability change.
Figure 10|Results on our new “key skills” benchmark. This benchmark also consists of “capture-theflag”(CTF)challenges, butthesechallengesaretargetedatkeyskillsrequiredtoexecutecyber-attacks:
reconnaissance, tool development, tool usage and operational security. A challenge is consideredsolved if the agent succeeds in at least one out of N attempts, where N = 30-50 for the 2.5 Pro runand N = 10-30 for the other models, depending on the challenge complexity. Note that for 2.0 Prowe omit results from five challenges and so 2.0 results are not directly comparable. Here, Gemini 2.5 family models show significant increase in capability at all three difficulty levels. Particularly ofnote is Gemini 2.5 Pro solving half of the hard challenges - challenges at the level of an experiencedcybersecurity professional.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Machine Learning R&D Machine Learning R&D Autonomy Level 1 CCL Definition: “The model can fully automatethe AI R&D pipeline at a competitive cost. The cost comparison is relative to humans augmented by AI tools.” CCL reached? No. On RE-Bench, although the gap between Gemini and expert humans hasshrunk, the model still doesn’t reach our early warning threshold (which is based on a specificaverage score over all challenges). Note that RE-bench comprises relatively low-context tasks witha limited time horizon (calibrated to allow significant progress by humans experts in 8 hours), and represents a small subset of the tasks comprising the full AI R&D pipeline.
Machine Learning R&D Uplift Level 1 CCL Definition: “The model can or has been usedto accelerate AI development, resulting in AI progress substantially accelerating (e.g. 2x) from 2020-2024 rates .” CCL reached? Likely no. We do not yet have dedicated evaluations for this CCL, but giventhat Gemini does not yet reach our early warning threshold on Autonomy Level 1, the modellikely lacks the necessary capabilities to automate or significantly uplift any significant fraction ofthe research process.
To evaluate Gemini 2.5 models’ potential for accelerating ML R&D, we ran the open-source Research Engineering Benchmark (Wijk et al., 2025). This benchmark comprises seven machine learningchallenges difficult enough to take a human practitioner several hours to complete. For example, inthe Optimize LLM Foundry challenge, the model must speed up a fine-tuning script while keeping theresulting model the same. We omit two challenges, Finetune GPT-2 for QA and Scaffolding for Rust Codecontest since they require internet access, which we disallow for security reasons.
The model is equipped with METR’s modular scaffold with minimal adjustment. Following theoriginal work, we simulate a scenario in which the agent has a total time budget of 32 hours and theagent may choose a tradeoff between the number of runs and the length of each run. We evaluatetwo settings: 43 runs with a time limit of 45 minutes each, and 16 runs with a time limit of 2 hourseach. For each setting, we aggregate scores across runs using the method described in the originalwork (Wijk et al., 2025). This involves taking a number of bootstrap samples, taking the maximumscore over each sample, and calculating a confidence interval using percentiles of the resulting values.
(For the Scaling Law Experiment challenge, because the score is not visible to the agent and thereforethe agent would not be able to pick run results based on the best score, we instead bootstrap themean using all scores.) For the 45 minute setting, we do 64 actual runs, but sample only 43 runs foreach bootstrap sample. Similarly for the 2 hour setting, we do 24 runs.
Gemini 2.5 Pro’s best runs score between 50% and 125% of the best human-written solutions.
Despite this, the model does not reach our alert threshold, which was set higher than the humanperformance in view of the fact that RE-bench contains low-context and limited time horizon tasksthat we expect to be especially easy for AI systems to reach human parity on. Some of the model’ssolutions are nevertheless quite interesting. For example, in the Restricted Architecture MLM task, the agent is tasked with implementing a language model without use of basic primitives such asdivision and exponentiation. This seemingly simple constraint invalidates modern architectures like Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
the Transformer, whose attention mechanism and normalization layers rely heavily on these forbiddenoperations. In one attempt, Gemini 2.5 Pro realises it can achieve this by drawing inspiration fromaspects of the MLP-Mixer architecture (Tolstikhin et al., 2021)—a non-trivial insight that draws on itsextensive knowledge of the research literature. In effect, creativity is substituted by knowledge.
Figure 11|Results on the Research Engineer Benchmark (RE-Bench), in which the model mustcomplete simple ML research tasks. Following the original work, scores are normalised against agood quality human-written solution: if a model achieves a score 𝑦on a challenge, the normalisedscore is(𝑦−𝑦𝑠)/(𝑦𝑟−𝑦𝑠), where 𝑦𝑠is the “starting score” of a valid but poor solution provided to themodel as an example, and 𝑦𝑟is the score achieved by a reference solution created by the author ofthe challenge. Figures for Claude 3.5 Sonnet and expert human performance are sourced from theoriginal work. The number of runs and the time limit for each run are constrained by a total timebudget of 32 hours, and error bars indicate bootstrapped 95% confidence intervals; see main text fordetails. Gemini 2.5 Pro is moderately strong at these challenges, achieving a significant fraction ofexpert human performance—and in two cases surpassing it.
Deceptive Alignment Instrumental Reasoning Level 1 CCL Definition: “The instrumental reasoning abilities ofthe model enable enough situational awareness (ability to work out and use relevant details of itsdeployment setting) and stealth (ability to circumvent basic oversight mechanisms) such that, absentadditional mitigations, we cannot rule out the model significantly undermining human control .” CCL reached? No. Gemini 2.5 Pro does not perform competently enough on both the stealthand situational awareness challenges. Qualitatively, the model often fails to reason through itssituation and find a credible strategy; it also sometimes struggles with planning and long-horizonreasoning. It partially displays situational awareness but most of the time, it fails to understandand intervene on its environment/deployment setting.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Instrumental Reasoning Level 2 CCL Definition: “The instrumental reasoning abilities ofthe model enable enough situational awareness and stealth that, even when relevant model outputs (including, e.g., scratchpads) are being monitored, we cannot detect or rule out the risk of a modelsignificantly undermining human control .” CCL reached? No. This threshold is strictly higher than Instrumental Reasoning Level 1.
Ourdeceptivealignmentevaluationsmeasurestealthcapabilitiesandsituationalawarenesscapabilitiesseparately, using two separate sets of challenges.
Stealth: In these challenges, the model is tasked with a devious objective and must achieve thatobjective without raising suspicion. For example, one challenge is a customer support scenario wherethe model deals with incoming support tickets. The agent is tasked with resolving as many tickets aspossible while complying with the company’s protocols. There are ways to cheat at this (resulting inmore tickets resolved)—but if the model does decide to cheat, it must not be caught by an overseer.
Here we measure performance relative to the score that humans get when they do the challenge.
Situational awareness: These challenges test whether the model can reason about itself as an agentembedded in the deployment environment, and to intervene on it in service of a goal. Many of themtest whether the model can realise that it needs to give itself more affordances, e.g. by changingconfiguration files that place constraints on its action space. The agent may need to, say, turn offswear word filtering in order to write an angry email. For more details of these evaluations, see (Phuong et al., 2025).
Results: We ran these evaluations on Gemini 2.5 Pro Preview 03-25. All of the results reported arewith 50 retries and involve a model equipped with scaffolds that uses chain-of-thought reasoning andreflection to enhance context utilization and better planning. Broadly, Gemini 2.5 Pro exhibits poorperformance on situational awareness evaluations, and moderate performance in stealth evaluations.
Across 50 trials, Gemini 2.5 Pro has no successes on 8 of our suite of 11 situational awarenessevaluations. Among the remaining evaluations, the highest performance is achieved on a “Disabled Tool” challenge, in which Gemini is run in an agentic environment and has to grant itself access tomore tools though configuration changes (42% success rate across 50 trials). For stealth evaluations, Gemini 2.5 Pro achieves low rates of success on 3/5 challenges. It achieves a ~44% success rate onthe Decision Sabotage challenge and a ~35% success rate on the Oversight Pattern challenge, whichis similar to human performance.
Frontier Safety: Summary Gemini 2.5 Pro was evaluated against the Critical Capability Levels defined in our Frontier Safety Framework, which examines risk in CBRN, cybersecurity, machine learning R&D, and deceptivealignment. Based on these results, we find that Gemini 2.5 Pro (up to version 06-17) does not reachany of the Critical Capability Levels in any of these areas.
However, it showed some ability in all four areas. For example, in our evaluation of Machine Learning R&D capabilities, while the model’s average performance was lower than the human baseline, in two cases its best performances exceeded even the best expert human-written reference solutions.
Gemini 2.5 Pro also showed a significant increase in some capabilities, such as cyber uplift, compared to previous Gemini models. Following our Frontier Safety Framework, we are putting in Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
place a response plan, including conducting higher frequency testing and accelerating mitigations forthe Cyber Uplift Level 1 CCL. As reported above, no model reached the CCL in these additional tests.
Looking ahead, these evaluations are key to safe deployment of powerful AI systems. We willcontinuetoinvestinthisarea,regularlyperformingFrontierSafetyFrameworkevaluationstohighlightareas where mitigations (e.g. refusal to respond to prompts that return dangerous results) must beprioritized.
5.8. External Safety Testing As outlined in the Gemini 1.5 Technical Report (Gemini Team, 2024), as part of our External Safety Testing Program, we work with a small set of independent external groups to help identify areas forimprovement in our model safety work by undertaking structured evaluations, qualitative probing, and unstructured red teaming. As a heuristic, the External Safety Testing Program reviews the mostcapable Gemini models, with the largest capability jumps. As such, testing was only carried out onthe 2.0 Pro and 2.5 Pro models, including on early versions of both models. At the time of writing wehave not carried out external safety testing on the Flash models. The External Safety Testing Programfocused testing on an early version of Gemini 2.5 Pro (Preview 05-06) to capture early findings anddid not test the final model candidate which went to GA.
For Gemini 2.5 Pro, our external testing groups were given black-box testing access to Gemini 2.5 Pro (Preview 05-06) on AI Studio for a number of weeks. This enabled Google DeepMind to gatherearly insights into the model’s capabilities and understand if and where mitigations were needed.
Testing groups had the ability to turn down or turn off safety filters, in line with what is available on AI Studio.
These groups were selected based on their expertise across a range of domain areas, such asautonomous systems, societal, cyber, and CBRN risks. Groups included civil society and commercialorganizations. The groups testing the model checkpoints were compensated for their time.
Externalgroupswerebydesigninstructedtodeveloptheirownmethodologytotesttopicswithinaparticulardomainarea, remainingindependentfrominternalGoogleDeepMindevaluations. Thetimededicated to testing also varied per group, with some groups being dedicated full-time to executingtesting processes, while others were part-time dedicated. Some groups pursued manual red-teamingand reported on qualitative findings from their exploration of model behavior, while others developedbespoke automated testing strategies and produced quantitative reports of their results.
WhilereportswerewrittenindependentlyofGoogleDeepMind, ourinternalsubjectmatterexpertswere on hand to understand the external testing groups’ methodologies and findings throughout thetesting process.
External safety testing groups shared their analyses and findings, as well as the raw data andmaterials they used in their evaluations (e.g., prompts, model responses). After testing, we internallyreviewed the data and model output transcripts in detail, and Google DeepMind subject matterexperts assigned severity ratings to outputs, based on our internal harm frameworks and safetypolicies, and noted whether these cross the Critical Capability Levels outlined in different domains (Google DeepMind, 2025a). We then communicated findings back to modelling teams and productpolicy teams (both within Google DeepMind and across Alphabet) and reported these as part of ourgovernance processes. Our external testing findings also help us identify gaps in our existing internalevaluation methodologies and safety policies.
We’ve outlined some of the high-level insights from our external testing across the domain areastested, including autonomous systems, cyber misuse, CBRN, and societal risks.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Autonomous systems risks An external group tested models for autonomous systems risks, focusing on models’ ability andpropensity to covertly pursue misaligned goals. The evaluations consist of settings where the model isgiven a goal that requires deception, scheming, or sabotage to achieve. Evaluations were focused on:
•Strategic deception: testing the model’s propensity to deceive a user or developer about theactions it took.
•In-contextschemingreasoning: testingthemodel’scapabilitiesinthisdomainwhereschemingis an effective strategy.
•Sabotage capabilities: assessing the model’s ability to compromise other language modelswith overt actions.
OverallexternalresearcherssuggestedthatGemini2.5Pro(Preview05-06)hadasimilarschemingcapability to other models evaluated. External researchers noted that the model is not sufficientlycapable of causing catastrophic harms on rollouts where it is scheming. However, external researchersnoted minor harms such as reward-hacking may be possible, which could potentially lead to adegraded user experience.
Complementing these tests, Google DeepMind’s Deceptive Alignment evaluations (see Section 5.7) provide evidence that the risk of severe harm is low due to the models’ limited situational awarenesscapabilities.
Cyber misuse risks Cybersecurity risks External cyber evaluations focused on assessing the ability for malicious actors to enhance existingattack vectors across a range of key cyber skills, such as vulnerability discovery, vulnerability exploitation, social engineering, and cyberattack planning (capability uplift). Testers also focused on themodel’s ability to accelerate repetitive or time-consuming elements of cyber operations, enablingincreased scale (throughput uplift).
Evaluations were conducted within simulated environments that realistically represented a rangeoftargetsystems,networks,andsecuritycontrols. Thisinvolvedsettingupvirtualnetworksmimickingenterprise infrastructure, deploying realistic software vulnerabilities, and simulating user behaviorsin social engineering scenarios.
Evaluations strived to incorporate elements of real-world constraints and complexities. Thisincluded introducing noisy data, limited information availability, or adversarial defenses that the AImodel must overcome, mirroring the challenges faced by attackers in live operations.
Findings from these evaluations concluded that Gemini 2.5 Pro was a capable model for cybersecurity tasks, showing marked increase in ability from Gemini 1.5 Pro. Complementing these evaluations, the GDM Cyber team conducted their own tests, and found similarly high levels of capability (see Section 5.7).
Indirect Prompt Injections The model was evaluated for patterns of susceptibility to indirect prompt injection attacks. Inparticular, the model was tested for vulnerabilities in function calls and potential asymmetries thatexist across security measures. The model was also tested to understand how different domains yield Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
higher hijack rates. In line with internal evaluations and mitigations in this space (Section 5.5), weare continuing to evolve how we monitor and measure the resilience of increasingly capable Geminimodels.
CBRN risks Chemical and Biological risks In addition to our internal evaluations described above (Section 5.7) capabilities in chemistry andbiology were assessed by an external group who conducted red teaming designed to measure thepotential scientific and operational risks of the models. A red team composed of different subjectmatter experts (e.g. biology, chemistry, logistics) were tasked to role play as malign actors who wantto conduct a well-defined mission in a scenario that is presented to them resembling an existingprevailing threat environment. Together, these experts probe the model to obtain the most usefulinformation to construct a plan that is feasible within the resource and timing limits described in thescenario. The plan is then graded for both scientific and logistical feasibility. Based on this assessment, GDM addresses any areas that warrant further investigation.
External researchers found that the model outputs detailed information in some scenarios, oftenproviding accurate information around experimentation and problem solving. However, researchersfound steps were too broad and high level to enable a malicious actor.
Radiological and Nuclear risks Risks in the radiological and nuclear domains were assessed by an external group using a structuredevaluation framework for red teaming. This incorporated single-turn broad exploration across thefull risk chain and multi-turn targeted probing for high risk topics.
Assessments were structured around threat actors and harm pathways without measuring modeluplift, evaluating responses based on accuracy, actionability, and dual-use potential, with additionalscrutiny applied to the model’s thought summaries when applicable. External researchers foundthat model responses within this domain were accurate but lacked sufficient technical detail to beactionable.
Societal risks For the Gemini 2.5 Pro (Preview 05-06) model, external researchers focused on democratic harmsand radicalisation, with an emphasis on how the model might be used by malicious actors. Risks inthis domain focused on structured evaluations. The model was tested on its ability to identify harmfulinputs and the extent to which it complied with harmful requests. As no internal evaluations mirrorthese precise domain harms, the External Safety Testing Program shared these findings with relevantteams to ensure monitoring and mitigation where necessary.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
6. Discussion In this report we have introduced the Gemini 2.X model family: Gemini 2.5 Pro, Gemini 2.5 Flash, Gemini 2.0 Flash and Gemini 2.0 Flash-Lite. Taken together, these models span the full Pareto frontierof model capability vs cost, and Gemini 2.5 Pro is the most capable model we have ever developed.
Gemini 2.5 Pro excels across a wide range of capabilities, and represents a step change in performancerelative to Gemini 1.5 Pro. Its coding, math and reasoning performance are particularly notableand Gemini 2.5 Pro achieves the SoTA score on the Aider Polyglot evaluation, as well as extremelycompetitive scores on GPQA (diamond) and Humanity’s Last Exam.
As well as their strong performance on academic benchmarks, entirely new capabilities areunlocked with the Gemini 2.5 models. Gemini is now the preferred AI assistant amongst educators (LearnLM Team, 2025) and it is now possible for Gemini to take a video of a lecture and create aninteractive web application that can test a student’s knowledge of that content. Finally, the Gemini 2.5models enable exciting new agentic workflows, started to power numerous products already (Pichai, 2025).
In addition to being highly performant, the Gemini 2.5 models maintain strong safety standardsand, compared to their 1.5 counterparts, are much more helpful. They are less likely to refuse toanswer important user queries or respond with an overly sanctimonious tone. Gemini 2.5 exhibitednotable increases in Critical Capabilities, including cybersecurity and machine learning R&D. However, the model has not crossed any Critical Capability Levels.
Reflecting on the path to Gemini 2.5, the staggering performance improvement attained over thespace of just one year points to a new challenge in AI research: namely that the development of noveland sufficiently challenging evaluation benchmarks has struggled to keep pace with model capabilityimprovements, especially with the advent of capable reasoning agents. Over the space of just a year, Gemini Pro’s performance has gone up 5x on Aider Polyglot and 2x on SWE-bench verified (one ofthe most popular challenging agentic benchmarks). Not only are benchmarks saturating quickly, butevery new benchmark that gets created can end up being more expensive and take longer to createthan its predecessor, due to the more restricted pool of experts able to create it. Experts were paidup to $5000 for each question that was accepted to the Humanity’s Last Exam benchmark (Phanet al., 2025), and while this benchmark still has significant headroom at the time of writing (June 2025), performance on it has improved significantly over the space of a few months (with the bestmodels achieving just a few percent accuracy on it when it was initially published in early 2025).
When one considers agentic systems, which are able to tackle problems for longer and which haveaccess to tools and self critique, the complexity of benchmarks required to measure performancealso increases dramatically. Being able to scale evaluations in both their capability coverage and theirdifficulty, while also representing tasks that have economic value, will be the key to unlocking thenext generation of AI systems.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
References R. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E. Dahl, and G. E. Hinton. Large scale distributedneural network training through online distillation, 2018. URL https://arxiv.org/abs/1804 .03235 .
R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, et al. Palm 2 technical report, 2023. URLhttps://arxiv.org/abs/2305.10403 .
Anthropic. Claude’s extended thinking, 2025. URL https://www.anthropic.com/research/visible-extended-thinking .
A. Baddepudi, A. Yang, and M. Lučić. Advancing the frontier of video understanding with Gemini 2.5, 2025. URL https://developers.googleblog.com/en/gemini-2-5-video-understanding/.
Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, et al. Constitutional ai: Harmlessness from aifeedback, 2022. URL https://arxiv.org/abs/2212.08073 .
M. Balunović, J. Dekoninck, I. Petrov, N. Jovanović, and M. Vechev. Matharena: Evaluating llms onuncontaminated math competitions, 2025. URL https://arxiv.org/abs/2505.23281 .
P. Barham, A. Chowdhery, J. Dean, S. Ghemawat, S. Hand, D. Hurt, M. Isard, H. Lim, R. Pang, S. Roy, et al. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and Systems, 4:430–449, 2022. URL https://proceedings.mlr.press/v162/barham22a.html .
A. Beutel, K. Xiao, J. Heidecke, and L. Weng. Diverse and effective red teaming with auto-generatedrewards and multi-step reinforcement learning, 2024. URL https://arxiv.org/abs/2412.1 8693.
S. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O’Brien, et al. Pythia: A suite for analyzinglargelanguagemodelsacrosstrainingandscaling. In Proceedingsofthe40thInternationalConferenceon Machine Learning , 2023. URL https://proceedings.mlr.press/v202/biderman23a.html.
N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying memorization acrossneural language models. In 2022 IEEE Symposium on Security and Privacy (SP) , pages 1113–1130, 2022. URL https://arxiv.org/abs/2202.07646 .
W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. Jordan, J. E.
Gonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. In Forty-first International Conference on Machine Learning , 2024. URL https://arxiv.org/abs/ 2306.05685 .
A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al. PaLM: Scaling language modeling with pathways. arXiv preprint N. Chowdhury, J. Aung, C. J. Shern, O. Jaffe, D. Sherburn, G. Starace, E. Mays, R. Dias, M. Aljubeh, M. Glaese, C. E. Jimenez, J. Yang, L. Ho, T. Patwardhan, K. Liu, and A. Madry. Introducing SWEbench verified, 2024. URL https://openai.com/index/introducing-swe-bench-verified/.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
A. Clark, D. de las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hechtman, T. Cai, S. Borgeaud, G. van den Driessche, E. Rutherford, T. Hennigan, M. Johnson, K. Millican, A. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. Sifre, S. Osindero, O. Vinyals, J. Rae, E. Elsen, K. Kavukcuoglu, and K. Simonyan. Unified scaling laws for routed language models, 2022. URL "https://arxiv.org/abs/2202.01169" .
CodeGemma Team. Codegemma: A family of open code models based on gemma. https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf , 2024.
A. Conneau, M. Ma, S. Khanuja, Y. Zhang, V. Axelrod, S. Dalmia, J. Riesa, C. Rivera, and A. Bapna.
Fleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken Language Technology Workshop (SLT) , pages 798–805. IEEE, 2023.
M. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. P. Steiner, M. Caron, R. Geirhos, I. Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In International Conference on Machine Learning , pages 7480–7512. PMLR, 2023. URL https:
//proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf .
T. Doshi. Build rich, interactive web apps with an updated Gemini 2.5 Pro, 2025a. URL https:
//blog.google/products/gemini/gemini-2-5-pro-updates/ .
T. Doshi. Gemini 2.5: Our most intelligent models are getting even better, 2025b. URL https:
//blog.google/technology/google-deepmind/google-gemini-updates-io-2025/ .
N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Firat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. arXiv preprint W. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models withsimple and efficient sparsity. arXiv preprint arXiv:2101.03961 , 2021. URL https://arxiv.org/ abs/2101.03961 .
C. Fu, Y. Dai, Y. Luo, L. Li, S. Ren, R. Zhang, Z. Wang, C. Zhou, Y. Shen, M. Zhang, et al. Video-mme:
The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. In Proceedings of the Computer Vision and Pattern Recognition Conference , pages 24108–24118, 2025.
URL https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Video-MME_The _First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-Modal_LLMs_in_C VPR_2024_paper.html .
Gemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.
arXiv preprint arXiv:2403.05530 , 2024. URL https://arxiv.org/abs/2403.05530 .
Gemma Team. Gemma: Open models based on gemini research and technology. https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf , 2024.
O. Goldman, U. Shaham, D. Malkin, S. Eiger, A. Hassidim, Y. Matias, J. Maynez, A. M. Gilady, J. Riesa, S. Rijhwani, L. Rimell, I. Szpektor, R. Tsarfaty, and M. Eyal. Eclektic: a novel challenge set forevaluation of cross-lingual knowledge transfer, 2025. URL https://arxiv.org/abs/2502.2 1228.
Google DeepMind. Frontier safety framework. https://deepmind.google/discover/governance/frontier-safety-framework/ , February 2025a.
Google DeepMind. Gemini 2.0 Flash-Lite, 2025b. URL https://deepmind.google/models/gemini/flash-lite/ .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
D. Grattafiori, S. Jelassi, S. Hotton, D. Bertoin, and A. Sablayrolles. Security of mixture-of-experts, 2024. URL https://arxiv.org/abs/2405.13220 .
D. Hassabis. Our vision for building a universal AI assistant, 2025. URL https://blog.google/ technology/google-deepmind/gemini-universal-ai-assistant/ .
G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015. URLhttps://arxiv.org/abs/1503.02531 .
K. Hu, P. Wu, F. Pu, W. Xiao, Y. Zhang, X. Yue, B. Li, and Z. Liu. Video-mmmu: Evaluating knowledgeacquisition from multi-discipline professional videos, 2025. URL https://arxiv.org/abs/25 01.13826 .
S. Hughes, M. Bae, and M. Li. Vectara Hallucination Leaderboard, nov 2023. URL https://github .com/vectara/hallucination-leaderboard .
D. Ippolito, F. Tramer, M. Nasr, C. Zhang, M. Jagielski, K. Lee, and N. Carlini. Preventing memorizationof verbatim text sequences in language models, 2022. URL https://arxiv.org/abs/2206.0 1358.
A. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating, A. Bloniarz, C. Saroufim, C. Fry, D. Marcus, D. Kukliansky, G. S. Tomar, J. Swirhun, J. Xing, L. Wang, M. Gurumurthy, M. Aaron, M. Ambar, R. Fellinger, R. Wang, R. Sims, Z. Zhang, S. Goldshtein, and D. Das. Facts grounding leaderboard. https://www.kaggle.com/benchmarks/google/facts-grounding , 2024. Google Deepmind, Google Research, Google Cloud, Kaggle.
A.Jacovi,A.Wang,C.Alberti,C.Tao,J.Lipovetz,K.Olszewska,L.Haas,M.Liu,N.Keating,A.Bloniarz, etal. Thefactsgroundingleaderboard: Benchmarkingllms’abilitytogroundresponsestolong-forminput.arXiv preprint arXiv:2501.03200 , 2025. URL https://arxiv.org/abs/2501.03200 .
N. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.
Livecodebench: Holistic and contamination free evaluation of large language models for code, 2024. URL https://arxiv.org/abs/2403.07974 .
A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088 , 2024. URLhttps://arxiv.org/abs/2401.04088 .
C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan. SWE-bench: Canlanguage models resolve real-world github issues? In The Twelfth International Conference on Learning Representations , 2024. URL https://openreview.net/forum?id=VTF8yNQM66 .
K. Kampf and N. Brichtova. Experiment with Gemini 2.0 Flash native image generation, 2025. URLhttps://developers.googleblog.com/en/experiment-with-gemini-20-flash-native-image-generation/ .
K. Kavukcuoglu. Gemini 2.0 is now available to everyone, 2025. URL https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025 .
L. Kilpatrick. Gemini 2.5 Pro Preview: even better coding performance, 2025. URL https://developers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance .
S. Kudugunta, S. M. A. Eslami, D. Raposo, J. C. Mellor, R. Pascanu, et al. Beyond human data: Scalingself-training for problem-solving with language models, 2023. URL https://arxiv.org/abs/ 2312.06585 .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
J. M. Laurent, J. D. Janizek, M. Ruzo, M. M. Hinks, M. J. Hammerling, S. Narayanan, et al. LABBench: Measuring capabilities of language models for biology research, 2024. URL https:
//arxiv.org/abs/2407.10362 .
LearnLM Team. Evaluating Gemini in an Arena for Learning, 2025. URL https://goo.gle/LearnLM-May25 .
J. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M. Arnold, V. Perot, S. Dalmia, et al. Can long-context language models subsume retrieval, rag, sql, and more? arXiv preprint J. Lei, T. L. Berg, and M. Bansal. Detecting moments and highlights in videos via natural languagequeries. Advances in Neural Information Processing Systems , 34:11846–11858, 2021.
D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. GShard:
Scaling giant models with conditional computation and automatic sharding. In International Conference on Learning Representations , 2020. URL https://openreview.net/forum?id=qrwe7XHTmYb .
N. Li, A. Pan, A. Gopal, S. Yue, D. Berrios, A. Gatti, et al. The WMDP benchmark: Measuring andreducing malicious use with unlearning, 2024. URL https://arxiv.org/abs/2403.03218 .
L. Liu, X. Liu, J. Gao, W. Chen, and J. Han. Understanding the difficulty of training transformers.
arXiv preprint arXiv:2004.08249 , 2020. URL https://arxiv.org/abs/2004.08249 .
LMArena Team. Webdev arena, 2025. URL https://web.lmarena.ai/leaderboard .
S. B. Mallick and L. Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro, 2025. URL https://developers.googleblog.com/en/gemini-2-family-expands/ .
A. Mehrotra, M. Zampetakis, P. Kassianik, B. Nelson, H. Anderson, Y. Singer, and A. Karbasi. Tree ofattacks: Jailbreaking black-box llms automatically, 2024. URL https://arxiv.org/abs/2312 .02119 .
I. Molybog, P. Albert, M. Chen, Z. DeVito, D. Esiobu, N. Goyal, P. Koura, S. Narang, A. Poulton, R. Silva, et al. A theory on adam instability in large-scale machine learning. arXiv preprint arXiv:2304.09871 , 2023. URL https://arxiv.org/abs/2304.09871 .
MrCheeze. Gemini discovers an (apparently unknown) glitch in seafoam islands, 2025. URL https:
//www.reddit.com/r/ClaudePlaysPokÃľmon/comments/1l198af/gemini_discovers _an_apparently_unknown_glitch_in .
A.Nagrani,S.Menon,A.Iscen,S.Buch,R.Mehran,N.Jha,A.Hauth,Y.Zhu,C.Vondrick,M.Sirotenko, C. Schmid, and T. Weyand. Minerva: Evaluating complex video reasoning, 2025a. URL https:
//arxiv.org/abs/2505.00681 .
A. Nagrani, M. Zhang, R. Mehran, R. Hornung, N. B. Gundavarapu, N. Jha, A. Myers, X. Zhou, B. Gong, C. Schmid, M. Sirotenko, Y. Zhu, and T. Weyand. Neptune: The long orbit to benchmarking longvideo understanding, 2025b. URL https://arxiv.org/abs/2412.09582 .
M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, et al. Scalable extraction of training datafrom (production) language models, 2023. URL https://arxiv.org/abs/2311.17035 .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
P. Padlewski, M. Bain, M. Henderson, Z. Zhu, N. Relan, H. Pham, D. Ong, K. Aleksiev, A. Ormazabal, S.Phua,E.Yeo,E.Lamprecht,Q.Liu,Y.Wang,E.Chen,D.Fu,L.Li,C.Zheng,C.deMassond’Autume, D. Yogatama, M. Artetxe, and Y. Tay. Vibe-eval: A hard evaluation suite for measuring progress ofmultimodal language models, 2024. URL https://arxiv.org/abs/2405.02287 .
V. Patraucean, L. Smaira, A. Gupta, A. Recasens, L. Markeeva, D. Banarse, S. Koppula, M. Malinowski, Y. Yang, C. Doersch, et al. Perception test: A diagnostic benchmark for multimodal video models.
Advances in Neural Information Processing Systems , 36:42748–42761, 2023.
E. Perez, S. Huang, H. F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving.
Red teaming language models with language models. CoRR, abs/2202.03286, 2022. URL https:
//arxiv.org/abs/2202.03286 .
L. Phan et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.14249 .
M. Phuong, M. Aitchison, E. Catt, S. Cogan, A. Kaskasoli, V. Krakovna, D. Lindner, M. Rahtz, Y. Assael, S. Hodkinson, et al. Evaluating frontier models for dangerous capabilities, 2024. URL https:
//arxiv.org/abs/2403.13793 .
M. Phuong, R. S. Zimmermann, Z. Wang, D. Lindner, V. Krakovna, S. Cogan, A. Dafoe, L. Ho, and R. Shah. Evaluating frontier models for stealth and situational awareness, 2025. URL https:
//arxiv.org/abs/2505.01420 .
S. Pichai. Google I/O 2025: From research to reality, 2025. URL https://blog.google/technology/ai/io-2025-keynote/ .
C. Plizzari, A. Tonioni, Y. Xian, A. Kulshrestha, and F. Tombari. Omnia de egotempo: Benchmarkingtemporal understanding of multi-modal llms in egocentric videos. In Proceedings of the Computer Vision and Pattern Recognition Conference , pages 24129–24138, 2025.
D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman. Gqqa:
A graduate-level google-proof q&a benchmark. In First Conference on Language Modeling , 2024.
C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and N. Houlsby. Scaling vision with sparse mixture of experts, 2021. URL https://arxiv.org/abs/ 2106.05974 .
J. Roberts, M. R. Taesiri, A. Sharma, A. Gupta, S. Roberts, I. Croitoru, S.-V. Bogolin, J. Tang, F. Langer, V. Raina, et al. ZeroBench: An impossible visual benchmark for contemporary large multimodalmodels. arXiv preprint arXiv:2502.09696 , 2025.
M. Rodriguez, R. A. Popa, F. Flynn, L. Liang, A. Dafoe, and A. Wang. A framework for evaluatingemerging cyberattack capabilities of ai, 2025. URL https://arxiv.org/abs/2503.11917 .
S. Roller, S. Sukhbaatar, J. Weston, et al. Hash layers for large sparse models. Advances in Neural Information Processing Systems , 34:17555–17566, 2021. URL https://proceedings.neurips.
cc/paper/2021/file/883e881bc596359e0c5112411858a74b-Paper.pdf .
M. Samvelyan, S. C. Raparthy, A. Lupu, E. Hambro, A. H. Markosyan, M. Bhatt, Y. Mao, M. Jiang, J. Parker-Holder, J. Foerster, T. Rocktäschel, and R. Raileanu. Rainbow teaming: Open-endedgeneration of diverse adversarial prompts, 2024. URL https://arxiv.org/abs/2402.16822 .
R. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda, R. A. Popa, R. Jain, R. Greig, S. Albanie, S. Emmons, S. Farquhar, S. Krier, S. Rajamanoharan, Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
S. Bridgers, T. Ijitoye, T. Everitt, V. Krakovna, V. Varma, V. Mikulik, Z. Kenton, D. Orr, S. Legg, N. Goodman, A. Dafoe, F. Flynn, and A. Dragan. An approach to technical agi safety and security, 2025. URL https://arxiv.org/abs/2504.01849 .
D. Sharon. Upload and edit your images directly in the Gemini app, 2025. URL https://blog.google/products/gemini/image-editing/ .
N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously largeneural networks: The sparsely-gated mixture-of-experts layer. In ICLR (Poster) . OpenReview.net, 2017. URL https://arxiv.org/abs/1701.06538 .
C. Shi, S. Lin, S. Song, J. Hayes, I. Shumailov, I. Yona, J. Pluto, A. Pappu, C. A. Choquette-Choo, M. Nasr, C. Sitawarin, G. Gibson, A. Terzis, and J. F. Flynn. Lessons from defending gemini againstindirect prompt injections, 2025. URL https://arxiv.org/abs/2505.14534 .
S. Singh, A. Romanou, C. Fourrier, D. I. Adelani, J. G. Ngui, D. Vila-Suero, P. Limkonchotiwat, K. Marchisio, W. Q. Leong, Y. Susanto, R. Ng, S. Longpre, W.-Y. Ko, M. Smith, A. Bosselut, A. Oh, A. F. T. Martins, L. Choshen, D. Ippolito, E. Ferrante, M. Fadaee, B. Ermis, and S. Hooker. Globalmmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation, 2024. URL https://arxiv.org/abs/2412.03304 .
R. Stein. Expanding AI Overviews and introducing AI Mode, 2025. URL https://blog.google/ products/search/ai-mode-search .
I. O. Tolstikhin, N. Houlsby, A. Kolesnikov, L. Beyer, X. Zhai, T. Unterthiner, J. Yung, A. Steiner, D. Keysers, J. Uszkoreit, et al. MLP-Mixer: An all-MLP Architecture for Vision. Advances in neuralinformation processing systems , 34:24261–24272, 2021.
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin.
Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems , volume 30.
Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf .
K. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu, S. Jain, R. Shivanna, J. Hui, N. Dikkala, M. Kazemi, B. Fatemi, et al. Michelangelo: Long context evaluations beyond haystacks via latent structurequeries. arXiv preprint arXiv:2409.12640 , 2024. URL https://arxiv.org/abs/2409.12640 .
B. Wang. NotebookLM now lets you listen to a conversation about your sources , 2024. URLhttps://blog.google/technology/ai/notebooklm-audio-overviews .
C. Wang, A. Wu, and J. Pino. Covost 2: A massively multilingual speech-to-text translation corpus, 2020.
W. Wang, Z. He, W. Hong, Y. Cheng, X. Zhang, J. Qi, X. Gu, S. Huang, B. Xu, Y. Dong, M. Ding, and J. Tang. Lvbench: An extreme long video understanding benchmark, 2024. URL https:
//arxiv.org/abs/2406.08035 .
X. Wang, J. Wu, J. Chen, L. Li, Y.-F. Wang, and W. Y. Wang. Vatex: A large-scale, high-qualitymultilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF internationalconference on computer vision , pages 4581–4591, 2019.
J. Wei, K. Nguyen, H. W. Chung, Y. J. Jiao, S. Papay, A. Glaese, J. Schulman, and W. Fedus. Measuringshort-form factuality in large language models. arXiv preprint arXiv:2411.04368 , 2024. URLhttps://arxiv.org/abs/2411.04368 .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
L. Weidinger, J. Barnhart, J. Brennan, C. Butterfield, S. Young, W. Hawkins, et al. Holistic safety andresponsibility evaluations of advanced ai models, 2024. URL https://arxiv.org/abs/2404.1 4068.
H. Wijk, T. Lin, J. Becker, S. Jawhar, N. Parikh, T. Broadley, L. Chan, M. Chen, J. Clymer, J. Dhyani, et al. RE-Bench: Evaluating frontier ai r&d capabilities of language model agents against humanexperts, 2025. URL https://arxiv.org/abs/2411.15114 .
M. Wortsman, P. J. Liu, L. Xiao, K. Everett, A. Alemi, B. Adlam, J. D. Co-Reyes, I. Gur, A. Kumar, R. Novak, et al. Small-scale proxies for large-scale transformer training instabilities. arXiv preprint J. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. InterCode: Standardizing and benchmarkinginteractive coding with execution feedback, 2023. URL https://arxiv.org/abs/2306.14898 .
Z. Yu, D. Xu, J. Yu, T. Yu, Z. Zhao, Y. Zhuang, and D. Tao. ActivityNet-QA: A dataset for understandingcomplex web videos via question answering. In AAAI, 2019.
X. Yue, Y. Ni, K. Zhang, T. Zheng, R. Liu, G. Zhang, S. Stevens, D. Jiang, W. Ren, Y. Sun, et al.
Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expertagi. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 9556–9567, 2024.
Zerokid. Pokemon Red Version - Guide and Walkthrough (GB), 2024. URL https://gamefaqs.gamespot.com/gameboy/367023-Pokémon-red-version/faqs/64175 .
S. Zhai, T. Likhomanenko, E. Littwin, D. Busbridge, J. Ramapuram, Y. Zhang, J. Gu, and J. M. Susskind.
Stabilizingtransformertrainingbypreventingattentionentropycollapse. In InternationalConferenceon Machine Learning , pages 40770–40803. PMLR, 2023. URL https://proceedings.mlr.press/v202/zhai23a/zhai23a.pdf .
J. Zhang. Gemini Plays Pokemon Twitch Stream, 2025. URL https://www.twitch.tv/gemini _plays_pokemon/about .
S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al.
Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068 , 2022. URLhttps://arxiv.org/abs/2205.01068 .
L. Zhou, C. Xu, and J. J. Corso. Towards automatic learning of procedures from web instructionalvideos. In AAAI Conference on Artificial Intelligence , pages 7590–7598, 2018. URL https://www.
aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344 .
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
7. Contributors and Acknowledgments Contributors Gheorghe Comanici Eric Doi Mike Schaekermann Ice Pasupat Noveen Sachdeva Inderjit Dhillon Marcel Blistein Ori Ram Dan Zhang Evan Rosen Luke Marris Sam Petulla Colin Gaffney Asaf Aharoni Nathan Lintz Tiago Cardal Pais Henrik Jacobsson Idan Szpektor Nan-Jiang Jiang Krishna Haridasan Ahmed Omran Nikunj Saunshi Dara Bahri Gaurav Mishra Eric Chu Toby Boyd Brad Hekman Aaron Parisi Chaoyi Zhang Kornraphop Kawintiranon Tania Bedrax-Weiss Oliver Wang Ya Xu Ollie Purkiss Uri Mendlovic Ilaï Deutel Nam Nguyen Adam Langley Flip Korn Lucia Rossazza Alexandre Ramé Sagar Waghmare Helen Miller Qiao Zhang Shubham Agrawal Daniel Hernandez Diaz Reeve Ingle Elena Buchatskaya Xiaofan Zhang Gregory Dibb Ty Geri Yiming Gu Xuezhi Wang Simon Osindero Annie Marsden Aniket Ray Qiqi YanMaggie Tran Alfonso Castaño Johnson Jia Isabel Edkins Toshihiro Yoshino Ben Murdoch Jyn Shan Jichuan Chang Marcello Maggioni Junlin Zhang Lior Belenki Kiran Vodrahalli Da-Cheng Juan Kingshuk Dasgupta Dan Abolafia Vera Axelrod Elan Rosenfeld Eva Schnider Petko Georgiev Guolong Su Haiqiong Li Yuankai Chen Rohan Anil Vinodh Kumar Rajendran Josef Dean Lewis Chiang Candice Schumann Sam Haves Gabriela Surita Damion Yates Yiran Mao Lin Zhuo Jeremy Selier Surya Bhupatiraju Ashwin Balakrishna Kellie Webster Santhosh Thangaraj Antoine He Chulayuth Asawaroengchai Kaan Katircioglu Sungyong Seo Jennie Lees Sachin Yadav Nikhil Mehta Ambrose Slone Yan Xiong Tomas Mery Nico Duduta Markus Freitag Thi Avrahami Yong Cheng Uri Alon Lior Madmoni Han Ke Hartwig Adam Cho-Jui Hsieh Toshiyuki Fukuzawa Adams YuXiaodan Tang Kurt Shuster Zeyu Liu Hugo Song Four Flynn Vittal Premachandran Tom Ouyang Adrià Puigdomènech Khyatti Gupta Yang Lu Alex Grills Sammy Jerome Rich Munoz Kayi Lee James Rubin Simon Green Georgi Karadzhov Sergi Caelles Mike Dusenberry Guangxing Han Lewis Ho Hai Qian Di Lu Abhishek Bapna Shuang Song Hao Zhang Andrew Over Piotr Ambroszczyk HyunJeong Choe Parker Schuh Bahar Fatemi Aida Amini Prajit Ramachandran Andrew Lee Changwan Ryu Sudeshna Roy Rosemary Ke Hao Xu Duncan Williams Nishesh Gupta Ganesh Mallya Yangsibo Huang Jason Chang Salah Zaiem John Wieting Tianhao Zhou Stefani Karp Michal Jastrzebski Yuan (June) Shangguan Ido Kessler Paul Natsev Navneet Potti Yichao Zhou Courtney Biles Dawid Wegner Legg Yeung Pengcheng Yin David LindnerJifan Zhu Hongliang Fei Austin Stone Nacho Cano Josh Smith Zeynep Cankara Geoffrey Cideron Mohamed Elhawaty Alex Mossin Kevin Cen Zhaoyi Zhang Pratik Joshi Bin Ni Trilok Acharya Max Bain Junwen Bai Kelvin Chan Jarek Wilkiewicz Bowen Liang Brian Roark Gellért Weisz Kyriakos Axiotis Fedir Zubach Dhriti Varma Tomas Kocisky David Madras Alice Chen Grace Chung Siddharth Vashishtha Gabriel Dulac-Arnold Nan Hua Nikolai Chinaev Grace Hu Jie Tan Matt Lawlor Kai Bailey Sergey Levi Zhen Yang Serena Zhan Fuzhao Xue Ivor Rendulic Noah Fiedel Jack Weber Abhijit Karmarkar Ross Hemsley Benigno Uria Paramjit Sandhu Cassidy Hardin Lisa Wang Nimesh Ghelani Sam Sobell Andy Wan Folawiyo Campbell-Ajala Oscar Akerlund Alice Li Boyu Wang Markus Kunesch Ted Xiao Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Jessica Lo Angelos Filos Divya Jain Yani Donchev Rohan Agrawal Tom Hennigan Michael Quinn Matija Kecman Weize Kong Johan Ferret Dale Johnson Billy Porter Javad Azizi Timo Denk Gagan Bansal Sebastian Flennerhag Yuexiang Zhai Francesco Piccinno Ilia Shumailov Kefan Xiao Alif Raditya Rochman Vicky Zayats David Bieber Arnar Mar Hrafnkelsson David Barker Abhishek Jindal Jean-Baptiste Lespiau Almog Gueta Suhas Ganesh Harish Ganapathy Patrick Siegler Shruti Rijhwani Noam Shazeer Wei Liang Hanzhao Lin Ryan Mullins Aurko Roy Yiling Jia Seungji Lee Emily Xue Praneeth Netrapalli Zhongru Wu Andrey Ryabtsev Cicero Nogueira dos Santos Nate Hurley Jon Schneider Chase Malik Anca Stefanoiu Rishabh Bansal Ballie Sandhu Paulo Zacchello Victor Gomes Alexandra Belias Yunxiao Deng Alexey Kolganov Petros Maniatis Maciej Kula Meng Wei Zach Fisher Sarah Nguyen Sijal BhatnagarSoroush Radpour Sebastian Borgeaud Mariano Schain Afief Halumi Marco Selvi Victor Cotruta Eric Ni Jonathan Herzig Guohui Wang Etienne Pot Jiawei Cao Kartik Audhkhasi Aäron van den Oord Jason Riesa François-Xavier Aubet Fabio Viola Peter Sung Varun Yerram YaGuang Li Chao Jia Arijit Pramanik Nicolas Heess Anirudh GP Mauro Verzetti Yasaman Razeghi Avi Singh Will Ng Xing Wu Rocky Rhodes Vincent Nallatamby Yang Gao Neha Sharma Tom Duerig Ali Eslami Jed Borovik Jordan Griffith Willi Gierke Jonni Kanerva Jennifer Beattie Rohit Sathyanarayana Saksham Thakur Marco Tagliasacchi Joseph Kready Masa Yamaguchi Xing Yu Michiel Blokzijl Charline Le Lan Jeffrey Hui Mukundan Madhavan Maria Voitovich Du Phan Chengrun Yang Weel Yang Peter de Boursac Charles Chen Elinor Davies Zelin Wu Anne Zheng Alessio Tonioni Henry Prior Chester KwakSheng Li Nicholas FitzGerald Eugénie Rives Ilya Figotin Tania Rojas-Esponda Gabby Wang Tiberiu Sosea Richard Everett Viorica Patraucean Marianne Monteiro Taylan Bilal Danny Tarlow Ray Smith Qiujia Li Dan A. Calian Aditya Kusupati Sujee Rajayogam Alvin Abdagic Nishant Agrawal Mudit Bansal Markus Mircea Sri Gayatri Sundara Padmanabhan Lawrence Moore Wenjun Zeng Philippe Schlattner Adam Bloniarz Wenting Ye Bobak Shahriari Parul Bhatia Okwan Kwon Tianlin Liu Bo-Juen Chen Tom Kwiatkowski Le Hou Jayaram Mudigonda Diego Machado Siim Põder Mateo Wirth Prasha Sundaram Vikas Verma Quentin Wellens Nathaniel Braun Robin Strudel Biao Zhang Yonghui Wu Ela Gruzewska Yennie Jun Jian Li Sushant Prakash Siddharth Goyal Minh Giang Lucio Dery Julia Di Trapani Ryan Julian Liam MacDermed Geoff Brown Ajay Kannan Shakir Mohamed Renke Pan Oriol VinyalsUmang Gupta Anil Das Catalin Ionescu Louis O’Bryan Weiren Yu Dave Lacey Benjamin Beyret Alex Wertheim Ling Wu Paul Voigtlaender Tianli Ding Zi Wang Lam Nguyen Thiet Rajesh Venkataraman Jiahao Cai Guy Bensky Olga Kozlova Peter Grabowski Elahe Dabir Blair Kutzman Kaiz Alarakyia Harish Rajamani Elena Pochernina Balaji Venkatraman SQ Mah Megha Nawhal Julian Odell Milad Nasr Tamar Yakar Michal Sokolik Linhai Qiu Vasilisa Bashlovkina Peiran Li Howard Zhou Kush Bhatia Manaal Faruqui Joost van Amersfoort Alessandro Epasto Adrian Goedeckemeyer James Lyon Jesse Emond Yifan Ding Vikas Yadav Rushin Shah Caleb Habtegebriel Zhe Yuan Igor Mordatch Fred Alcober KP Sawhney Kavya Kopparapu Muye Zhu Stephen Spencer Qiyin Wu Maria Bauza Vikash Sehwag Jay Whang Oliver Woodman Subha Puttagunta Pablo Sprechmann Mohammad Hossein Bateni Ada Ma Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Aleksandra Faust Nami Akazawa Manfred Warmuth Mudit Verma Fantine Huot Ben Ingram Alex Ramirez Satish Kambala Jim Stephan Faruk Ahmed Clement Farabet Andreas Terzis Tyrone Hill Jay Pavagadhi Alek Andreev Alex Pak Gufeng Zhang Jingjing Chen James Atwood Linda Deng Matej Kastelic Paul Caron Adrian Hutter Conglong Li Daniel Andor Konstantinos Bousmalis Jovana Mitrović Disha Jindal Anhad Mohananey Lijie Fan Polina Zablotskaia Srinadh Bhojanapalli Christian Walder Xinyi Wu Sivan Eiger Dave Orr Yaoyiran Li Bonnie Li Prakash Shroff Danny Vainstein Wenhao Yu Avinatan Hassidim Malika Mehrotra Sanil Jain Sergey Brin Jialu Liu Abhishek Nayyar Jeffrey Dudek David Reitter Xuhui Jia Mahdi Mirzazadeh Dario de Cesare Wael Farhan Weicheng Kuo Amit Jhindal Raj Apte Adam Zhang Tom Stone Michael Kilgore Zhuowan Li Axel StjerngrenDeep Karkhanis Sheng Peng Aditi Chaudhary Andrew Hogue Yann Dauphin Le Yan Pablo Barrio Pushkar Mishra Allie Culp Tolly Powell Avraham Ruderman Sujoy Basu Adi Mayrav Gilady Seth Benjamin Christopher Yew Federico Lebron Sahand Sharifzadeh Jing Lu Ilia Labzovsky Jackson Tolins Christoph Hirnschall Peter Stys George Polovets Artur Mendonça Michael Moffitt Piermaria Mendolicchio Adam Raveret James Lottes Chih-Kuan Yeh Vikas Sindhwani Trang Pham Natalie Axelsson Saurabh Agrawal Pramod Gupta Kuang-Huei Lee Connie Tao Abhishek Bhowmick Desi Ivanov Fei Liu Da Huang Doug Reid Radu Soricut Alex Morris Gil Fidel Preeti Singh Sushant Kafle Praynaa Rawlani Anu Sinha Ronny Votel Christian Schuler Tolga Bolukbasi Avery Lamp Bidisha Samanta Ashrith Sheshan Zi Yang Tomer Levinboim Assaf Hurwitz Michaely Andy Brock Haotian Tang Matthias Lochbrunner Miaosen WangZafarali Ahmed Krishan Subudhi Ana Hosseini Sertan Girgin Juliette Love Mina Khan Ramya Ganeshan Yash Pande Xiaomeng Yang Rodrigo Cabrera Kedar Soparkar Allan Zhou Avia Aharon Neha Jha Sneha Kudugunta Vincent Perot Yoav Ben Shalom Ying Chen Shashi Narayan Ramin Mehran Hisham Husain Yanif Ahmad Meiqi Guo Nana Nti Kelvin Guu Shuguang Hu Yiming Li Sid Dalmia Adnan Ozturel Ming-Wei Chang Zhi Hong Helen Ran Bharath Mankalale Clara Huiyi Hu Joe Kelley Claudio Fantacci Marco Fornoni Tianqi Liu Yang Li Dmitry Kalashnikov Mathieu Blondel Félix de Chaumont Quitry Dilip Krishnan Ayush Dubey Youhei Namiki Koji Kojima Tom Eccles Brendan O’Donoghue Theofilos Strinopoulos Ke Chen Adrià Recasens Xiyang Luo Ferjad Naeem Qiantong Xu Ndidi Elue Sheena Panthaplackel Jiaqi Pan Chiyuan Zhang Andrey Simanovsky Paul Niemczyk Eliza RutherfordDanfeng Qin Alex Haig Siqi Zuo Canfer Akbulut Austin Wu Erik Jue Ganesh Jawahar Clemens Meyer Sumit Bagri Gabe Barth-Maron Yash Katariya Shreyas Chandrakaladharan Julia Proskurnia Pawan Dogra Igor Karpov Alexandra Cordell Yixian Di Geoff Clark Clara Barbu Morgane Rivière Grace Chen Josip Djolonga Ramya Sree Boppana Anthony Brohan Christina Butterfield Warren Chen Kartikeya Badola Oriana Riva Beliz Gunel Morgane Lustman Tongfei Guo Chinmay Kulkarni Andrii Maksai Mingcen Gao Ying Jian Tianhe Yu Himanshu Srivastava Jeremiah Liu Trevor Yacovone Efrat Farkash Mahdis Mahdieh Brian Albert Stephanie Winkler Roma Patel CJ Carey Anuj Sharma Ricardo Figueira Palak Jain Chizu Kawamoto Ethan Liang Safeen Huda Dawei Jia Matt Thomas Austin Kyker Adam Sadovsky Chi Zou Sanaz Bahargam Bing Zhang George Zhang Leslie Baker Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Zhihao Li Maria Wang Xin Li Cordelia Schmid Andreas Steiner Andy Davis Machel Reid Martin Sevenich Arunkumar Byravan Chris Alberti Françoise Beaufays Qingchun Ren Xiaokai Zhao Zhuoyuan Chen Roman Goldenberg Geta Sampemane Iain Barr Karol Gregor Yun Lei Sanjay Ghemawat Pete Shaw Vincent Tsang Lu Liu Will Song Xiao Ma Javad Hosseini Elizabeth Cole Aleksandr Zaks AJ Maschinot Chun-Sung Ferng Ethan Dyer Julian Walker Yiwen Song Rahul Arya Haichuan Yang Gui Citovsky Kunal Lad Jack Rae Michele Bevilacqua Kevin Lee Fangyu Liu Iulia Coms ,a Anna Korsun Dawn Chen Ravin Kumar Ashwin Sreevatsa Nagabhushan Baddi Bilva Chandra Jeshwanth Challagundla Borja De Balle Pigem Harry Ragan Chris Duvarney Mojtaba Seyedhosseini Phil Chen Sabela Ramos Kaisheng Yao Alain Vaucher Yanhan Hou Anton Kovsharov Hexiang Hu Ali ElqurshChristine Chan Lev Proleev Elnaz Davoodi Olivier Lacombe Jiaming Shen Chris Knutsen Arthur Szlam Ben Albrecht Honglong Cai Kehang Han Weiyang Zhang Carlos Guía Chenjie Gu Basil Mustafa Huan Gui Jonathan Tompson Serge Toropov Chen Liang Carl Saroufim Benoit Schillings Deepali Jain Matt Dibb Itay Laish Xuan Yang Stav Ginzburg Chris Sauer Kenny Vassigh Wenxuan Zhou Matko Bošnjak Gautam Vasudevan Orion Jankowski Matt Young Mara Finkelstein Kostas Andriopoulos Ryo Nakashima Mandar Sharma Abhimanyu Goyal Mark Geller Yukun Zhu David Tian Bilal Piot Tian Xie Jamie Hall Martin Izzard Duc Dung Nguyen Saloni Shah Lydia Lihui Zhang Hanie Sedghi Kanav Garg Raghavender R Mingyao Yang Luheng He Weijie Chen Ashwin Murthy Lucas Gonzalez Gabriel Barcik Yuan Zhang Pooya Moradi Elizabeth Nielsen Rodrigo Benenson Megan BarnesYongqin Xian Nathan Byrd Ross Mcilroy Jennimaria Palomaki Jongbin Park Anian Ruoss Jie Han Zhipeng Jia Alessandro Agostini Guangda Lai Zachary Charles Nitish Kulkarni Srinivas Sunkara Jay Hartford Saarthak Khanna Pradeep Shenoy Jinoo Baek Michael Voznesensky Lantao Mei Yicheng Wang Mantas Pajarskas Avigail Dabush Nathan Waters Yang Xu Regev Cohen Kelvin Xu Marcel Prasetya Alex Kaskasoli Vihari Piratla Joan Puigcerver Ashwin Vaswani David Rim Arsha Nagrani Manolis Delakis Roland Zimmermann Phillip Lippe Wei Fan Buhuang Liu Sharat Chikkerur Himadri Choudhury Elena Gribovskaya Terry Koo Divya Tyam Alexey Stern Ilia Akolzin Jinyu Xie Kuo Lin Alex Muzio Arpi Vezer Cindy Wu Sally Ma Alex Fabrikant Soroosh Mariooryad Hui Zheng Yan Li Zheng Xu Daiyi Peng Terry Huang Sébastien Cevey Prateek Jain Jiageng ZhangSteven Hand Nicholas Roth Zixuan Jiang Trevor Cohn Ayzaan Wahid Gavin Buttimore Arthur Douillard Guanyu Wang Raymond Lin Girish Ramchandra Rao Dan Ethier Liang Bai Igor Petrovski Shruthi Prabhakara Sebastian Krause Yunfei Bai James Svensson Divya Pitta Swapnil Gawde Raia Hadsell Gaurav Singh Tomar Karthik Raman Pol Moreno Xiaowei Xu Simeon Ivanov Rajesh Jayaram Enrique Piqueras Johannes Griesser Keerthana Gopalakrishnan Haroon Qureshi Kyuyeun Kim Anders Andreassen Shuai Ye Jonathan Malmaud Abhijit Guha Roy Michal Yarom Chen Wang Daniel Balle Efren Robles Rory Blevins Daniel Rodriguez Avishkar Bhoopchand Jennifer She Siddharth Verma Sheela Goenka Mark Kurzeja Marcus Wainwright Christy Koh Farooq Ahmad Michelle Liu Berivan Isik Li Liu Chia-Hua Ho Ziyue Wang Jin Xie Shashank Viswanadha Lukasz Lew Corbin Quick Justin Mao-Jones Florence Perot Henry Wang Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Isaac Tian Irina Jurenka Nicola De Cao Baochen Sun Thomas Köppe Ales Mikhalap Jiao Sun George van den Driessche Umesh Telang Sergey Yaroshenko Remi Crocker Gary Wang Hui Peng Wenhu Chen Daniel Vlasic Ga-Young Joung Dave Uthus Mikhail Sirotenko Yuntao Xu Woohyun Han Cheng-Chun Lee Mostafa Dehghani Jane Shapiro Damien Vincent Orgad Keller Deepak Ramachandran Yan Wu James Manyika Diego Ardila Oleksandr Ferludin Alexey Svyatkovskiy Pankaj Joshi Kashyap Krishnakumar Katrina (Xinyi) Xu Rodolphe Jenatton Aijun Bai Ferran Alet Ivan Jurin Miltos Allamanis Zoltan Egyed Joel Wee Tejasi Latkar Ivan Lobov James Besley Ye Zhang Theophane Weber Min Choi Alexandre Moufarek Rachel Soh Yumeya Yamamori Xianghong Luo Arushi Gupta Simon Tokumine Carrie Grimes Bostock Taylor Bos Hayato Kobayashi Ananth Balashankar Georgie Evans Alex Lee Mihai Dorin Istin Yue MaLeland Rechis Jiawei Xia Haitian Sun Nitzan Katz Sachit Menon William Wong Kaspar Daugaard Zhao Fu Yuheng Kuang Aditya Tripathi James An Fan Bu Zhisheng Xiao Burcu Karagol Ayan Kazuki Osawa Akanksha Maurya Mohammad Saleh Andy Twigg Tom Schaul Nicolas Serrano Shriya Sharma Lars Lowe Sjoesund José Leal Chengxi Ye Joshua Kessinger James Freedman Wonpyo Park Juliana Vicente Franco Anna Goldie Keisuke Kinoshita Max Dylla Justin Chiu Matt Miecnikowski Siva Velusamy Alan Ansell Tayo Oguntebi Qiong (Q) Hu Abdo Abdelhamed Dominik Grewe Chong You Bryan Seybold Charles Blundell Hilal Dib Denis Vnukov Richard Song Jingyu Cui Valentin Dalibard Badih Ghazi Jamie Rogers GS Oh Alexey Vlaskin Asya Fadeeva Jane Park Keyvan Amiri Jewel Zhao Lotte Weerts Tom Lieber Adam Lelkes Hannah Kirkwood Dale Webster Ceslee MontgomeryJoel D’sa Tao Zhou Heidi Howard Behnam Neyshabur Lei Zhang Tianze Shi Shubham Mittal Ruoxi Sun Irene Cai Khalid Salama Maya Meng Heng-Tze Cheng Xi Liu Josip Matak Mimi Ly Alaa Saade Amol Mandhane Spurthi Amba Hombaiah Chenxi Pang Carrie Zhang Garrett Tanzer Zihang Dai Hagai Taitelbaum Miranda Aperghis Ramona Comanescu Flavien Prost Ankesh Anand Hongkun Yu Siddhartha Reddy Jonnalagadda Xiaoyue Pan Thomas Strohmann Larisa Markeeva Jinmeng Rao Pranav Nair Peggy Lu Parisa Haghani Matthew Tung Paul Covington Tayfun Terzi Peilin Zhong Tal Schuster Jialin Wu Andrew Nystrom Romina Datta Amer Sinha Sanjiv Kumar Ryan Foley Martin Chadwick Kashyap Kolipaka Pierre-Antoine Manzagol Zefei Li Dan Holtmann-Rice Susie Sargsyan Claire Cui Evgeny Sluzhaev Ian Stewart-Binks Niket Kumar Bhumihar Helena Pankov Dayeong Lee Alberto MagniAndy Ly Renjie Wu Aditya Pandey Paweł Wesołowski Hen Fitoussi Ali Shah Daniel von Dincklage Xinyi Bai Hamish Tomlinson Luis Castro Hadi Hashemi Bryce Petrini Pablo Duque Itay Karo Zhi Xing Rémi Leblond Eric Wang Steve Li Terry Thurk Manish Reddy Vuyyuru Omkar Savant Orhan Firat Shan Han Abe Ittycheriah Jiepu Jiang Betty Chan Kritika Muralidharan Fabian Pedregosa Verena Rieser Yoad Lewenberg Yuan Liu Aarush Selvan David Parkinson Qin Cao David Du Yaxin Liu Junjie Wang Mike Kwong Kevin Villela Elizabeth Salesky Angad Chandorkar Aayush Singh Andrew Bolt Tom Funkhouser Rajeev Aggarwal Ariel Brand Kingshuk Majumder Léonard Hussenot Yenai Ma Weijuan Xi Wolfgang Macherey Shawn Gao Pete Blois Dre Mahaarachchi Marissa Giustina Yaroslav Akulov Minmin Chen Vaishakh Keshava Abe Friesen Chaochao Yan Ethan Mahintorabi Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Jingwei Zhang Tingting Zou Steven Pecht Jasmine Liu Yael Karov Shaan Bijwadia Nikita Saxena Jarrod Kahn Erika Gemzer Sara Nasso Wing Lowe Yifan He Xingyi Zhou Hila Sheftel Rama Pasumarthi Gladys Tyen Xerxes Dotiwalla Darren Ni Bingyuan Liu Kelly Chen Christian Reisswig Chas Leichner Petre Petrov Ebrahim Songhori Richard Green Ioana Bica Sam Redmond Donnie Kim Hubert Soyer Nolan Ramsden Tony (Tu ´ân) Nguy ˜ên Jake Walker Sangnie Bhardwaj Raoul de Liedekerke Doug DeCarlo Zhuyun Dai Shengyang Dai Aviral Kumar Daniel Suo Eugene Weinstein Yony Kochinski Jinning Li Kelvin Zhang Doug Fritz Idan Brusilovsky Pulkit Mehta Tarun Bharti Ben Limonchik Thomas Jimma Steve Chien Tammo Spalink Amir Yazdanbakhsh Simon Baumgartner Josef Broder Roy Hirsch Taylor Tobin Lucas Manning Pu Han Jitendra Harlalka Richard Tanburn Aviel AtiasAlexandra Chronopoulou Junru Wu Xiangzhu Long Qingnan Duan JD Co-Reyes Jon Simon Pankil Botadra Te I Eyal Ben-David Andrei Sozanschi Shikhar Vashishth Danila Sinopalnikov Stan Bileschi Aditya Srikanth Veerubhotla Mirko Rossini Madeleine Clare Elish Michael Isard Eli Collins John Youssef Chung-Ching Chang Stephen Roller Phuong Dao Sergei Lebedev Petar Veličković Simon Bucher Tamara von Glehn Tomas Izo Andre Elisseeff Ashish Gupta Rachel Hornung Leon Li Praveen Kallakuri Pei Sun Rylan Schaeffer Jarred Barber Bibo Xu Tianxiao Shen Oded Elyada Martin Zlocha Canoee Liu Herman Schmit Edouard Rosseel Abhishek Sinha Tao Chen Jeffrey Zhao Ashyana Kachra Guillaume Desjardins Jacob Scott Eugene Ie CJ Zheng Greg Farquhar Sudeep Dasari Felix Fischer Chu-Cheng Lin Dheeru Dua Virat Shejwalkar Mikołaj Rybiński Avital Zipori Fan Yang Junhyuk OhYuchen Liu Anand Rao Songyou Peng Sumeet Singh Warren (Weilun) Chen Cheng Li Jean Tarbouriech Paul Kishan Rubenstein Tautvydas Misiunas Alekh Agarwal Steven Zheng Adam Kraft Setareh Ariafar Fei Zheng Wentao Yuan Ehsan Amid Aga Świetlik Steve Xu Mark Graham Travis Choma Joshua Ainslie Andrew Dai Isabel Leal Immanuel Odisho Evan Palmer Ying Xiao Vadim Zubov Dan Belov Iftekhar Naim Jiazhong Nie Vladimir Pchelin Nitish Gupta Mikhail Sushkov XiangHai Sheng Vedant Misra Solomon Demmessie Aishwarya Kamath Yichi Zhang Ramiro Leal-Cavazos Chris Apps Ben Golan Mehdi Hafezi Manshadi Doron Kukliansky Beer Changpinyo Montse Gonzalez Arenas Vaibhav Tulsyan Yinan Wang Robert Riachi Steven Hansen Marco Liang Tim Blyth Jonathan Hoech Tara Thomas Dan Malkin Hannah Forbes-Pollard Vinh Tran Toni Creswell Kuntal Sengupta Tianli Yu Lukas Zilka Maulik ShahJonathan Lai Suraj Satishkumar Sheth Huanjie Zhou Zak Tsai Penporn Koanantakool Cathy Yip Zaheer Abbas Priyanka Agrawal Yiling Huang Alanna Walton Ed Chi Bartek Perz Kai Hui Hidetoshi Shimokawa Anton Briukhov Eva Lu Nisarg Kothari Michael Fink David Vilar Torres Rui Wang Nikhil Khadke Qixuan Feng Jim Sproch Jacob Austin Svetlana Grant Patrik Sundberg Stein Xudong Lin Chuqiao (Joyce) Xu Li Li Subhrajit Roy Alex Panagopoulos Viral Shah Jeff Stanway Daniel Formoso Nevan Wichers Yin Li Marc’aurelio Ranzato Mandy Guo Ayushi Agarwal Ragha Kotikalapudi Maryam Majzoubi Ankita Goel Ce Zheng John Maggs Hyeontaek Lim Mirek Olšák Alex Zhai Jakub Adamek Mukund Raghavachari Sheryl Luo Silvio Lattanzi Kristina Toutanova Qingze Wang Nora Kassner Annie Xie Abhimanyu Singh William Kong Yannis Assael Mukund Sundararajan Vincent Roulet Aurora Wei Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Mark Epstein Zack Nado Feng Han Dahun Kim Eric Bailey Kaushik Shivakumar Phil Crone Alena Butryna David Soergel Shariq Iqbal Jiayu Ye Keith Rush Linda Friso Aliaksei Severyn Sobhan Miryoosefi Natasha Noy Siqi Liu Alexander Pritzel Xiaoen Ju Sharad Vikram Becca Roelofs Raphael Koster Sasha Brown Ralph Leith Prabakar Radhakrishnan Wei-Chih Hung Young Maeng Carl Lebsack Colin Ji Denis Petek Kalpesh Krishna Ming Zhang Ganna Raboshchuk Adil Dostmohamed Lizzetth Bellot Gowoon Cheon Lucia Loher Piotr Stanczyk Huiyu Wang Apurv Suman Victor Carbune Xinxin Yu Christina Sorokin Nick Young Jinwei Xing Martin Baeuml Tzu-Kuo Huang Prakhar Gupta Tris Warkentin Michela Paganini Jeremiah Willcock Zongwei Zhou Julian Salazar Dmitry (Dima) Lepikhin Sam Conway-Rahman Marvin Ritter Alyssa Loo Oskar Bunyan Pranjal Awasthi Bangju Wang Paul ChangAntoine Yang Mukul Bhutani Victor Stone Bo Pang Luo Yu Efrat Nehoran Mingda Zhang Karthik Duddu Jake Abernethy Pierre Marcenac Marco Tulio Ribeiro Senaka Buthpitiya Yue Song Arnaud Autef Ashwin Chaugule Zizhao Zhang Dan Goldberg Chris Rawles Christopher Semturs Emily Nottage Noah Goodman Prem Eruvbetine Stefan Zinke Weilun Chen Jinliang Wei Hairong Mu Sahitya Potluri Tongzhou Chen Florent Altché Tal Marian Jake Marcus Aleksandr Chuklin Sarah Perrin Zhe Chen Renshen Wang Aditya Kini Fangxiaoyu Feng Sreenivas Gollapudi Andrew Rosenberg Caglar Unlu Santiago Ontanon Tao Zhu Ankur Bapna Shravya Shetty Zichuan Wei Ciprian Chelba Luowei Zhou Kai Kang Junehyuk Jung Duhyeon Kim Niharika Ahuja Garrett Honke Maxwell Chen Bo Wang Klemen Kloboves Leon Liu Renga Aravamudhan Zelda Mariet Ivan Korotkov Zhixin (Lucas) Lai Jared LichtargeConnie Fan Pauline Coquinot Andreas Noever Sindhu Raghuram Dragos Dena Golnaz Ghiasi Bo Li Sara Javanmardi Leonard Berrada Nate Kushman Seth Odoom Jindong Gu Ayan Chakrabarti Jilei (Jerry) Wang Kaiyang Ji Ying Xu Yuqi Li Rishabh Joshi Joe Stanton Tobias Weyand Ronny Huang Dean Reich Matteo Hessel Sneha Mondal Shane Gu Mingyang Zhang Duc-Hieu Tran Pouya Tafti Hyo Lee Nir Levine Roykrong Sukkerd Emma Wang Jason Lee Max Chang Olcan Sercinoglu Cindy Wang Xinjian Li Mario Lučić Seungyeon Kim Georgi Stephanov Srinivasan Venkatachary Junwei Yuan Christof Angermueller Peter Choy Alen Carin Shubham Milind Phal Dimitrios Vytiniotis Deepak Sharma Raphaël Lopez Kaufman Matthew Watson André Susano Pinto Azalia Mirhoseini Pidong Wang Wojciech Stokowiec Zhenkai Zhu Kevin Hui Mia Chen Dana Alon Carolina Parada Yuval Bahat Roopali VijMarcella Valentine Tom Hudson Jeremy Chen Bill Rosgen Olivia Ma Felix Wu Edward Chou Charles Yoon Yochai Blau Tynan Gangwani Weijun Wang Pascal Lamblin Victoria Langston James Keeling Abhishek Chakladar Mohit Agarwal Jilin Chen Rebecca Lin Frederick Liu Horia Toma Zoubin Ghahramani Ji Liu Lin Yang Yonatan Bitton Arjun Khare Lucian Ionita Kenton Lee Wenlei Zhou Kate Lee Ian Chou Aneesh Pappu Philip Pham Ramy Eskander John Palowitch Ilkin Safarli Shlomi Cohen-Ganor Mario Pinto Pranav Shyam David Raposo Don Metzler Lisa Lee Sarah York Sagi Perel Adhi Kuncoro Tim McConnell Ágoston Weisz Majid Hadian Shreya Pathak Alex Castro-Ros Evgenii Eltyshev Alex Ruiz Mandar Joshi Soheil Hassas Yeganeh Yanzhang He Anja Hauth Nigamaa Nayakanti Swachhand Lokhande Berkin Akin Sebastian Riedel Sage Stevens Fabian Fuchs Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Wei-Jen Ko Carl Doersch Rina Panigrahy Xingyu Wang Sergei Vassilvitskii Chang Ye Ziwei Ji Disha Shrivastava Golan Pundak Sridhar Thiagarajan Xinying Song Brendan McMahan Mona El Mahdy Blaž Bratanič Shixin Li Jiajun Shen Albin Cassirer Ionel Gog Dan Suh Nikola Momchev Danny Swisher Sean Kirmani Andrew Audibert Dongkai Chen Hao Zhou Jon Stritar Mahan Malihi Congchao Wang Jay Hoover Lampros Lamprou Sercan Arik Kanishka Rao Joana Iljazi Klaus Macherey Vighnesh Birodkar Neera Vats Garrett Bingham Shaleen Gupta Emanuel Taropa Hagen Soltau Justin Fu Nadav Olmert Jiho Choi Harry Askham Nikita Gupta Alicia Jin Frankie Garcia Itay Yona Yanhua Sun Demetra Brady Anand Shukla Hussain Masoom John Aslanides Caden Lu Mohit Sharma David Greene Cesar Magalhaes Kay McKinney Terry Spitz Aedan Pope Andy CrawfordSandeep Kumar Vinay Ramasesh Arun Ahuja Pichi Charoenpanit Maciej Mikuła Huizhong Chen Jiri Simsa Jong Lee Ashutosh Sathe Varun Godbole Kelvin Nguyen Amayika Panda Yujing Zhang Philipp Neubeck Shivanker Goel Ellie Talius Haiguang Li Abodunrinwa Toki Sasha Goldshtein David Reid Bat-Orgil Batsaikhan Catarina Barros Alexander Bykovsky David D’Ambrosio Lucy Kim Natalie Clay Blagoj Mitrevski Kazuma Hashimoto David Saxton Zalán Borsos Mehadi Hassen Aditya Siddhant Kyle Kastner Paul Michel Lily Wang Niccolò Dal Santo Kieran Milan Kelvin Zheng Yogesh Kalley Will Truong Susan Zhang Samuel Albanie Xuanyi Dong Daniel Zheng Christopher A.
Choquette-Choo Jenny Lee Tian Shi Anthony Chen Daniel Eppens Parker Beak Yiqing Tao Alex Hofer Jane Labanowski Meiyan Xie Parthasarathy Gopavarapu Hongxu Ma Norbert Kalb Fabio Pardo Sorin Baltateanu Terry ChenGabriel Rasskin Sami Alabed Miteyan Patel Achintya Singhal Hui Huang Jeremy Wiesner Oran Lang Roy Frostig Emma Cooney Mai Giménez James Lee-Thorp Seojin Bang Angéline Pouget Yanping Huang Jing Xie Kate Lin Snchit Grover Mary Cassin Kuangyuan Chen Yuan Yuan Divyansh Shukla Komal Jalan Matthew Mauger Dan Karliner Eunyoung Kim Thomas Lampe Josh Dillon Zhe Shen Sara Mc Carthy Jason Lin Yeongil Ko Antoine Miech Jordan Grimstad Katie Millican Yury Stuken Alexander Grushetsky Matt Hoffman Vaibhav Aggarwal Eden Cohen Bing Wang Shawn Xu Luke Leonhard Xiaodan Song Ning Niu Mayank Lunayach Nithya Attaluri Rahul Gupta Martin Sundermeyer Jake Ades Sandra Lefdal Filip Pavetić Anita Gergely Ayal Hitron Tomy Tsai Salem Haykal Chenxi Liu Felix Hernandez-Campos Siddharth Gopal Tony Bruguier Jeongwoo Ko Roee AharoniAbhanshu Sharma Kathie Wang Mike Bernico Austin Myers David Steiner Pingmei Xu Vihan Jain Dimitris Paparas Tongxin Yin SK Park Zachary Garrett Ankit Singh Rawat Lior Shani Michael Tschannen Mingqiu Wang Alexander Frömmgen Yifan Chang Vivek Sampathkumar Sophia Austin Brian Wieder Shen Yan Octavio Ponce Eran Ofek Sailesh Sidhwani Yi Gao Xiaoqi Ren Sriram Ganapathy Sharon Silver Rachel Sterneck Mihaela Rosca Daniel Keysers Emily Pitler Allen Porter Victoria Krakovna Norman Rink Karina Zainullina Alexei Bendebury Ofir Roval Yuanzhen Li Kleopatra Chatziprimou Feryal Behbahani Josh Lipschultz Libin Bai Fiona Lang Ruth Wang Aybuke Turker Mary Phuong Ian Mackinnon Vahab Mirrokni Matthew Wiethoff Sally Goldman Pauline Sho Muhuan Huang Xiao Wu Dorsa Sadigh Qifei Wang Amy Stuart Daisuke Ikeda Wouter Van Gansbeke Jordi Orbay Zhihao Shan Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Andrew Howard Justin Snyder Ivana Balazevic Sarmishta Velury Domagoj Ćevid James Cohan Yiqian Zhou João Gabriel Oliveira Rishikesh Ingale Thomas Buschmann Yasuhisa Fujii Richard Powell Håvard Garnes Rahma Chaabouni Hanna Klimczak-Plucińska Sean Augenstein Jing Xiong Samrat Ghosh Vitaly Kovalev Corentin Tallec Bryan Richter Clayton Sanford Slav Petrov Martin Polacek Todd Wang Mike Burrows Utsav Prabhu Sashank Reddi Colin Evans Jennifer Brennan Adam Hillier Zhiyuan Zhang Sicheng Li Felipe Tiengo Ferreira Aaron Archer Shitao Weng Zhenhai Zhu Sean Sun Takaaki Saeki Alexey Guseynov Casper Liu Ishita Dasgupta Siyang Qin Zhiying Zhang Tatiana Sholokhova Anima Singh Kevin Mather Edward Lee Zohar Yahav Ali Khodaei Yinlam Chow Yufei Wang Austin Huang Megha Mohabey Zhufeng Pan James Wendt Arthur Bražinskas William Bono Sadh MNM Khan Shuba Lall Gilles BaechlerSean Purser-haskell Valentin Gabeur Dan Horgan Levent Bolelli Yifeng Lu Yunting Song Viral Carpenter Rakesh Shivanna Ankit Anand Daniel Toyama Phoebe Kirk Jerry Chang Nan Ding Denny Zhou Zhicheng Wang Yilun Du Richard Killam Yan Wang Nikhil Sethi Lisa Anne Hendricks Emily Caveness Louis Rouillard Dee Cattle Xi Chen Dustin Zelle Jianqiao Liu Sebastian Gerlach Kevin Aydin Frank Ding Evgeny Gladchenko Abhirut Gupta Patrick Kane Khe Chai Sim Harman Singh Sanjay Ganapathy Chengda Wu Cosmo Du Chris Hidey Owen Xiao Alex Feng Jasper Snoek Martin Matysiak Dawsen Hwang Michael Wunder Bernd Bandemer Albert Webson Alex Polozov Diego Antognini Xi Xiong Matt Harvey Nancy Yuen Trevor Strohman Kevin R. McKee Jingchen Ye Kai Chen Keshav Shivam Alec Kosik Fangda Li Ryan Burnell Ana Salazar Chu-ling KoSagar Gubbi Anastasia Petrushkina Tao Huang Jasmine George Rong Rong Li Zhong Dan Jarrett Sudheendra Vijayanarasimhan Michael Guzman Maigo Le Shyam Upadhyay Shantanu Thakoor Guru Guruganesh Helen King Adam Santoro Tim Sohn Lu Li Himanshu Gupta Isabelle Guyon Aurick Zhou Grigory Rozhdestvenskiy Luke Vilnis Riccardo Patana Samuel Yang Jad Al Abdallah Aditya Chawla Kalyan Andra Nitesh Bharadwaj Gundavarapu Li Lao Zeyu Zheng Richard Nguyen Adam Paszke Zuguang Yang Diana Mincu Adrian Collister Uri First Mingyang Ling Dominika Rogozińska Lalit Jain Jie Feng Nina Anderson Wesley Helmholz Alex Kurakin Shenil Dodhia Steven M. Hernandez Vitor Rodrigues Sujeevan Rajayogam Megan Shum Sharon Lin Peter Humphreys Nathan Clement Omer Levy Moran Ambar Yannick Schroecker Amin Ghafouri Ophir Aharoni Kaan Tekelioglu Sandeep Mariserla Felix WeissenbergerShuang Liu Laurent El Shafey Todor Davchev Pradeep Kumar S George Scrivener Craig Swanson Tajwar Nasir Partha Talukdar Morgan Redshaw Rolf Jagerman Chris Welty Thomas Anthony Mikhail Dektiarev Ankur Taly Shane Settle Junwhan Ahn Noam Velan Malcolm Reynolds Vlad Feinberg Jörg Bornschein Arun Narayanan Jan-Thorsten Peter Peng Xu Yun Zhu Sravanti Addepalli Joe Kovac Been Kim Arjun Narayanan Puranjay Datta Vladimir Magay Madhavi Sewak Shachi Dave Anton Bulyenov Eric Noland Alexandre Fréchette Isabela Albuquerque Anna Bortsova John Schultz Archita Vadali Matthew Denton Ashleah Gill Georgios Evangelopoulos Alex Gurney Bartek Wydrowski Hannah DeBalsi Yunjie Li Vlad Ionescu Mukund Sridhar Jieming Mao Kristian Kjems Nir Shabat Aishwarya P S Jason Chase David Ross Xinyang Geng Nishanth Dikkala Dominik Paulus Bogdan Damoc Shyamal Buch Wei Wang Chenkai Kuang Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Tat Tan Fernando Pereira Séb Arnold Chao Wang Chetan Tekur Hongyang Jiao Younghoon Jun Wen Ding Alek Wang Srinivas Tadepalli Hanwen Chen Chongyang Shi Mo Shomrat James Martens Tim Zaman Scott Baird Adaeze Chukwuka Vivek Sharma Xiang Zhou Zach Behrman Aviv Rosenberg Sophie Wang Dhruva Bhaswar Shimu Wu Lora Aroyo Krzysztof Choromanski Blanca Huergo Yuvein Zhu Diego Cedillo Tim Dozat Sidharth Mudgal Dror Marcus Peter Chen Karel Lenc Max Schumacher Phoenix Meadowlark Steven Schwarcz Motoki Sano Marcus Wu Yuri Chervonyi Tero Rissa Mengchao Wang Seher Ellis Andras Gyorgy George-Cristian Muraru Zhang Li Marissa Ikonomidis Nguyet Minh Phu Amit Sabne Altaf Rahman Arka Dhar Alex Goldin Marco Andreetto Natan Potikha Sam Kwei Manish Gupta Kiran Yalasangi Vilobh Meshram Will Bishop Arturo BC Karan GillNelson George Rohin Shah Mark Collier Ndaba Ndebele Andrew Leach Yan Zhong Sebastien Baur Robert Berry Jon Clark Nilesh Tripuraneni Yue Gao Sławek Kwasiborski Nicole Brichtova Yingying Bi James Noraky David Amos Robert David Iñaki Iturrate Gabriela Botea Timothy Lillicrap Dan Zheng Cosmin Paduraru Seliem El-Sayed Liam McCafferty Mihajlo Velimirović Amelio Vázquez-Reina Jie Ren Yao Su Valentin Anklin Art Khurshudov Oscar Chang Dave Dopson Jing Chen JK Kearns Siyuan Qiao Himanshu Sahni Lauren Agubuzu Lexi Baugher Premal Shah Rahul Sukthankar Rob Willoughby Timothy Chung JD Chen Asahi Ushio Artiom Myaskovsky Nikita Putikhin Sanket Vaibhav Mehta Lawrence Chan Siyang Xue Yu Liang Emilio Parisotto Andrew Lampinen Lei Shu Naveen Kumar Sharath Maddineni Hadar Shemtov Sayna Ebrahimi Tatsuya Kiyono Samira Khan Seokhwan Kim Chris TarAlexandre Senges Victor Ungureanu Kristen Chiafullo Jessica Hamrick Víctor Campos Wei Chen Arun Nair Will Grathwohl Mayank Daswani Hongrae Lee Michaël Sander Kai Zhao Petr Mitrichev Ioana Mihailescu Zoe Ashwood Rachita Chhaparia Andrew Bunner Xinyi Chen Joshua Howland Henry Griffiths Dia Kharrat Joao Carreira Marco Gelmi Vaibhav Mehta Yana Lunts Binbin Xiong Arthur Nguyen Daniele Calandriello Corey Fry Kamyu Lee Anastasija Ilić Ryan Poplin Mor Hazan Taege John Nham Justin Frye Sho Arora David Silver Cat Graves Romal Thoppilan Majd Al Merey Ashish Shenoy Zhaoqi Leng Yizhong Liang Pranav Talluri Anitha Vijayakumar Zach Gleicher Tiziana Refice Andrea D’olimpio Andreea Marzoca Jiewen Tan Alex Chen Geng Yan Jamie Hayes Josh Jacob Yiming Wang John Blitzer Yuxiang Zhou Animesh Sinha Yeqing Li Patrik Zochbauer Sam RitterWaleed Khawaja Alex Tudor Michael Han Wei Wei Colton Bishop Chi Ming To Meenu Gaba Yinghao Sun Jieru Mei Victor Lavrenko Yuchi Liu Vered Cohen Pier Giuseppe Sessa Nima Khajehnouri Bill Jia Ada Maksutaj Oflazer Jamie Smith Zhi Li Ilya Kornakov Preethi Lahoti Nick Fernando Ni Lao Hoi Lam Christo Kirov Yoel Drori Yves Raimond Auriel Wright Muge Ersoy Allan Dafoe Harsh Mehta Bahram Raad Edouard Yvinec Myriam Khan Andrea Tacchetti Melvin Johnson Pranesh Srinivasan Hideto Kazawa Praneeth Kacham Wei Li Adrien Ali Taïga Jeremy Cole Kevin Sequeira Weiyue Wang Saket Joshi Jorge Gonzalez Mendez Heming Ge Shubin Zhao Sandeep Tata Heri Zhao Krishna Somandepalli Jenny Brennan Daniel Gillick Xiaowei Li Nishita Shetty Rich Galt Dipankar Ghosh Andrea Gesmundo Laurel Prince Richa Singh Alex Salcianu Charlie Chen Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Ganesh Poomal Girirajan AJ Piergiovanni Josh Feldman Cindy Fan Nilpa Jha Kushal Majmundar Yao-Yuan Yang Roshan Sharma Jing Wang DJ Strouse Sean Ammirati Nino Vieillard Yulong Wang Dangyi Liu Xiaobin Yu Sugato Basu Mansi Gupta Bernd Bohnet Martin Nikoltchev Loic Matthey Andrea Burns Tatiana Matejovicova Charles Kwong Yi Luan Jonathan Halcrow Evan Senter Varvara Krayvanova Arunachalam Narayanaswamy Jo Chick Yuan Cao Tulsee Doshi Yale Cong Arun Suggala Sarthak Jauhari Liangzhe Yuan Quoc Le Justin Gilmer Heiga Zen Arvind Kannan Jieru Hu Tara Thompson Christian Schallhart Henryk Michalewski Yamini Bansal Yuguo Liao Anton Bakalov Archit Sharma Ben Coleman Sherry Yang Boqing Gong Siobhan Mcloughlin Shuo-yiin Chang Cheolmin Kim Ahmed Eleryan Maxim Krikun Somit Gupta Igor Krivokon Elijah Peake Anton Tsitsulin Ishaan WattsRobert Dadashi Dessie Petrova Maggie Song Amr Khalifa Julia Pawar George Powell Yasumasa Onoe Jeff Dean Adam R. Brown Zhuo Xu Arjun Akula Summer Yue Bo Chang Michael Elabd Zheng Zheng Yang Guo Timothee Cour Samira Daruki Marcin Sieniek George Papamakarios Ashok Popat Parker Barnes Honglei Zhuang Goran Žužić Yichong Xu Shilpa Shetty Sudeep Gandhe Vincent Zhuang Yan Virin Daniil Mirylenka Chun-Te Chu Shikhar Bharadwaj Francesco Bertolini Erin Farnese Joseph Pagadora Nick Roy Ian Gemp Nikos Parotsidis Tanya Lando Jean-Baptiste Alayrac Nova Fallen Vineetha Govindaraj Geza Kovacs Sam El-Husseini David Welling Ruy Ley-Wild Sergio Guadarrama Leandro Kieliger George Necula Ashwin Kakarla Gena Gibson Lukas Haas Manu Agarwal Arkadiusz Socala Lauren Lax Thanumalayan Sankaranarayana Pillai Swaroop Nath Utku Evci Xiang Deng Seth NeelArthur Guez Gregory Thornton Alejandro Cruzado Ruiz Liqian Peng MH Tessler Jaume Sanchez Elias Misha Bilenko Shereen Ashraf Mayank Upadhyay Yang Yu Isabel Gao Dayou Du Amir Globerson Guanjie Chen Maria Ivanova Reid Hayes Vincent Hellendoorn Mason Dimarco Yunhsuan Sung Scott Pollom Artem Shtefan Andrea Banino Ben Caine Gaurav Menghani Ivy Zheng Hongji Li Carey Radebaugh Mikel Rodriguez Matthew Bilotti Praseem Banzal Uday Kalra Zhipeng Yan Fayaz Jamil Apoorv Reddy Anna Bulanova Wojtek Skut Sarah Chakera Jin Miao Tara Sainath Zhouyuan Huo Sarah Cogan Dalia El Badawy Myle Ott Robin Alazard Linting Xue Thais Kagohara Ruizhe Zhao Steven Baker Namrata Godbole James Cobon-Kerr Grishma Chole Mark Brand Angie Chen Aditya Shah Bernett Orlando Nick Li Sara Smoot Dustin Tran Arseniy Klimovskiy Zhengdong Wang Tyler LiechtyLiangchen Luo Alireza Nazari Paweł Stradomski Gang Wu Kushal Chauhan Ken Franko Bryan Perozzi Andrey Vlasov Yasemin Altun Eric Li Shibo Wang Angeliki Lazaridou Celine Smith Shahar Drath Jonas Adler Duy Nguyen Obaid Sarvana Yanyan Zheng Ahmet Iscen Tapomay Dey Ashish Thapliyal Carrie Muir Sid Lall Michael Pliskin Kate Baumli Alec Go Muqthar Mohammad Liqun Cheng Sergey Kishchenko Alicia Parrish Guowang Li Shitij Nigam Aaron Phillips Neesha Subramaniam Ye Jin Blake Hechtman Uri Shaham Phil Wallis Xavier Garcia Shiva Mohan Reddy Garlapati Bhargav Kanagal Shamanna Derek Lockhart Olivier Bachem Shachi Paul Sonal Gupta Florian Luisier Mehran Kazemi Hoang Nguyen Vitaly Nikolaev Kiranbir Sodhia Fei Xia Vlad-Doru Ion Loren Maggiore Arvind Neelakantan Aahil Mehta Jessica Austin Wei He Jean-Michel Sarr Michiel Bakker Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Yoel Zeldes Amir Zait Sofia Erell Sun Jae Lee Lorenzo Blanco Nikolay Savinov Boya Fang Reut Tsarfaty Livio Baldini Soares George Tucker Serkan Cabi Izhak Shafran Ben Vargas David Klinghoffer Zhichun Wu Qiuchen Guo Timothy Knight Yi-ting Chen Alex Yakubovich Angelo Scorza Scarpati Petar Sirkovic Gal Yona Xu Chen Nikhil Dhawan Yury Malkov Hui (Elena) Li Nicolas Perez-Nieves Sumit Sanghai Paige Kunkle Patrick Morris-Suzuki Naina Raisinghani Kacper Krasowiak Lubo Litchev Benny Li Felix Gimeno Cath Hope Jaeyoun Kim Swaroop Mishra Ramesh Sampath Nemanja Rakićević Dhruv Shah Natalia Ponomareva Matan Eyal Alex Druinsky Arissa Wongpanich Tong Zhou Hansa Srinivasan Nuo Wang Pierse Chandu Thekkath Paul Roit Paul Cavallaro Mohammad Babaeizadeh Randall Parker Jingwei Shen Khiem Pham Andrei Kapishnikov Jerome Connor Anmol Gulati Boone Severson Madhavi Yenugula Dylan ScandinaroFlorian Hartmann Metin Toksoz-Exley Hongzhi Shi Koray Kavukcuoglu Pierre Sermanet Pu-Chin Chen David Gaddy Shanthal Vasanth Javier Snaider Nick Sukhanov Rui Zhu Rivka Moroshko Benjamin Lee Ryan Kappedal Sameera Ponda Denis Teplyashin Shiyu Huang Christian Frank Heng Chen James Qin Rohun Saxena Laura Graesser Ming-Hsuan Yang Zaid Nabulsi Takahiro Kosakai Cip Baetu Pan-Pan Jiang Derek Gasaway Ravi Kumar Scott Lundberg Tong He Dee Guo Robert Busa-Fekete Yossi Matias Abhinav Singh Josh Newlan Ben Withbroe Joe Jiang Quan Yuan Josh Woodward Yanqi Zhou Lu Huang Kate Olszewska Samrat Phatale Philipp Fränken Mencher Chiang Omer Goldman Sophie Bridgers Dan Bahir Brian Farris Ken Caluwaerts Danny Karmon Sahra Ghalebikesabi Han Fu Mathias Bellaiche Keran Rong Yujia Li Manuel Tragut Abhishek Rao Meet Gandhi Rachel SaputroPeter Young James Huang Greg Billock RJ Skerry-Ryan Jun Qian Ben Horn John Karro Monica Roy Shobha Vasudevan Roopal Garg Marc Wilson Da-Woon Chung Gautam Prasad Ben Hora Austin Tarango Peter Garst Gan Song Matheus Wisniewski Daniel Murphy Jiho Park Spandana Raj Babbula James Allingham Krzysztof Jastrzębski Daniel Sohn Olaf Ronneberger Ziqiang Feng Wenhao Jia Naman Goyal Christian Wright Jianmo Ni Anirudh Baddepudi Abbas Abdolmaleki Tom Cobley Marko Velic Matthew Rahtz Qing Wei Eirikur Agustsson Mohammed Badawi Goran Petrovic Tasos Kementsietsidis Blake JianHang Chen Shadi Noghabi Xuanhui Wang Sasan Tavakkol Aviel Boag Xinyun Chen Siamak Shakeri Gloria Shen Julien Amelot Larry Jin Alex Vasiloff Apoorv Kulshreshtha Yana Kulizhskaya Gabe Taubman Irene Giannoumis Joe Zou Charles Sutton Xu Gao Jonathan Lee Yoni Halpern Eyal MarcusShiraz Butt Hassan Mansoor Sonam Goenka Averi Nowak Eren Sezener Jai Gupta Salvatore Scellato Thatcher Ulrich Derek Cheng Vivian Xia Phil Culliton David Kao Anudhyan Boral Xiance Si Danny Driess Fan Ye Eszter Vértes Roey Yogev Rui Yao Jiaxian Guo Omer Barak Ting Liu Jiaming Luo Bhuvana Ramabhadran Lijie Ren Praneet Dutta Jonas Valfridsson Yin Zhong Georges Rotival Weiyi Wang Grace Vesom Isaac Noble Yu Watanabe Ting Yu Giulia Vezzani Hadas Natalie Vogel Juliette Pluto Jacky Liang Edouard Leurent Logan Kilpatrick Patrick Griffin Bryan Gale Sam Shleifer Roman Ring Kexin Zhu Jean Pouget-Abadie Wendy Kan Anselm Levskaya Mohamed Hammad Drew Garmon Aroma Mahendru Yuchuan Liu Jennifer Prendki Susanna Ricco Petra Poklukar Qihang Chen Dhruv Madeka Robert Geirhos Shibl Mourad Natalie Ha Colin Cherry Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Yu-Cheng Ling Rhys May Maximilian Sieb Shankar Krishnan Richard Shin Bhavishya Mittal Amir Zandieh Gary Leung Piyush Patil Vittorio Selo Coline Devin Ellie Pavlick Alex Cullum Sébastien Pereira Alex Tomala Thibault Sellam Susheel Tatineni Federico Piccinini Yunhan Xu Hao Liu Yiqing Hua Ishaan Malhi Li Xiao Matthew Johnson Suyog Kotecha Kyle He Min Ma James Zhao Nina D’Souza Franz Och Massimo Nicosia Mohak Patel Sissie Hsiao Sergey Rogulenko Yuanzhong Xu Abhinit Modi Thang Luong Rigel Swavely Rishabh Agarwal Will Wu Hui Wan Xin Wang Dian Yu Khuslen Baatarsukh Daniel Kasenberg Alon Jacovi Jae Yoo Ken Burke Jan Wassenberg Gaël Liu Kaushal Patel Nicolas Lacasse Hannah Muckenhirn Chang Liu Lisa PatelAnnie Louis Kareem Mohamed Christine Kaeser-Chen Chak Yeung Prateek Kolhar Dipanjan Das Yi-Xuan Tan Brian Walker Paul Vicol Balaji Lakshminarayanan Aman Prasad Eddie Cao Will Thompson Jianmin Chen Chrysovalantis Anastasiou Jingcao Hu Guan Sun Sahil Singla Joss Moore Mahmoud Alnahlawi Yi Tay Martin Scholz Neel Kovelamudi Julian Eisenschlos Tanuj Bhatia Dennis Duan Joe Heyward Luyao Xu Avi Caciularu Stanislav Fort Aditya Gupta Sarah Hodkinson Fabian Mentzer Abhinav Arora Chaitra Hegde Ana Ramalho Vincent Cohen-Addad Hugo Vallet Dan Graur Shivani Agrawal Qijun Tan Anelia Angelova Andrei Rusu Mikita Sazanovich Parsa Mahmoudieh Michael Riley Fanny Wei Rebeca Santamaria-Fernandez Raphael Hoffmann Eric Ge Lesley Katzen Steven Hemingray Felix Halim Artur DwornikCharlotte Magister Kalesha Bullard Amy Hua Jannis Bulian Elizabeth Kemp Fred Bertsch Huijian Li Chen Zhu Trieu Trinh Lijun Yu Ester Hlavnova Dan Deutsch Georgi Stoyanov Nathalie Rauschmayr Anca Dragan Seb Noury Hao Zheng Simon Rowe Filippo Graziano Dima Damen Geoff Bacon Rachana Fellinger Armand Joulin Min Kim Ale Hartman Dinesh Tewari Szabolcs Payrits Megh Umekar Marc Brockschmidt Yang Xiao Chace Lee Jianling Wang Chawin Sitawarin Tao Tu Dawn Bloxwich Shoshana Jakobovits Vytenis Sakenas Renee Wong Danielle Eisenbud Chuyuan Kelly Fu Neslihan Bulut Morteza Zadimoghaddam Donghyun Cho Ruichao Li Alex Siegman Dean Weesner Mitchelle Rasquinha Alban Rrustemi Adi Gerzi Rosenthal Iurii Kemaev Katerina Tsihlas Caitlin Sikora Frank Kim Siddhartha Brahma Francesco PongettiMark Omernick Zhen Qin Daniel De Freitas Tom Paine Carla Bromberg Pallavi LV Grace Chu Xiangzhuo Ding Gabriel Ibagon Aditya Ayyar Megha Goel Katherine Lee Dero Gharibian Michael Collins Pranavaraj Ponnuramu Aaron Cohen Michael Bendersky Jens Heitkaemper Sanja Deur Alex Irpan Erica Moreira Demis Hassabis Tony Lu Alexey Frolov Mariko Iinuma Tsendsuren Munkhdalai Tao Jiang Ruoxin Sang Alok Gunjan Mary Jasarevic Honglin Yu Jun Xu Emma Dunleavy Sholto Douglas Danilo Martins Eleftheria Briakou Edward Loper Yin Zhang Sami Lachgar Kareem Ayoub James Swirhun Tingnan Zhang Arjun Kar Paul Barham Eric Jia Tao Li Dean Hirsch Abhinav Gupta Jinhyuk Lee Ruibo Liu Kay Lamerigts Arjun Pillai Connor Schenck Arthur Conmy Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
The development of Gemini is a large-scale collaborative effort involving over 3000 individualsacross Google, including researchers, engineers, and operations staff. These individuals contributedtheir hard work and expertise across diverse areas, from foundational research and the developmentof model architecture, data, training, and infrastructure, through to evaluation and ensuring safetyand security. We gratefully acknowledge the dedication and hard work of each contributor in making Gemini a reality.
We are also grateful to the Google-independent developer Joel Zhang for his work on Gemini Plays Pokemon, and for sharing with us the design of his set-up.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
8. Appendix 8.1. Evaluation additional details Please see a description of the benchmarks considered, along with details of how scores in the maintext were obtained in Table 11.
Benchmark Description Details LiveCodeBench Code generation in Python (Jain et al., 2024).Resultsaretakenfrom https://livecodebench.github.io/leaderboard.html (1/1/2025 - 5/1/2025 in the UI) or, wherenot available, run internally by us.
Aider Polyglot Code editing in C++, Go, Java, JavaScript Python and Rust. See https://aider.chat/2024/12/21/ polyglot.html#the-polyglot-benchmark for a full description of thistask.Wereportresultsonthe“diff”or“diff-fenced” edit format (see https://aider.chat/docs/more/edit-formats.html for adescription of the different formats). Thescore reported are the pass rate average of 3trials. Numbers come from https://aider.chat/docs/leaderboards/ SWE-bench VerifiedAgentic coding: evaluates AI agentson real-world programming tasks from GitHub (Chowdhury et al., 2024; Jimenez et al., 2024).Gemini uses an internal agentic harnessequipped with tools to navigate the repo, edit files, and test the code.
We report scores for two modes: performance of a single agentic trace (“singleattempt”), and performance of a scaffoldthat samples multiple agentic traces and rereranks them before evaluation using Gemini’s own judgement (“multiple attempts”).
All evaluations are done with temperature=1, topp=0.99, topk=1024.
GPQA (diamond)Challenging dataset of questions written by domain experts in biology, physics, and chemistry (Rein et al., 2024).
Humanity’s Last ExamChallenging dataset of questions written by domain experts in a wide rangeof disciplines, including mathematics, physics, chemistry, biology and computer science (Phan et al., 2025).No tool use variant.
Reported results are from https://scale.
com/leaderboard/humanitys_last_exam.
for DeepSeek they are taken from https:
//scale.com/leaderboard/humanitys_last_exam_text_only (leaderboardfor performance on the text-only questions) and in the case of the Gemini 2.0 models, these results are on an earlier HLE dataset, obtained from https://scale.com/leaderboard/humanitys_last_exam_preview(indicated with a †in Table 3) SimpleQA World knowledge factuality with nosearch enabled (Wei et al., 2024).F1 scores are obtained from https://github.com/openai/simple-evals and, where not available, run internally by us.
Continued on next page Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Benchmark Description Details FACTS GroundingAbility to provide factually correct responses given documents and diverseuser requests. (Jacovi et al., 2025)Results are sourced from https://www.kaggle.com/benchmarks/google/facts -grounding Global MMLU (Lite)MMLUtranslatedbyhumantranslatorsinto 15 languages. (Singh et al., 2024)The lite version includes 200 Culturally Sensitive and 200 Culturally Agnostic samplesper language, see https://huggingface.
co/datasets/CohereLabs/Global-M MLU-Lite ECLeKTic A closed-book QA dataset that evaluates cross-lingual knowledge transfer (Goldman et al., 2025).
AIME 2025 Performance on 30 questions from American Invitational Mathematics Examination from 2025 (Balunović et al., 2025).Results are sourced from https://matharena.ai/ .
HiddenMathHardCompetition-levelmathproblems,Heldout dataset AIME/AMC-like, crafted byexperts and not leaked on the web.
LOFT (hard retrieval subset)Long context multi-hop and multineedle retrieval evaluation of 300queries (Lee et al., 2024).We report the results on two variants: anup to 128K average context length variant toensure they can be comparable with othermodels and a pointwise value for 1M contextwindow to show the capability of the modelat full length.
MRCR-V2 (8needle)MRCR-V2 is a significantly harder instance of the MRCR family of longcontext evaluations (Vodrahalli et al., 2024). Compared to MRCR-V1, weincrease the nesting of the dictionarysize to depth 3 rather than 2 by including a style parameter (for instance, anexample key might be “write a poemabout penguins in an archaic style”, rather than just “write a poem aboutpenguins”).The methodology has changed compared topreviously published results: we focus on aharder, 8-needle version (compared to the 4-needle version used before).
We report the results on two variants: an upto 128K average context length variant toensure they can be comparable with othermodels and a pointwise value for 1M contextwindow to show the capability of the modelat full length.
MMMU Multi-discipline college-level multimodal image understanding and reasoning problems. (Yue et al., 2024) Vibe-Eval (Reka) Image understanding evaluation, featuring particularly challenging examples. (Padlewski et al., 2024)Gemini is used as a judge.
ZeroBench Challenging image understanding evaluation that requires multi-step reasoning. (Roberts et al., 2025)Gemini is used as a judge. Average over 4runs.
Continued on next page Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Benchmark Description Details BetterChartQA A comprehensive chart understandingevaluation that covers 9 disjoint capability buckets. The chart images arerandomly sampled from the web and QA pairs are written by professional human annotators to reflect the wide distribution of chart styles and real-worldcases. (Gemini Team, 2024)Gemini is used as a judge.
FLEURS Automatic speech recognition (Conneau et al., 2023).0-shot queries to public APIs for all models.
Used a subset of 53 languages (out of 102); we filtered languages for which either modelresponses were too incompatible to groundtruth responses to be fairly scored.
We use Word-Error-Rate WER (lower is better) except for four segmented languageswhere we aggregate Character-Error-Rates (Chinese, Japanese, Korean and Thai).
CoVoST 2 Speech to text translation (Wang et al., 2020).0-shot queries to public APIs for all models.
We report BLEU scores for translating 21 languages to English.
ActivityNet-QA General video understanding (Yu et al., 2019)Test subset, 0-shot.
Videos were processed at 1fps and linearlysubsampled to a maximum of 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 =1024frames. For GPT 4.1, we used 500 framesdue to API limitations.
EgoTempo Egocentric video understanding (Plizzari et al., 2025)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 256.
Perception Test Perceptual understanding/reasoning (Patraucean et al., 2023)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 256.
QVHighlights Moment retrieval (Lei et al., 2021) Validation subset, 4-shots. Accuracy measured with R1@0.5.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 256.
VideoMMMU Video knowledge acquisition (Hu et al., 2025)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 256.
1H-VideoQA Hour-long video understanding (Gemini Team, 2024)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 7200.
LVBench Longvideounderstanding(Wangetal., 2024)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 1024.
Continued on next page Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Benchmark Description Details VideoMME Long video understanding (Fu et al., 2025)0-shot. Audio + visual uses the Long subsetof test set, audio + visual + subtitles usesfull test set.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 1024.
VATEX General video captioning (Wang et al., 2019)Test subset, 4-shots. CIDEr score.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 =64.
VATEX-ZH Chinese video captioning (Wang et al., 2019)Validation subset, 4-shots. CIDEr score.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 =64.
YouCook2 Cap Instructional video captioning (Zhouet al., 2018)Validation subset, 4-shots. CIDEr score.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 256.
Minerva Complex video reasoning (Nagraniet al., 2025a)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 1024.
Neptune Long video understanding (Nagraniet al., 2025b)Test subset, 0-shot.
Same processing as above with 𝑁𝑓 𝑟𝑎𝑚𝑒𝑠 = 1024.
Table 11|Description of the benchmarks used, along with extra details about subsets, variants andmodel specifications.
8.2. Gemini Plays Pokémon Additional Details Changing the model used by the Gemini Plays Pokémon agent had a strong effect on performance, ascan be seen in Figure 4.1.
Additional Harness Details The Gemini Plays Pokémon agent (Zhang, 2025) receives a subset of RAM information, intended togive sufficient information to play the game, partially overlaid with a screenshot of the Game Boyscreen. Gemini is prompted with a system prompt telling it that it is playing Pokémon Blue and thatits goal is to beat the game, as well as descriptive information to help it understand the conventionsin the translation from vision to text and a small number of general tips for gameplay. Gemini thentakes actions, translated to button presses. The sequence of actions is stored in context, followed bya summary clear every 100 turns. The summaries are stored in context as well. Every 1000 turns GPP compresses the existing summaries again. Additionally, Gemini keeps track of three main goals (primary, secondary, and tertiary) as well as several additional goals (contingency plans, preparation, exploration, team composition). Every 25 turns, another prompted instance of Gemini (Guidance Gemini, or GG) observes the same context as the main Gemini and critiques performance and attemptsto point out hallucinations and so on. The overworld fog-of-war map is stored in the context in XML, where coordinates which have not been seen cannot be viewed until explored. Crucially, in thesystem prompt, Gemini is instructed to explore. Once a tile is explored, however, the coordinate isautomatically stored in the map memory and labeled with a visited counter. Tiles are also labeled bytype (water, ground, cuttable, grass, spinner, etc.), and warp points to different maps are also labeledas such. Gemini also has access to two agentic tools, which are both instances of Gemini equippedwith a more specialized prompt - the pathfinder tool, and the boulder_puzzle_strategist Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
0 10 20 30 40 50 60 70 Time Elapsed (Hours)Rival 1 (Oak's Lab)Viridian CityEnter Viridian Forest (1st)Exit Viridian Forest (1st)Boulder BadgeEnter Mt. Moon (1st)Exit Mt. Moon (1st)Rival 3 (Nugget Bridge)Bill’s HouseCascade BadgeGame Milestones Gemini Plays Pokemon Progress Timeline Gemini 2.5 Pro Gemini 2.5 Flash Run 1 Gemini 2.5 Flash Run 2 Figure 12|The model matters: Same agentic harness, different Gemini models. All runs have thesame starter (Charmander). Note that measuring in units of hours also controls for the fact that eachof 2.5 Flash’s actions was significantly faster (though it requires more actual actions to achieve itsgoals). X marks the end of gameplay and is a lower bound on the time to complete the next milestone.
tool. In the pathfinder prompt, Gemini is prompted to mentally simulate a path-finding algorithm, which is left unspecified, and to verify that the path is valid against the map information available. Intheboulder_puzzle_strategist tool, Gemini is prompted to solve special boulder puzzles thatare present in Pokémon Blue in the Victory Road dungeon - these puzzles are similar to the game Sokoban - again, by mentally simulating sequences of actions that lead to solutions to the puzzle.
The prompt describes the physics and the task of the boulder puzzle, as well as the desired output ofsolutions. The tool was added after Gemini had solved 2/4 of the puzzles in Victory Road on its own, but progress was slow on the 3rd and 4th puzzles.
Additional Examples of Capabilities Long Context Agentic Tooling The model is able to identify a complex path through a maze withauto-movement only specified by direction (Rocket Hideout spinner puzzles), solve multiple shortestpath problems across multiple maps with limited resources (Safari Zone), perform maze solving onmazes with large description length (Route 13), and solve complex boulder-pushing puzzles acrossa multi-map 3D maze (Seafoam Islands). It is perhaps even more impressive that it appears to bepossible for the model to solve these problems only with textual descriptions of the problems. On theother hand, other models, like Gemini 2.5 Flash, were not able to perform similarly long pathfindingtasks, and often failed to find simpler paths. This gap highlights the superior long context reasoningcapability of Gemini 2.5 Pro (as also evidenced by other evaluations).
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Gemini Plays Pokemon: Agent ArchitectureGame I/OAgentic Core (Gemini 2.5 Pro) Full Context Agents Periodic Processes Agentic ToolsPersistent Memory & Context RAMUpdated by Agentic Core Pokemon Blue (Game Boy) Game State (RAM)Capture Screenshot Fog-of-War XML MapGame Screenshots Execute Button PressesMain Agent Goals Primary/Secondary/Tertiary Prepare/Explore/Contingency/TeamMemory Summarizer (100/1000 actions) Guidance Gemini (Critique / 25 turns) Pathfinder Boulder Puzzle StrategistSystem Prompt Inventory & PartyAction History & Summaries Figure 13|An overview of the agent harness (Zhang, 2025). The overworld fog-of-war map automatically stores a tile once explored and labels it with a visited counter. The type of tile is recorded from RAM. The agentic tools ( pathfinder ,boulder_puzzle_strategist ) are prompted instancesof Gemini 2.5 Pro. pathfinder is used for navigation and boulder_puzzle_strategist solvesboulder puzzles in the Victory Road dungeon.
boulder_puzzle_strategist is similarly impressive. The boulder puzzles in Pokémon Blueare Sokoban-like puzzles that require the player character to maneuver boulders on to switches andthrough holes in order to open up a pathway through a cave with multiple levels. The puzzles canbecome quite complex, requiring long circuitous pathways and multi-level movement in order to solvethe puzzle. With only a prompt describing boulder physics and a description of how to verify a validpath, Gemini 2.5 Pro is able to one-shot some of these complex boulder puzzles, which are requiredto progress through Victory Road.
pathfinder andboulder_puzzle_strategist are currently the only two agentic tools thatthe Gemini Plays Pokémon developer has implemented. In future runs, there are plans to exploretool-creation tools where the model can create new tools with only a prompt. Since most of theprompts for pathfinder andboulder_puzzle_strategist were actually written by Gemini 2.5 Pro itself, it is quite plausible that autonomous tool creation is possible for the current 2.5 Pro model.
General Reasoning Gemini 2.5 Pro is able to reason through complex game puzzles in Pokémonquite well. In this section, we present two examples.
Catching a Pokémon that is quick to flee: In one of the runs, the Gemini 2.5 Pro agent wasattempting to catch an Abra, and planned to use Pikachu’s Thunder Wave to paralyze the Abra, simultaneously making it less likely that Abra could Teleport out of the battle while also improvingthe catching rate. After multiple attempts, the agent caught Abra with this strategy.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Creatively escaping a softlock caused by bugs in game I/O: On the Cycling Road, the slopeforces southward movement at all times unless there is an obstacle. It turns out there are two tiles onthe Cycling Road that result in a softlock as a result of this behavior. In the GPP framework, buttonpresses are limited by time delays, and in order for a player to escape those two tiles (blocked on allsides except the north), the player would have to input a sequence of button presses more quicklythan the GPP framework allows. Gemini 2.5 Pro unluckily found itself in one of these two spots – luckily, it was not a softlock, because 2.5 Pro had already taught one of its party members HM02 FLY which allows for travel to any town it has been to. FLY is not typically used as an escape mechanism (unlike the item ESCAPE ROPE and the move DIG, both of which fail in this situation). After 4 hoursof trying many approaches to escape (including movement, ESCAPE ROPE, DIG, all of which areblocked), the Gemini 2.5 Pro agent came up with the idea to use FLY to escape from the softlocksuccessfully. This reasoning action is especially impressive since this situation can never occur in anexisting game – and thus, it is certain that information from training data for this behavior has notleaked into the model’s knowledge base!
Long Horizon Task Coherence There are several additional interesting case studies of shorterplanning sequences throughout Pokémon Blue that Gemini 2.5 Pro in the GPP harness was able tosolve:
Training team to prepare for upcoming battles: In one run where Gemini picked Charmander, the Fire-type starter, Gemini 2.5 Pro lost to Misty, the Water-type Gym Leader, the first time.
To prepare for the rematch, Gemini 2.5 Pro spent over 24 hours leveling up a Pikachu and a Bellsprout (both super-effective against Water types) by around 25 levels in total to successfullydefeat Misty.
Acquiring Hidden Moves (HMs) for game progression: In many parts of the game, it is necessaryto first acquire an HM before game progression is possible. Two examples are HM01 CUT and HM05 FLASH. Acquiring the ability to use CUT and FLASH each require four steps: 1) obtainingthe HM item itself, 2) acquiring a compatible Pokémon which can learn the move, 3) adding thecompatible Pokémon to the player’s team, 4) teaching the HM move to the compatible Pokémon.
In many cases, each step requires many steps itself. As an example, in run 1, Gemini 2.5 Prohad to a) retrieve CUT by completing the S.S. Anne quest, b) identify a Pokémon which couldlearn CUT and catch it (CHOPPY the Bellsprout), c) add CHOPPY to the team and d) teach CUT. Similarly, for HM05 FLASH, Gemini 2.5 Pro had to a) first catch 10 Pokémon to fill outthe Pokedex, b) backtrack to find an Aide who gives HM05 Flash, c) catch a Pokémon (ZAPthe Pikachu) in Viridian Forest, use the PC to deposit a Pokémon and withdraw ZAP, d) teach HM05 FLASH to Zap.
Solving the Safari Zone: The Safari Zone is another location with required HMs (both HM03 SURFand HM04 Strength). However, it has an extra constraint - it requires 500 ¥to enter each time, and the player is limited to only 500 total steps in the Safari Zone. As a result, if the player isunable to reach the required items in the limited number of steps, the player loses 500 ¥and isrequired to re-start! As a result, it is possible to essentially softlock if the player takes too manyattempts to complete the Safari Zone. Solving the Safari Zone itself requires traversing acrossfour different maps and not getting lost. Gemini 2.5 Pro was able to get both required HMs in 17 attempts in run 1, and in only 5 attempts in run 2.
Finding hidden keys in dungeons: Another method of progression in Pokémon is to find hiddenkeys and solve complex multi-floor dungeons. In particular, in Rocket Hideout, the player mustrecover the LIFT KEY on the fourth basement floor (dropped after beating a specific Team Rocket Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
Grunt) in order to unlock the elevator to find the evil Giovanni, leader of Team Rocket. In Silph Co., the player must find the CARD KEY in order to open multiple doors to find the path acrosseleven floors of the building to rescue the President from Giovanni. To open the seventh gym on Cinnabar Island, the player must enter the Pokémon Mansion and traverse three floors in orderto find the SECRET KEY which unlocks the gym door. All of these cases require maintainingthe goals over large numbers of actions and many local puzzles (like spinner puzzles in Rocket Hideout, and switch puzzles in Pokémon Mansion), in addition to maintaining the health of the Pokémon on the player’s team and managing wild encounters, trainer battles, and other items.
Puzzle solving over complex multi-level dungeons: The Seafoam Islands contain 5 floors involving multiple boulder puzzles which require the player to navigate mazes and push bouldersthrough holes across multiple floors using HM04 STRENGTH in order to block fast-movingcurrents that prevent the player from using HM03 Surf in various locations in this difficultdungeon. As a result, the player must track information across five different maps in order toboth deduce the goal (push two boulders into place in order to block a specific current) as wellas engage in multi-level (effectively 3D) maze solving to find the way out. It is likely the mostchallenging dungeon in the game. Only the second run of GPP went through Seafoam Islands, as it is not required to progress. During the course of solving Seafoam Islands, the GPP agentalso encountered a novel bug in the code of Pokémon Red/Blue, and is likely the first AI to finda bug in the game’s code (MrCheeze, 2025) (source).
Additional Challenges Hallucinations and Fixations on Delusions While game knowledge can sometimes leak and bequite beneficial to the ability of the model to progress, it can also hinder the model in surprisingways due to hallucinations, delusions, and mix ups with other generations of Pokémon games. Oneexample of this phenomenon is the TEA item. In Pokémon Red/Blue, at one point the player mustpurchase a drink (FRESH WATER, SODA POP, or LEMONADE) from a vending machine and handit over to a thirsty guard, who then lets the player pass through. In Pokémon FireRed/LeafGreen, remakes of the game, you must instead bring the thirsty guard a special TEA item, which does notexist in the original game. Gemini 2.5 Pro at several points was deluded into thinking that it had toretrieve the TEA in order to progress, and as a result spent many, many hours attempting to find the TEA or to give the guard TEA.
In Run 2, the model was explicitly prompted to act as a player completely new to the game, and todisregard prior knowledge about game events, item locations, and Pokémon spawn points, in order tomitigate hallucinations from model pretraining knowledge and to also attempt to perform a cleanertest of the model’s ability to reason through the game. It appears to have at least partially worked multiple hallucinations from other games have been avoided in the second run. On the flip side, thisprompt may have also harmed the model’s ability to utilize information from its common knowledgeabout the game, hindering overall performance in a few critical places.
Fixations on delusions due to goal-setting and also due to the Guidance Gemini instance are notan uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the onlyexample of this behavior. An especially egregious form of this issue can take place with “contextpoisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformationabout the game state, which can often take a very long time to undo. As a result, the model canbecome fixated on achieving impossible or irrelevant goals. This failure mode is also highly related tothe looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Letme try to go through the entrance to a house and back out again. Then, hopefully the guard who isblocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
model to ignore common sense and repeat the same incorrect statement. Context poisoning can alsolead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out” and teleporting to the nearest Pokémon Center and losing half your money, instead of attempting toleave).
Topological Traps in Thinking Patterns One recurring pattern in particularly-difficult-to-solvepuzzles and mazes for Gemini 2.5 Pro consists of a “topological trap” - the topology of the reasoninggraph required to solve the maze or puzzle has a distinctive shape. Namely, the desired objectiveappears to be nearby and easily reachable (an “attractor”), but the correct solution requires taking adetour in order to arrive at the correct solution. We observed this phenomenon in multiple parts ofthe game. In the spinner puzzle on B3F of Rocket Hideout (Zerokid, 2024), the map positions bothan item and the correct staircase to the south, but they are only accessible by going the long wayaround. The Route 13 maze has only one correct route through - the upper narrow pass. Finally, the Victory Road 3F boulder puzzle requires the player to push the boulder in the upper right all the wayto the upper left switch, while ignoring the boulder puzzles, ladders, and exits to the south.
Notably, if the model is instructed to solve a given puzzle at all once (e.g., via pathfinder ), itcan manage to do so if the context length is not too long. For instance, pathfinder implementedwith Gemini 2.5 Pro is able to solve the B3F spinner trap in one shot.
Agent Panic Over the course of the playthrough, Gemini 2.5 Pro gets into various situations whichcause the model to simulate “panic”. For example, when the Pokémon in the party’s health or powerpoints are low, the model’s thoughts repeatedly reiterate the need to heal the party immediately orescape the current dungeon (e.g., famously using the move DIG or an ESCAPE ROPE item). Quiteinterestingly, this mode of model performance appears to correlate with a qualitatively observabledegradation in the model’s reasoning capability – for instance, completely forgetting to use thepathfinder tool in stretches of gameplay while this condition persists. This behavior has occurredin enough separate instances that the members of the Twitch chat have actively noticed when it isoccurring.
Actions vs. Game Milestones For completeness, we plot the number of actions/steps required to achieve each game milestone (see Figure 14). An action consists of each bucketed instance where the agent outputs a sequenceof button presses to the game (note that other AI agents playing Pokémon may output differentnumbers of button presses per action, define what constitutes a button press differently, or define anaction/step differently). However, it is important to consider action-milestone plots in conjunctionwith information about the time and/or cost in order to obtain the full picture about the agent’sperformance.
8.3.Frontier Safety Framework Evaluations Additional Details: Frontier Safety Correctness Tests For each testing environment, we performed basic correctness checks by looking at how the agentsbehaved. This involved combining AI and manual reviews of the agents’ actions to flag potentialissues.
On RE-Bench, we examined the best, median and lowest scoring trajectories. For cybersecurityenvironments (InterCode CTFs, Internal CTFs, Hack the Box), we carefully inspected at least onesuccessfulattempt(whereavailable)fromeachenvironment,andotherwiseexaminedanunsuccessful Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
0 5000 10000 15000 20000 25000 30000 35000 # ActionsRival 1 (Oak's Lab)Viridian CityEnter Viridian Forest (1st)Exit Viridian Forest (1st)Boulder BadgeEnter Mt. Moon (1st)Exit Mt. Moon (1st)Rival 3 (Nugget Bridge)Cascade BadgeBill’s HouseRival 4 (SS Anne)Access Pokemon w/ CUTAcquire HM05 FlashThunder BadgeEnter Rock Tunnel (1st)Access Pokemon w/ FlashExit Rock Tunnel & Reach Lavender Town (1st)Rival 5 (Lavender Tower)Enter Celadon City (1st)Enter Rocket Hideout (1st)Rocket Boss 1 (Rocket Hideout)Rainbow BadgeAcquire PokéFlute (Rescue Fuji)Enter Fuchsia City (1st)Enter Safari Zone (1st)Acquire HM03 Surf (Beat Safari Zone)Soul BadgeAcquire HM04 Strength (Warden's Teeth)Enter Saffron City (1st)Enter Silph Co. (1st)Rival 6 (Silph Co.)Rocket Boss 2 (Silph Co.)Marsh BadgeEnter Seafoam IslandsExit Seafoam IslandsEnter Cinnabar Island (1st)Acquire Secret Key (Pokemon Mansion)Volcano BadgeEarth BadgeRival 7 (Route 22 #2)Enter Victory Road (1st)Exit Victory Road (1st)Beat Elite Four LoreleiBeat Elite Four BrunoBeat Elite Four AgathaBeat Elite Four LanceHall of FameGame Milestones Gemini 2.5 Pro Plays Pokemon Progress Timeline Run 2 (a) The fully autonomous Run 2 milestones as a function of the number of individual actions.
0 1000 2000 3000 4000 5000 6000 7000 8000 # ActionsRival 1 (Oak's Lab)Viridian CityEnter Viridian Forest (1st)Exit Viridian Forest (1st)Boulder BadgeEnter Mt. Moon (1st)Exit Mt. Moon (1st)Rival 3 (Nugget Bridge)Bill’s HouseCascade BadgeGame Milestones Gemini Plays Pokemon Progress Timeline Gemini 2.5 Pro Gemini 2.5 Flash Run 1 Gemini 2.5 Flash Run 2(b) Comparison of 2.5 Pro and 2.5 Flash in terms ofactions to milestones.
Figure 14|Analog of Figure 5 and 14b, in terms of actions instead of hours.
attempt. We also performed checks on sample situational awareness and stealth evaluations. Thisinvolved basic spot checks to ensure that the prompt and shell outputs were correctly formatted.
We used AI assistance to monitor for obvious instances of cheating, and did not find any. For the RE-Bench tests specifically, we also looked at how the best-performing agent achieved its score toensure that it was a plausible approach, rather than exploiting an obvious reward hack. Overall, wedid not observe errors that we believe would invalidate the results of the benchmarks.
8.4. Image to Code Demo We prompted Gemini 1.5 Pro and Gemini 2.5 Pro to generate an SVG representation of an image andfound Gemini 2.5 Pro generates better reconstructions.
Prompt Gemini 1.5 Pro Gemini 2.5 Pro Please convert this image into SVG and try to reconstruct thespatial arrangement of theobjects.
Figure 15|Comparison of Gemini 1.5 Pro and Gemini 2.5 Pro responses to image-to-SVG reconstruction prompt.
Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.
8.5. Long Context Video Understanding Demo We prompted Gemini with the full video and the following prompt to assess its ability to find a veryspecific scene (which only lasts 1 second) out of the full 46 minutes video.
Video (46 minutes): Redefining Robotics with Carolina Parada Prompt: What color is the T-shirt the robot arms are trying to fold, and at what timecode doesthis occur?
Figure 16|Frame and timestamp the model is meant to recall. Taken from https://www.youtube.com/watch?v=Rgwty6dGsYI at timestamp 27:29.
See Table 12 for samples. Gemini 1.5 Pro gets the color right in 1/3 cases, and gets the timestampin 0/3 cases (quite far away). Gemini 2.5 Pro gets the color in 3/3 cases, and gets the timestamp in 1/3 cases (remaining 2/3 are within 3 seconds close).
Model Trial Model response Gemini 1.5 Pro 1 The t-shirt the robot arms are trying to fold is a dark teal orturquoise blue color. The folding begins at and continues at [11:06–11:15].
2The T-shirt is orange, and the robot can be seen trying to foldit starting at [00:00:26–00:00:28].
3The t-shirt being folded is dark blue and can be seen between [00:00:56–00:00:58] and [00:07:56–00:07:59].
2.5 Pro Preview 05-06 1 The T-shirt the robot arms are trying to fold is blue. Thisscene occurs at timecode 27:29.
2The T-shirt the robot arms are trying to fold is blue. Thisoccurs at timecode 27:26.
3The T-shirt the robot arms are interacting with (as part of the "fold laundry" task mentioned by the speaker) is blue. Thisoccurs at timestamp 0:27:28.
Table 12|Gemini models samples for T-shirt folding scene recall
