<!-- metadata -->

- **title**: CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications
- **source**: https://arxiv.org/abs/2506.03543
- **author**: Wanghao Ye et al.
- **published**: 2025-06-04T03:54:30Z
- **fetched**: 2025-06-08T19:26:33+00:00
- **tags**: codex, gnwt, social-ai, digital-twin
- **image**: /static/browse/0.3.4/images/arxiv-logo-fb.png

## 要約

GNWT を実装した CogniPair は複数のサブエージェント（感情・記憶・社会規範・計画・目標管理）がグローバルワークスペースで協調し、人格の一貫性と社会的学習を両立する。冒険ゲーム形式の性格テストにより初期化したデジタルツインを使って 551 名分の Speed Dating データを再現し、ペアリングやマッチ予測を評価した。パートナー選好の進化精度 72.5%、マッチ予測精度 77.8% を達成し、人間の魅力傾向と 72% の相関を示した。人間参加者によるデジタルツインの行動再現度評価は 5.6/7、意思決定一致率は 74% で、HR 面接シナリオでは一致率 81% まで向上。将来的には文化要因や非言語情報の導入、計算効率の最適化が課題だが、恋愛や採用、教育など広範な社会的意思決定の支援に応用できる。

## 本文

arXiv:2506.03543v1 [cs.AI] 4 Jun 2025

CogniPair: From LLM Chatbots to Conscious AI
Agents - GNWT-Based Multi-Agent Digital Twins for
Social Pairing - Dating & Hiring Applications
Wanghao Ye1 , Sihan Chen2 , Yiting Wang1 , Shwai He1 , Bowei Tian1 , Guoheng Sun1 , Ziyi Wang1 ,
Ziyao Wang1 , Yexiao He1 , Zheyu Shen1 , Meng Liu1 , Yuning Zhang1 , Meng Feng1 , Yang Wang3 ,
Siyuan Peng1 , Yilong Dai4 , Zhenle Duan1 , Hanzhang Qin5,∗ , Ang Li1,∗
2

1
University of Maryland, College Park
Viterbi School of Engineering, University of Southern California
3
Northeastern University
4
Department of Computer Science, University of Florida
5
National University of Singapore
∗
Joint corresponding authors

University of Maryland Departments: Electrical and Computer Engineering, Computer Science,
Robert H. Smith School of Business, School of Public Policy, Department of Agricultural and Resource Economics
{wy891, yiting, bowei, guoheng, ziyi, ziyao, yexiao, zheyu, meng, yuning, mfeng, siyuan, zhenle, angli}@umd.edu
sihan@usc.edu yang@northeastern.edu yilong@ufl.edu hanzhang@nus.edu.sg

Abstract
Current large language model agents lack authentic human psychological processes
necessary for genuine digital twins. We present the first computational implementation of Global Workspace Theory (GNWT), creating agents with multiple
specialized sub-agents (emotion, memory, social norms, planning, goal-tracking)
coordinated through a global workspace broadcast mechanism. This architecture
allows agents to maintain consistent personalities while evolving through social
interaction. Our CogniPair simulation platform deploys 551 GNWT-Agents for
speed dating interactions, grounded in real data from the Columbia University
Speed Dating dataset. Evaluations show unprecedented psychological realism,
with agents achieving 72% correlation with human attraction patterns and outperforming baselines in partner preference evolution (72.5% vs. 61.3%). Human
validation studies confirm our approach’s fidelity, with participants rating their
digital twins’ behavioral accuracy at 5.6/7.0 and agreeing with their choices 74%
of the time. This work establishes new benchmarks for psychological authenticity
in AI systems and provides a foundation for developing truly human-like digital
agents.

1

Introduction

Human social interactions—from dating to job interviews—require not just coherent dialogue but
authentic psychological processes including emotion regulation, memory consolidation, and dynamic
preference formation. LLM-based agents have been applied to model human social interactions,
showing promise in domains such as customer service, healthcare assistance, and educational
tutoring [22, 33, 28]. Despite recent advances, current LLM-based agents face two fundamental
limitations that restrict their ability to model human behavior realistically: (1) the psychological
behavior gap—they cannot authentically simulate internal mental states, emotional processing, or
evolving preferences [35, 25, 17, 14]; and (2) the social behavior gap—they fail to capture the
complex dynamics of human-to-human interactions where preferences and behaviors co-evolve
through social experiences [22, 34, 16, 23, 2, 26].
Preprint. Under review.

The psychological behavior gap manifests in two critical problems: the individualization problem,
Broadcast
Global Workspace
Conscious Access
We selected speed dating as our evaluation domain because it exemplifies the most challenging aspects

architecture where multiple sub-agents within each agent replicate human psychological
processes through dynamic workspace broadcasting
theory with large-scale social simulation, capable of generalizing beyond our dating
testbed to various social decision environments as demonstrated by successful transfer to
job interview contexts (81% accuracy)
vs. 61.3%), self-perception adaptation, and external evaluation shifts compared to state-ofthe-art baselines

Input & Agent

Session

Session
Module

（Optional）
Stateless Reply
Limitations:

• Linear processing

• No persistent memory

（Biological Cognition）

Parallel Processing Modules（Similar to Unconscious Modules）

User Prompt
Single LLM Core

GNWT Human Model

（Brain-Inspired Design）

Emotion
Memory
Social Norms
Planning
Goal Tracking

Broadcast

Feedback

Salience Competition
（Module Activation）

Global Workspace

Integration & Broadcasting

（Information Bus）

Broadcasts to All Modules

Persistent Memory
Conscious Response

1

Unconscious
Modules

（Parallel Processing）

Broadcast

to Modules

Winning Coalition

2

Memory

Loop
3

（Attention Gate）

Global Workspace

Conscious Access

（Broadcasting）

Broadcasts to System

Conscious Output

Figure 1: Comparison of Cognitive Architectures: Traditional RL/Chatbot (left), GNWT Agent
Architecture (center), and GNWT Human Model (right), showing the evolution from linear processing
to brain-inspired parallel processing with global workspace integration.
To address these fundamental gaps, we turn to Global Workspace Theory (GNWT) [21, 4], a leading
neurocognitive model that explains how human consciousness emerges from the interaction of specialized brain modules. In human cognition, GNWT describes how disparate neural processes—emotion,
memory, perception, and planning—compete for access to a central "global workspace." When
information becomes sufficiently salient, it triggers a broadcast that propagates this content throughout the brain, creating our unified stream of consciousness. This theoretical foundation provides
a clear roadmap for building agents that can overcome both the psychological and social behavior
gaps(Figure 1). To address the psychological behavior gap, we operationalize GNWT into a computational agent architecture where each individual agent contains multiple specialized sub-agents
working in parallel as a unified consciousness. Our GNWT-Agent implements five specialized
cognitive modules—Emotion, Memory, Planning, SocialNorms, and GoalTracking—each grounded
in neurocognitive theories and parameterized by the agent’s Five-Factor personality profile. By
implementing GNWT’s broadcast mechanism computationally, we create agents with genuine internal psychological dynamics—emotion sub-agents generate affective responses, memory sub-agents
consolidate experiences, social norms sub-agents manage cultural awareness, planning sub-agents
develop strategies, and goal-tracking sub-agents maintain objectives. This architecture fundamentally
differs from traditional LLM agents that process inputs sequentially without internal state evolution.
To bridge the social behavior gap, we developed CogniPair, a social-influence decision system
that enables GNWT-Agents to engage in authentic social interactions and evolve through experience.
CogniPair is not merely a testbed but a comprehensive system for modeling and guiding social
influence between individuals, ultimately optimizing decision processes across various social contexts.
While our primary evaluation uses a speed dating testbed, the CogniPair system itself can be extended
to other social decision environments such as team formation, negotiation scenarios, and collaborative
problem-solving.
2

We selected speed dating as our evaluation domain because it exemplifies the most challenging aspects

architecture where multiple sub-agents within each agent replicate human psychological
processes through dynamic workspace broadcasting
theory with large-scale social simulation, capable of generalizing beyond our dating
testbed to various social decision environments as demonstrated by successful transfer to
job interview contexts (81% accuracy)
vs. 61.3%), self-perception adaptation, and external evaluation shifts compared to state-ofthe-art baselines
Input & Agent
Session
Session
personality modeling: core traits remain stable through persistent attention patterns while allowing
adaptive changes through experience-driven broadcast priority shifts. Unlike previous approaches
that treat personality as static prompts or surface behaviors, our architecture models the cognitive
processes underlying personality and the social dynamics shaping its evolution.
Our evaluation framework measures psychological and social realism across multiple dimensions.
For psychological realism, we assess preference consistency (how well agents maintain core values
while adapting), emotional coherence (whether affective responses follow human psychological
principles), and memory integration (how past experiences influence decisions). For social realism,
we measure attraction correlation (how closely agent mate selection aligns with human patterns),
interaction dynamics (how conversations evolve), and emergent social phenomena (group formation,
preference shifts). These metrics ground our claims about achieving human-level authenticity in
both psychological processing and social behavior. Our experiments demonstrate that our GNWTAgents achieve unprecedented accuracy in modeling human social dynamics. We show significant
improvements in partner preference evolution (72.5% accuracy vs. 61.3% for Multi-Agent Debate),
self-perception adaptation, external evaluation changes, and match prediction (77.8% accuracy)
compared to state-of-the-art baselines. Most impressively, our agents demonstrate human-like
evolution patterns with high correlation to ground truth data (above 0.7 across multiple dimensions,
with a 0.72 correlation for match patterns). Human validation studies further confirm the psychological
fidelity of our approach, with participants rating their digital twins’ behavioral fidelity at 5.6/7.0 and
agreeing with their twin’s choices 74% of the time. Our key contributions are:

1. We are the first to operationalize GNWT for computational agents, creating a cognitive
   architecture where multiple sub-agents within each agent replicate human psychological
   processes through dynamic workspace broadcasting
2. We develop CogniPair, the first social-influence decision system combining cognitive
   theory with large-scale social simulation, capable of generalizing beyond our dating
   testbed to various social decision environments as demonstrated by successful transfer to
   job interview contexts (81% accuracy)
3. Our extensive experiments confirm GNWT’s broadcast mechanism enables genuine personality evolution, with significant improvements in partner preference evolution (72.5%
   vs. 61.3%), self-perception adaptation, and external evaluation shifts compared to state-ofthe-art baselines

2

Related Work

LLMs for Social Interaction and Simulation: Recent LLM advances have enabled sophisticated
conversational capabilities [27, 22], but standard LLMs lack persistent psychological states [14, 35].
While approaches like Chain-of-Thought [31], self-consistency [29], retrieval-augmentation [18],
and memory architectures [14, 35] enhance reasoning, they show limitations in modeling social
dynamics [32, 28] and rarely incorporate selective attentional mechanisms [35, 36, 3].
Social simulation systems like Park et al.’s Generative Agents [22] implement memory and planning
but use fictional personas without psychological grounding. Huang et al. [16] identified gaps between
simulated and human behavior in LLM agents. While PersonaChat [34], Li et al. [20], and Gao et
al. [12] advanced social simulation, none incorporate real human data for initialization, neuroscience3

Input & Agent
   Session



   Session

Conversation

Agent
Conversations

Precompute Pairs

Create GNWT-Agent lntegration instances

4. Start
Session

Agent 1 Turn


N turns

Loop
Agent 2 Turn

GNWT-Agent processing

GNWT-Agent processing

GNWT-Agent Processing Details

Pairing Decisions
& Results

Make Decisions

heck Matches

C

6. Evaluate
Session

Store in GNWT-Agent
memory

Export Results

Figure 2: CogniPair Platform System Flow
based cognitive processing, dynamic personality evolution, or comprehensive social evaluation
metrics [2, 22]. Our CogniPair system integrates all these components to address these fundamental
limitations.
Modeling Psychological Processes in AI: Traditional cognitive architectures relied on handcrafted symbolic representations with limited adaptability. Global Neuronal Workspace Theory
(GNWT) [4, 21] provides a framework for modeling human-like dynamic attention allocation. While
Bengio et al. [5] and Goyal et al. [13] explored computational implementations of consciousness
theories, they focused on perceptual processes rather than higher-order social cognition. Frameworks
from Dehaene et al. [8] and Mashour et al. [21] similarly neglect social-cognitive dimensions essential
for authentic human interaction simulation. Recent digital twins research emphasizes behavioral
mimicry [24] without capturing underlying psychological dynamics, and personality modeling
systems [19, 30] typically treat traits as static rather than adaptive characteristics evolving through
social interaction [1, 26].
Systems using debate mechanisms [9, 6] or transformer-based aggregation [7, 15] show improved
performance over single-agent approaches but implement coordination through explicit turn-taking
rather than human-like parallel processing. Our GNWT-Agent addresses these limitations through
a global workspace mechanism enabling selective attention based on personality-driven priorities.
CogniPair enables realistic preference adaptation while maintaining consistent core traits, using
the Columbia dataset [10] for both initialization and evaluation, demonstrating significantly higher
contextual coherence and emotional alignment compared to alternatives.

Planning Module. This module implements hierarchical goal decomposition: breaking down

Planning Module. This module implements hierarchical goal decomposition: breaking down

structures N documenting group formation.
This multi-level data collection enables both micro-analysis of individual cognitive processes and
macro-analysis of emergent social patterns, providing a foundation for validating the system’s fidelity
to human social behavior across different interaction contexts.


  structures N documenting group formation.
  This multi-level data collection enables both micro-analysis of individual cognitive processes and
  macro-analysis of emergent social patterns, providing a foundation for validating the system’s fidelity
  to human social behavior across different interaction contexts.
Figure 3: Social Dynamics Evolution: Human vs. GNWT-Agent Comparison. (A) Partner preference
For external evaluation (Figure 3C), there is a dramatic shift in evaluation criteria from Time 1 to
Conscious processing and the global neuronal workspace hypothesis. Neuron, 105(5):776–798, 2020.
Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual ACM symposium on user interface software and technology, pages 1–22, 2023.
using a large language model based on group-level demographic information. arXiv preprint, 2024.
[29] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Selfconsistency improves chain of thought reasoning in language models. In International Conference on Learning Representations, 2023.
A
A.1
• Calculate relevance scores
• Apply personality factors
• Determine activation threshold
Memory Module
• Apply personality prior
• Episodic memory retrieval

• Progress estimation
• Semantic memory search
• Cultural conditioning
• Hierarchy prediction
• Uncertainty estimation
• Working memory update
• Plan memory check
• Relevance estimation
• Relevance scoring
• Update emotional memory

• Memory consolidation

• Confidence estimation
• Personality adaptation


• Detect emotional content
• Query transformation
• Context classification
• Active goal update
A.2



• Detect emotional content
• Query transformation
• Context classification
• Active goal update
A.2
= {w1 , w2 , ..., wn }
Modulesi .weights = M (Pi , IAi )

(9)
(10)
(11)

where Pi represents the agent’s personality profile (typically Five-Factor traits), IAi represents
scenario-specific interaction attributes, and M is a mapping function that determines module processing parameters. This approach ensures individual agents retain consistent core traits while adapting
their behavior appropriately to different social contexts.
The interaction protocol supports multiple engagement patterns: 1. Dyadic exchanges - One-toone interactions with reciprocal turn-taking; 2. Group discussions - Multi-participant exchanges
with dynamic speaker selection; 3. Hierarchical interactions - Structured exchanges with defined
role-based communication paths.
For each interaction, the system manages turn-taking, tracks interaction histories, and computes
evolving relationship metrics. The architecture records comprehensive interaction data including:
- Complete interaction histories H - Cognitive trace datasets T capturing internal mental states Relationship development trajectories R tracking interpersonal dynamics - Emergent social network
structures N documenting group formation.
This multi-level data collection enables both micro-analysis of individual cognitive processes and
macro-analysis of emergent social patterns, providing a foundation for validating the system’s fidelity
to human social behavior across different interaction contexts.

4

Experiments and Results

4.1

Experimental Setup

Dataset and Simulation Protocol: The Columbia University Speed Dating dataset [10] contains
records of 551 participants who engaged in 5,500+ four-minute speed dates over 21 sessions, resulting
in over 8,300 observations. Each record includes pre-dating attribute self-ratings (1-10 scale), attribute
importance ratings (distributing 100 points across 6 attributes), post-dating partner ratings on the
same attributes, and match decisions (yes/no interest in seeing a partner again). The six key attributes
measured are: attractiveness, sincerity, intelligence, fun, ambition, and shared interests. We instantiate
551 GNWT-Agents as digital twins of the original participants, initializing each agent’s personality
profile with the Five-Factor traits inferred from participants’ self-ratings and importance distributions.
The physical and temporal parameters in the CogniPair system are configured to match the original
study’s environment (bar-restaurant setting, 4-minute interaction, 8-10 conversation turns). For each
simulated date, agents engage in 8 conversation turns, after which they update their self-ratings based
on interaction experience, rate their partners on the six attributes, and make match decisions. We
compare match patterns, preference evolution, and conversation dynamics against ground truth data
from the original study.
Baselines: We compare against state-of-the-art approaches: Single Sequential LLM (standard promptbased approach without specialized cognitive modules), Memory-Enhanced LLM (incorporates
retrieval-augmented context) [18], Multi-Agent Debate (simulates internal deliberation through
multiple agents) [6], and Hierarchical Architecture (uses a command structure to organize decisionmaking) [9]. All baselines use identical data initialization to ensure fair comparison.
4.2

Results and Key Findings

We examine population-level social dynamics to assess how well our system bridges the social
behavior gap identified in our introduction. Our experimental approach creates digital twins of the
Columbia Speed Dating study participants and compares their evolution with the ground truth human
data across multiple time points.
7

Figure 3: Social Dynamics Evolution: Human vs. GNWT-Agent Comparison. (A) Partner preference
changes from T1 to T2; (B) Self-perception adjustments across attributes; (C) Evolution of attributeliking correlations from initial to post-interaction evaluations.

Figure 4: Comparison of GNWT-Agent with baseline methods across evolution dimensions. (A)
Evolution accuracy showing GNWT-Agent’s superior performance in all metrics; (B) Human-agent
correlation demonstrating stronger alignment with human data compared to baseline approaches.

4.2.1

Evolution of Social Dynamics

We evaluate our system’s ability to model four key dimensions of social dynamics evolution: partner preference changes, self-perception adaptation, external evaluation shifts, and match decision
accuracy. As illustrated in Figure 3, our analysis reveals several important patterns that characterize
human social dynamics and demonstrates the remarkable similarity in evolution patterns between
human participants and our GNWT-Agents.
For partner preferences (Figure 3A), both humans and agents show consistent patterns in attribute
importance shifts. Attractiveness importance increases substantially (+39.0% human, +25.0%
agent), while intelligence (−24.8% human, −15.2% agent) and sincerity (−16.6% human, −10.5%
agent) show significant decreases. Shared interests show comparable positive changes (+9.8%
human, +9.7% agent), while fun remains relatively stable with slight increases (+1.3% human,
+5.8% agent). Ambition (−7.0% human, −4.5% agent) exhibits moderate decreases, suggesting its
relative stability as a core value less influenced by short-term interactions.
For self-perception (Figure 3B), there is subtle but consistent calibration of traits through social
interaction. Unlike partner preferences, self-perception shows more conservative adjustments, with
small negative shifts across most dimensions for both humans and agents: attractiveness (+0.3%
human, −0.5% agent), sincerity (−3.5% human, −2.5% agent), intelligence (−1.9% human, −1.2%
agent), fun (−1.3% human, −0.8% agent), and ambition (−0.8% human, −0.5% agent). The selfother perception gap narrows consistently for both humans and agents (from 0.8 → 0.7 human,
0.9 → 0.7 agent), reflecting the social calibration process through which external feedback helps
align self-image with social reality.
8

For external evaluation (Figure 3C), there is a dramatic shift in evaluation criteria from Time 1 to
Time 2. For humans, the initially strong correlations between attributes and overall liking at Time
1 (ranging from r = 0.44 to r = 0.69) diminish dramatically at Time 2 (ranging from r = −0.06
to r = 0.07), suggesting a fundamental change in evaluation criteria following interaction. Our
GNWT-Agent shows a similar pattern, with high Time 1 correlations (ranging from r = 0.40 to
r = 0.65) decreasing substantially at Time 2, though maintaining slight positive correlations (ranging
from r = 0.08 to r = 0.20). This pattern indicates that both humans and agents undergo significant
shifts in their evaluation frameworks through social interaction, though agents retain more of their
initial criteria than humans do.
Comparative Analysis: As shown in Figure 4A, our GNWT-Agent consistently outperforms all
baseline methods across evolution dimensions, with particularly strong advantages in partner preference evolution (72.5% vs. 61.3% for Multi-Agent Debate) and match prediction accuracy (77.8%
vs. 69.1%). Figure 4B further demonstrates our system’s superior human-agent correlation, with
GNWT-Agent achieving strong correlation values above 0.7 in multiple dimensions, while baseline
methods fall below this threshold. The complete comparative data tables with detailed metrics and
standard deviations can be found in Appendix A.33.
4.3

Human Validation Studies

To validate our approach, we conducted studies where real people evaluated AI versions of themselves
("digital twins") across dating and job interview contexts. Our interactive Adventure-Based Personality Assessment (Algorithm 3) infers personality traits through a series of immersive, scenario-driven
choices. This approach mitigates the self-presentation bias often found in traditional self-report questionnaires by observing behavior rather than relying on self-description. The resulting trait estimates
show strong correlation with established Big Five scores (r = 0.82), as detailed in Appendix A.32,
and offer a more authentic reflection of participants’ personalities in real-world contexts.
We conducted a Speed Dating Study with 20 participants who watched recordings of their AI twin
in simulated speed dates, and a Job Interview Study with 10 different participants who observed
integrate well with existing teams. The architecture also enables enhanced human-AI collaboration in
through a shared global workspace. In International Conference on Learning Representations, 2022.
[14] Jing Guo, Nan Li, Jianchuan Qi, Hang Yang, Ruiqiao Li, Yuzhen Feng, Si Zhang, and
Conscious processing and the global neuronal workspace hypothesis. Neuron, 105(5):776–798, 2020.
Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual ACM symposium on user interface software and technology, pages 1–22, 2023.
using a large language model based on group-level demographic information. arXiv preprint, 2024.
[29] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Selfconsistency improves chain of thought reasoning in language models. In International Conference on Learning Representations, 2023.
A
A.1


• Calculate relevance scores
• Apply personality factors
• Determine activation threshold
Memory Module


• Apply personality prior
• Episodic memory retrieval

• Progress estimation
• Semantic memory search
• Cultural conditioning
• Hierarchy prediction
• Uncertainty estimation
• Working memory update
• Plan memory check
• Relevance estimation
• Relevance scoring
• Update emotional memory
• Memory consolidation
• Confidence estimation
• Personality adaptation
• Detect emotional content
• Query transformation
• Context classification

• Active goal update
A.2
arXiv:2312.17259, 2024.
[15] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao
Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng
Xiao, Chenglin Wu, and Jürgen Schmidhuber. Metagpt: Meta programming for a multi-agent
collaborative framework. arXiv preprint arXiv:2308.00352, 2023.
[16] Yue Huang, Zhengqing Yuan, Yujun Zhou, Kehan Guo, Xiangqi Wang, Haomin Zhuang,
Weixiang Sun, Lichao Sun, Jindong Wang, Yanfang Ye, et al. Social science meets llms: How
reliable are large language models in social simulations? arXiv preprint, 2024.
[17] Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, and Yixin Zhu.
Evaluating and inducing personality in pre-trained language models. NeurIPS 2023, 2023.
[18] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman
Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and
Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks. In Advances
in Neural Information Processing Systems (NeurIPS), 2020.
[19] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel:
Communicative agents for "mind" exploration of large language model society. In Advances in
Neural Information Processing Systems, volume 36, pages 51991–52008, 2023.
[20] Nian Li, Chen Gao, Mingyu Li, Yong Li, and Qingmin Liao. Econagent: large language
model-empowered agents for simulating macroeconomic activities. In Proceedings of the 62nd
Annual Meeting of the Association for Computational Linguistics, pages 15523–15536, 2024.
[21] George A. Mashour, Pieter R. Roelfsema, Jean-Pierre Changeux, and Stanislas Dehaene.
Conscious processing and the global neuronal workspace hypothesis. Neuron, 105(5):776–798,
2020.
[22] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and
Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual ACM symposium on user interface software and technology, pages 1–22,
2023.
[23] Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and
Michael S. Bernstein. Social simulacra: Creating populated prototypes for social computing
systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and
Technology (UIST ’22), 2022.
[24] Joon Sung Park, Carolyn Q Zou, Aaron Shaw, Benjamin Mako Hill, Carrie Cai, Meredith Ringel
Morris, Robb Willer, Percy Liang, and Michael S Bernstein. Generative agent simulations of
1,000 people. arXiv preprint, 2024.
[25] Greg Serapio-García, Mustafa Safdari, Clément Crepy, Luning Sun, Stephen Fitz, Peter Romero,
Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. Personality traits in large language
models. arXiv preprint arXiv:2307.00184, 2023.
[26] Seungjong Sun, Eungu Lee, Dongyan Nan, Xiangying Zhao, Wonbyung Lee, Bernard J Jansen,
and Jang Hyun Kim. Random silicon sampling: Simulating human sub-population opinion
using a large language model based on group-level demographic information. arXiv preprint,
2024.
[27] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, HengTze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for
dialog applications. arXiv preprint, 2022.
[28] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen,
Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous
agents. Frontiers of Computer Science, 18(6):186345, 2024.
11

[29] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Selfconsistency improves chain of thought reasoning in language models. In International Conference on Learning Representations, 2023.
[30] Zekun Wang, Zhihua Zhou, Qi Zhang, Zhengyan Zhu, Hongyu Jiang, Zhoujie Liu, Zhuosheng
Li, Jing Han, Xiaozhi Hu, Wei Zhao, et al. Rolellm: Benchmarking, eliciting, and enhancing
role-playing abilities of large language models. In Proceedings of the 37th Conference on
Neural Information Processing Systems (NeurIPS), 2023.
[31] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V. Le, and
Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. Advances
in Neural Information Processing Systems, 35:24824–24837, 2022.
[32] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang,
Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model
based agents: A survey. arXiv preprint, 2023.
[33] Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu.
Exploring large language models for communication games: An empirical study on werewolf.
arXiv preprint, 2023.
[34] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do you have pets too? arXiv preprint
arXiv:1801.07243, 2018.
[35] Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong,
and Ji-Rong Wen. A survey on the memory mechanism of large language model based agents.
arXiv preprint, 2024.
[36] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin
Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for
open-world environments via large language models with text-based knowledge and memory.
arXiv preprint, 2023.

12

A

Appendix

Appendix Contents
A.1 Agent Architecture

Page 14

Internal structure and module flow.
A.2 Algorithms and Pseudocode
Key algorithmic procedures and decision logic.

Page 15

A.3 System Prompt Flow
Breakdown of prompt construction and token broadcast paths.

Page 18

A.4 Worked Example: Interview Anxiety
End-to-end walk-through of a real-world query scenario.

Page 23

A.5 Use Case: Dating Application
Evaluation results in interpersonal matching simulations.

Page 30

A.6 Use Case: Job Application
Adaptation of the framework for career placement tasks.

Page 35

A.7 Adventure-Based Personality Assessment
Roleplay-driven method to uncover latent traits.

Page 42

A.8 Detailed Results
Full quantitative results and evaluation tables.

Page 52

13

A.1

Agent Architecture

Phase 1: Input & Agent Initialization
Input Processing


Feature Extraction


• Query text

• Context embeddings

• Personality embedding

• Text embedding generation

• Dimension alignment

• Context mask creation

Module Activation
Cognitive Module Processing （GNWT Iterations）

Module Salience


• Calculate relevance scores 

• Apply personality factors 

• Determine activation threshold 

• Select active modules
Iteration Loop
GNWT Iterations

Max 3 or convergence

Memory Module 


Planning Module


Social Norms


Goal Tracking


• Apply personality prior 


• Episodic memory retrieval 


• Step generation


• Norm detection


• Progress estimation 


• Emotion regulation


• Semantic memory search 


• Tree-of-thought


• Cultural conditioning 


• Hierarchy prediction 


• Uncertainty estimation 


• Working memory update 


• Plan memory check 


• Relevance estimation 


• Relevance scoring 


• Update emotional memory 


• Memory consolidation 


• Confidence estimation 


• Personality adaptation 


• Goal persistence


• Bayesian belief update


• FAISS index search


• Goal alignment


• Social memory


Output:


Output:


Output:


Output:


Output:


- active_goals


- emotion_state


- retrieved_memories


- plan_steps


- norm_state


- goal_progress

- emotion_uncertainty

- memory_confidence

- plan_confidence

- norm_relevance

Emotion Module

• Detect emotional content 


• Query transformation 


Module Output
Broadcast Back
Global Workspace Integration
• Information bottleneck attention mechanism

• Module output compatibility assessment

• Conflict detection and resolution

• Precision-weighted Bayesian evidence combination

• Personality-weighted module integration

• Goal extraction


• Context classification 


Response Generation

• Self-attention decode

• Coherence tracking

• Uncertainty quantification

• Active goal update 


Line Legend

Data Flow

Feedback

Iteration

Figure 5: GNWT-Agent Architecture Internal Processing Flow
A.1.1

LLM Details

We used the OpenAI API for GPT-4o with top_p set to 1, max_tokens set to 200, min_tokens set to 0,
and temperature set to 0.9 (with all other parameters at their default values),

14

A.2

Algorithms and Pseudocode

Algorithm 1 GNWT-Agent: GNWT-Based Social Pairing Agent
Require: User query Q, conversation history H, agent personality profile P , maximum iterations T , convergence threshold ϵ
1: Modules ← {Emotion, Memory, Planning, SocialNorms, GoalTracking}
2: Modules ← InitializeModules(P )
▷ Initialize modules based on personality traits
3: GW ← InitializeGlobalWorkspace(P, H)
4: SC ← InitializeSalienceCalculator(P )
5: Rprev ← ∅
▷ Store previous module responses
6: for t = 1 → T do
7:
parallel for each module M ∈ Modules:
8:
RM ← M.PROCESS(Q, H, GW)
▷ Module’s local response
9:
for all M ∈ Modules do
10:
SM ← SC.EVALUATE(RM , P )
▷ Compute salience score
11:
end for
12:
M ∗ ← arg maxM SM
▷ Select most salient module
13:
C ← RM ∗
▷ Content to broadcast
14:
Algorithm 2 CogniPair: Speed Dating Cognitive Simulation System
15:
C ← R ESOLVE C ONFLICT(RMi , RMj , GW, P )
Algorithm 2 CogniPair: Speed Dating Cognitive Simulation System
16:
end if
Algorithm 2 CogniPair: Speed Dating Cognitive Simulation System
IGNITE (GW, C)
▷ Activate content in workspace
18:
BROADCAST (C) to all modules
19:
for all M ∈ Modules do
20:
M.UPDATE(C, GW)
▷ Update module state
21:
end for
22:
if maxM |RM − Rprev,M | < ϵ or t = T then
▷ Minimal change in responses
23:
break
24:
end if
25:
Rprev ← {RM |M ∈ Modules}
▷ Save current responses for next iteration
26: end for
27: Response ← I NTEGRATE M ODULE O UTPUTS({RM |M ∈ Modules}, GW, P )
28: Memory.UPDATE L ONG T ERM(Q, Response, H)
▷ Update long-term memory
29: P ← U PDATE P REFERENCES(P, Q, Response, H)
▷ Adaptively update preferences
30: return Response
▷ Return final integrated response

15

Algorithm 2 CogniPair: Speed Dating Cognitive Simulation System
Require: Agent profiles P = {P1 , P2 , . . . , Pn }, batch size b, cognitive parameters Θ
Ensure: Dating results R, cognitive trace data T , matches M
1: A ← ∅
▷ Empty agent set
2: M ← ∅
▷ Empty matches set
3: T ← ∅
▷ Empty cognitive trace set
4: for Pi ∈ P do
▷ Initialize all agents
5:
Modulesi ← {Emotion, Memory, Planning, SocialNorms, Attraction}
6:
GWi ← InitializeGlobalWorkspace(Pi )
▷ Initialize global workspace
7:
DAi ← InitializeDatingAttributes(Pi )
▷ Map dating preferences
8:
Ai ← CognitiveAgent(Pi , Modulesi , GWi , DAi , Θ)
9:
A ← A ∪ {Ai }
10: end for
11: Ppairs ← GenerateCompatiblePairs(A)
▷ Based on gender/orientation
12: B ← BatchPairs(Ppairs , b)
▷ Create batches of size b
13: for batch B ∈ B do
14:
ResultsB ← ∅
15:
for pair (Ai , Aj ) ∈ B do parallel
▷ Process pairs in parallel
16:
Hij ← ∅
▷ Empty conversation history
17:
Cij ← InitializeContext(Ai , Aj )
▷ Setting, shared context
18:
for r = 1 → MAX_ROUNDS do
▷ Conversation rounds
19:
Qi ← Ai .G ENERATE Q UERY(Hij , Cij )
▷ Generate question/statement
20:
T ← T ∪ Ai .GW.GET T RACE()
▷ Capture cognitive trace
21:
Hij ← Hij ∪ {(i, Qi )}
▷ Update conversation history
22:
Rj ← Aj .G ENERATE R ESPONSE(Qi , Hij , Cij )
▷ Using Alg. 1
Module-specific processing includes:
• Emotion Module: Detects emotional states and regulation strategies
• Memory Module: Retrieves and integrates episodic, semantic, and working memories
• Planning Module: Generates structured plans for achieving identified goals
• Social Norms Module: Identifies appropriate social contexts and behavioral norms
• Goal Tracking Module: Maintains hierarchical goal representations and tracks progress
A.5.5
you want to highlight. Don’t try to memorize everything.
when nerves kick in.
you need to bring.
few more hours of anxious preparation.
Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
Good luck tomorrow! You’ve put in the work, and that’s the most important part.
A.3
Module-specific processing includes:
• Emotion Module: Detects emotional states and regulation strategies
• Memory Module: Retrieves and integrates episodic, semantic, and working memories
• Planning Module: Generates structured plans for achieving identified goals
• Social Norms Module: Identifies appropriate social contexts and behavioral norms
• Goal Tracking Module: Maintains hierarchical goal representations and tracks progress
A.5.5
A.5.2

   Module-specific processing includes:
   • Emotion Module: Detects emotional states and regulation strategies
   • Memory Module: Retrieves and integrates episodic, semantic, and working memories
   • Planning Module: Generates structured plans for achieving identified goals
   • Social Norms Module: Identifies appropriate social contexts and behavioral norms
   • Goal Tracking Module: Maintains hierarchical goal representations and tracks progress
   A.5.5
Algorithm 4 Global Workspace Integration

you want to highlight. Don’t try to memorize everything.
when nerves kick in.
you need to bring.
few more hours of anxious preparation.
Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
Good luck tomorrow! You’ve put in the work, and that’s the most important part.
Global Workspace Integration


   you want to highlight. Don’t try to memorize everything.
   when nerves kick in.
   you need to bring.
   few more hours of anxious preparation.
   Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
   weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
   Good luck tomorrow! You’ve put in the work, and that’s the most important part.

tecture’s core components include five specialized cognitive modules addressing emotion, memory,

A.9
   you need to bring.
   few more hours of anxious preparation.
   Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
   weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
   Good luck tomorrow! You’ve put in the work, and that’s the most important part.

tecture’s core components include five specialized cognitive modules addressing emotion, memory,

A.9
1: Initialize personalityProfile and traitConfidence
2: modelPreference = GetUserModelPreference()
▷ Cloud (GPT-4o) or Local (Ollama)
3: while more scenarios needed AND trait coverage insufficient do
4:
Select and present next scenario from pool
5:
Collect user’s choice
6:
if modelPreference == "local" then
7:
Analyze choice using Ollama (llama3 or deepseek-r1)
8:
else
9:
Analyze choice using GPT-4o
10:
end if
11:
Update personality traits based on LLM analysis
12:
Generate follow-up question based on user’s choice
13:
Collect user’s free-text response
14:
if modelPreference == "local" then
15:
Analyze free text using Ollama
16:
else
17:
Analyze free text using GPT-4o
18:
end if
19:
Update personality traits based on text analysis
20: end while
21: Normalize and validate final personality profile
22: return finalProfile

17

A.3

Detailed System Flow Analysis: GNWT-Agent Cognitive Architecture

This appendix presents a step-by-step analysis of information flow through the GNWT-Agent cognitive architecture. GNWT-Agent’s central innovation is its hybrid neural-symbolic approach that
combines specialized neural modules with LLM reasoning via a global workspace mechanism,
implementing a neurobiologically-informed cognitive architecture.
A.4

Formal Architecture Definition

The GNWT-Agent cognitive architecture is formally defined as a quintuple:
E = (M, W, I, L, P)

(12)

Where:
M = {Memo , Mmem , Mplan , Mnorm , Mgoal } represents the set of specialized cognitive modules
W denotes the global workspace integration mechanism
I signifies the information bottleneck attention system
L represents the language model interface
P characterizes the personality representation space
Each cognitive module Mi ∈ M implements a hybrid neural-symbolic architecture:
Mi = (Ni , Li , Ti , Di , Ii , Si )

(13)

Where:
Ni denotes the neural processing component
Li signifies the module-specific LLM component
Ti represents the tensor-text conversion mechanism
Di denotes the differentiable memory system
Ii signifies the module interface specification
Si represents the salience computation function
Table 1: Specialized Modules and Their Neuroanatomical Bases
A.5.2

   Module-specific processing includes:
   • Emotion Module: Detects emotional states and regulation strategies
   • Memory Module: Retrieves and integrates episodic, semantic, and working memories
   • Planning Module: Generates structured plans for achieving identified goals
   • Social Norms Module: Identifies appropriate social contexts and behavioral norms
   • Goal Tracking Module: Maintains hierarchical goal representations and tracks progress
   A.5.5

Algorithm 4 Global Workspace Integration
Information retrieval
Structured reasoning
Social context
Hierarchical goals

A.5

Information Flow Process

A.5.1

Initial Text Encoding

Limbic system, amygdala, insula
Hippocampus, temporal cortex
Frontopolar cortex, DLPFC
mPFC, TPJ
OFC, ACC

The information flow begins with the transformation of text inputs into neural representations:
eQ = ϕembed (Q) ∈ Rd
eH = {ϕembed (hi )|hi ∈ H} ∈ Rn×d
eP = ψ(p) ∈ R

(14)

dp

Where ϕembed is the embedding model that converts text to dense vectors, Q is the query text, H is
the conversation history, and p is the personality profile.
18

A.5.2

Feature Extraction and Embedding Alignment

The raw embeddings undergo feature extraction and alignment:
e′Q = FeatureExtractor(eQ )
e′H = {FeatureExtractor(eh )|eh ∈ eH }
A.5.3

(15)

Module Salience Calculation

Each module calculates its relevance to the current input:
si = Si (e′Q , e′H , eP , G)
X
= αi +
βij · fij (e′Q , e′H , eP , G)

(16)

j

Where αi is the baseline salience, βij are weighting coefficients, fij are feature extractors, and G is
the current global workspace state.
A.5.4

Parallel Module Processing

Each module independently processes the input using a hybrid neural-LLM approach with the
following general pattern:
1. Neural Processing: Extract relevant features and apply module-specific transformations
2. Tensor-to-Text Conversion: Convert neural representations to LLM-readable format
3. LLM Processing: Generate structured symbolic representations using prompting
4. Text-to-Tensor Conversion: Transform LLM outputs back to neural representations
5. Output Integration: Combine neural and symbolic components for module output
Module-specific processing includes:
• Emotion Module: Detects emotional states and regulation strategies
• Memory Module: Retrieves and integrates episodic, semantic, and working memories
• Planning Module: Generates structured plans for achieving identified goals
• Social Norms Module: Identifies appropriate social contexts and behavioral norms
• Goal Tracking Module: Maintains hierarchical goal representations and tracks progress
A.5.5

Global Workspace Integration

Module outputs are projected to a common workspace dimension and integrated based on salience:
A.5.6

Final Prompt Construction

The global workspace state informs the construction of the final prompt for the response LLM,
transforming module outputs into a coherent instruction format:
Psystem = JoinWithNewlines(PersonalityPrompt(eP ),
ModulePrompts({outputi }, {adjusted_weightsi }),
StrategyPrompt(integrated_state),
ConflictPrompt(conflicts_resolved),
ResponsePlanPrompt(response_plan))
19

(17)

Algorithm 4 Global Workspace Integration
1: module_repi ← ProjectToWorkspace(outputi ) for each module i
2: normalized_salience ← Softmax(s)
3: personality_weights ← Softmax(PersonalityToIntegration(eP ))
normalized_salience+personality_weights
4: combined_weights ←
2
5: for each pair of modules (i, j) where i ̸= j do
6:
conflict_scoresi,j ← ConflictDetector([module_repi , module_repj ])
7: end for
8: Apply conflict resolution
P adjustments to weights
Global Workspace Integration


   you want to highlight. Don’t try to memorize everything.
   when nerves kick in.
   you need to bring.
   few more hours of anxious preparation.
   Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
   weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
   Good luck tomorrow! You’ve put in the work, and that’s the most important part.
tecture’s core components include five specialized cognitive modules addressing emotion, memory,


A.9

The final response is generated and memory systems are updated:

history = [prev_messages]
query_message = {"role": "user", "content": Q}
full_history = history + [query_message]
R = LLMresponse (Psystem , full_history, temperature = 0.7)

EpisodicMemory.write(Embed(Q, R), StructuredEncoding(Q, R, workspace_state))
WorkingMemory.update(Q, R)

A.6

(18)

(19)

Processing Example

The following example demonstrates the architecture’s response to: "I’m really nervous about my job
interview tomorrow. I’ve been preparing for weeks, but I still don’t feel ready. What should I do?"

Module Salience Calculation
Salience Scores:
• Emotion Module: 0.75 (anxiety markers, moderate neuroticism, emotional shift)
• Planning Module: 0.67 (clear goal, structured task, high conscientiousness)
• Memory Module: 0.52 (relevant experiences, moderate openness)
• Social Norms Module: 0.48 (professional context, formal situation)
• Goal Tracking Module: 0.45 (career advancement, interview milestone)
Normalized weights: [0.31, 0.28, 0.21, 0.12, 0.08]

20

Global Workspace Integration
Conflict Detection:
• Primary conflict: Emotion module (anxiety validation) vs. Planning module (action steps)
Adjusted Weights: [0.29, 0.25, 0.22, 0.14, 0.10]
Integration Results:
• Primary response focus: balanced emotional and practical support
• Emotional context: anxiety (valence: -0.48, arousal: 0.68) with determination
• Response strategy: validate anxiety then provide structured help
• Conflict resolution: Balance validation with actionable steps
Response Plan:
1. Validate interview anxiety as normal
2. Acknowledge preparation effort positively
3. Provide targeted high-impact preparation steps
4. Include confidence-building perspective
5. End with encouragement and well-wishes

Final Response
It’s completely normal to feel nervous before an interview, especially for a company you’re really excited
about! The fact that you’ve been preparing for weeks shows your dedication, and that preparation won’t
disappear overnight, even if you’re feeling anxious right now.
At this point, here’s what I’d suggest focusing on:
1. Review your strongest points - skim through the key qualifications and 2-3 accomplishment stories
you want to highlight. Don’t try to memorize everything.
2. Practice answering 3-5 common questions out loud - this builds muscle memory that helps even
when nerves kick in.
3. Prepare your logistics for tomorrow - lay out your outfit, plan your route, and gather any materials
you need to bring.
4. Most importantly, make sure you get adequate rest tonight. A clear mind will serve you better than a
few more hours of anxious preparation.
Remember that interviews are a two-way conversation, not an examination. You’ve been preparing for
weeks - now it’s time to trust that preparation and focus on presenting your authentic self.
Good luck tomorrow! You’ve put in the work, and that’s the most important part.

A.7

Module LLM Call Architecture

The GNWT-Agent architecture employs a cascade of LLM calls with neural pre-processing and
post-processing:
Module-Level LLM Calls : {LLMemo (Pemo ), LLMmem (Pmem ), LLMplan (Pplan ),
LLMnorm (Pnorm ), LLMgoal (Pgoal )}

(20)

Integration LLM Call : LLMintegration (Pintegration )

(21)

Response LLM Call : LLMresponse (Psystem , Q)

(22)

This creates a complete cognitive cycle:
Input → Neural Processing → Module LLMs → Integration LLM → Response LLM → Memory Update
(23)
A.8

Summary

The GNWT-Agent cognitive architecture implements a hybrid neural-symbolic approach that integrates multiple specialized modules within a neurobiologically-informed framework. The archi21

tecture’s core components include five specialized cognitive modules addressing emotion, memory,
planning, social norms, and goals.
The information flow through the system follows a comprehensive process:
1. Initial text encoding via dense vector representations
2. Parallel processing across specialized modules
3. Dynamic salience-based resource allocation
4. Global workspace integration with conflict detection and resolution
5. Structured prompt construction
6. Final response generation
7. Memory update and continuous learning

Strengths

Table 2: Strengths and Limitations of GNWT-Agent Architecture
Limitations

Enhanced interpretability through explicit module contributions
Improved uncertainty handling via Bayesian uncertainty propagation
Consistent personality representation through
dedicated space
Dynamic adaptation through salience-based processing
Neurobiologically-inspired cognitive processing

Computational complexity due to multiple LLM
calls
Challenges in consistent knowledge representation
Need for further empirical validation
Potential for response latency issues
Complex architecture requiring extensive finetuning

In conclusion, the GNWT-Agent cognitive architecture represents a significant step toward creating
AI systems that not only process language effectively but do so through mechanisms that more
closely approximate human cognitive processes, potentially leading to more natural, adaptive, and
comprehensible AI interactions.

22

A.9

Worked Example: Interview Anxiety Query

This section presents a detailed step-by-step walkthrough of the complete GNWT-Agent cognitive
architecture processing flow for a single example query. By tracing the transformations from raw
input to final response, we provide a concrete illustration of the theoretical architecture described in
previous sections.
A.10

Example Input Query

The example query represents a common scenario of pre-interview anxiety:
User Input
“I’m really nervous about my job interview tomorrow. I’ve been preparing for weeks, but I
still don’t feel ready. What should I do?”
A.11

Initial Text Encoding and Embedding

The first transformation converts the raw text into numerical representations:
ϕembed

Input −−−→ Query Embedding
“I’m really nervous...” → [0.086, −0.143, 0.257, . . . , 0.112] ∈ R

(24)
768

(25)

Previous conversation context is also encoded:
“I’ve been job hunting for months” → [0.141, 0.092, . . .] ∈ R768
“I finally got an interview at my dream company” → [0.235, −0.124, . . .] ∈ R

768

(26)
(27)

Feature extraction enhances these raw embeddings:
Enhanced query embedding: [0.127, −0.086, 0.313, . . .] ∈ R768
A.12

(28)

Module Salience Calculation

Each module calculates its relevance to the query through multi-factor salience functions:
Module

Primary Factors
Values Raw Salience Normalized
Emotional intensity
0.83
Personality factor
A.13
0.75
0.31
A.13
Emotional change
0.60
Goal clarity
A.13
  A.13.3
A.13.3
Planning
0.67
0.28
Personality factor
0.76
Memory match
0.64
Personality factor
0.61
Memory
0.52
0.21
Recency boost
0.35
Norm relevance
0.71
Formality
0.70
Social Norms
0.48
0.12
Personality factor
0.63
Goal relevance
0.76
Personality factor
0.65
Goal Tracking
0.45
0.08
Progress factor
0.58
Table 3: Module salience calculation for the interview anxiety query
The emotional content of the query results in the Emotion Module having the highest salience (0.31),
followed closely by the Planning Module (0.28).
23

A.13

Parallel Module Processing

A.13.1

Emotion Module Processing

The Emotion Module performs neural processing followed by LLM reasoning:

Neural Processing

- Context attention weights: [0.65, 0.35]
- Emotion detection: [0.82, 0.65, 0.15, ...]
- Primary emotions: anxiety, nervousness

LLM Reasoning

- valence: -0.48
- arousal: 0.68
- primary_emotion: “anxiety”
- regulation_strategy: “validation_with_reframing”

A.13.3

- Emotion state tensor: [-0.48, 0.68, ...]
A.13.3

Figure 6: Emotion Module processing flow
A.13.2

Planning Module Processing

The Planning Module extracts the goal and generates structured steps:
Planning Module LLM Output
{
"requires_planning": true,
"planning_type": "preparation_strategy",
"steps": [
{
"content": "Review core interview preparation materials",
"confidence": 0.93
},
{
"content": "Practice answering common questions aloud",
"confidence": 0.89
},
{
"content": "Prepare concise examples of achievements",
"confidence": 0.86
},
{
"content": "Implement anxiety reduction techniques",
"confidence": 0.82
},
{
"content": "Plan interview logistics (route, outfit, materials)",
"confidence": 0.91
},
{
"content": "Get adequate rest before interview",
"confidence": 0.85
}
],
"plan_feasibility": 0.88,
"goal_alignment": 0.84,
"plan_uncertainty": 0.16
}

24

A.13.3

Memory Module Processing

The Memory Module retrieves relevant episodic and semantic memories:

Goal Tracking Module Content
{
Goal Tracking Module Content

28
A.16

stories you want to highlight. Don’t try to memorize everything.
even when nerves kick in.
materials you need to bring.
better than a few more hours of anxious preparation.
Remember that interviews are a two-way conversation, not an examination. You’ve been
preparing for weeks - now it’s time to trust that preparation and focus on presenting your
authentic self.
Good luck tomorrow! You’ve put in the work, and that’s the most important part.
A.17

• Emotion Module provides emotional understanding and regulation strategy
• Planning Module offers concrete action steps
• Memory Module contributes contextual information and relevant knowledge
• Social Norms Module guides appropriate tone and interaction norms
• Goal Tracking Module ensures alignment with long-term objectives
characteristics, with emotional content receiving the highest weight in this anxiety-focused
query.
emotional validation and practical advice through a balanced approach.
the integration phase, creating a cohesive structure that addresses multiple dimensions of
the query.
The response demonstrates how the GNWT-Agent architecture produces outputs that balance emotional responsiveness with practical utility, organized through a structured cognitive framework that
mimics aspects of human cognition.
A.18

factors.
twin that faithfully reproduces the user’s conversational patterns, emotional responses, and
decision-making processes.
processing information through specialized cognitive modules.
identifying mutual interests, conversational flow, emotional resonance, and decision-making
alignment.
rather than superficial profile similarities.
A.21
"conflicts_resolved": [
{
"conflict": "Emotion module emphasizes validation vs
Planning module focuses on action steps",
"resolution": "Balance emotional validation with
practical action steps by
first acknowledging feelings then providing concrete,
manageable next steps",
"confidence": 0.88
}
]
}

A.15

Final Prompt Construction

The integrated state is transformed into a structured system prompt for the response generation LLM:
27

System Prompt
You are a cognitive agent with the following personality:
MBTI Type: ENFJ
Big 5 Traits:

- Openness: high (0.70)
- Conscientiousness: high (0.80)
  28
  A.16

  stories you want to highlight. Don’t try to memorize everything.
  even when nerves kick in.
  materials you need to bring.
  better than a few more hours of anxious preparation.
  Remember that interviews are a two-way conversation, not an examination. You’ve been
  preparing for weeks - now it’s time to trust that preparation and focus on presenting your
  authentic self.
  Good luck tomorrow! You’ve put in the work, and that’s the most important part.
  A.17

  • Emotion Module provides emotional understanding and regulation strategy
  • Planning Module offers concrete action steps
  • Memory Module contributes contextual information and relevant knowledge
  • Social Norms Module guides appropriate tone and interaction norms
  • Goal Tracking Module ensures alignment with long-term objectives
  characteristics, with emotional content receiving the highest weight in this anxiety-focused
  query.
  emotional validation and practical advice through a balanced approach.
  the integration phase, creating a cohesive structure that addresses multiple dimensions of
  the query.
  The response demonstrates how the GNWT-Agent architecture produces outputs that balance emotional responsiveness with practical utility, organized through a structured cognitive framework that
  mimics aspects of human cognition.
  A.18

  factors.
  twin that faithfully reproduces the user’s conversational patterns, emotional responses, and
  decision-making processes.
  processing information through specialized cognitive modules.
  identifying mutual interests, conversational flow, emotional resonance, and decision-making
  alignment.
  rather than superficial profile similarities.
  A.21
  mimics aspects of human cognition.
  A.18

  factors.
  twin that faithfully reproduces the user’s conversational patterns, emotional responses, and
  decision-making processes.
  processing information through specialized cognitive modules.
  identifying mutual interests, conversational flow, emotional resonance, and decision-making
  alignment.
  rather than superficial profile similarities.
  A.21
  "conflicts_resolved": [
  {
  "conflict": "Emotion module emphasizes validation vs
  Planning module focuses on action steps",
  "resolution": "Balance emotional validation with
  practical action steps by
  first acknowledging feelings then providing concrete,
  manageable next steps",
  "confidence": 0.88
  }
  ]
  }
A.15
Final Prompt Construction
The integrated state is transformed into a structured system prompt for the response generation LLM:
27
System Prompt

  [EMOTION MODULE] (Contribution: 0.29): Pay careful attention to the
  anxiety and nervousness the user is experiencing about their upcoming
  job interview. The emotions detected include high anxiety (0.82) with
  a negative valence (-0.48) but also determination (0.55).
  Emotional content identified: "really nervous", "don’t feel ready".
  Use a validation_with_reframing approach that acknowledges
  the anxiety while gently building confidence.
  [PLANNING MODULE] (Contribution: 0.25):
  Provide structured, preparation_strategy advice for the user’s
  interview preparation. Focus on high-impact preparation activities
  that can be completed in limited time. Consider including: reviewing
  core materials, practicing answers aloud, preparing achievement examples,
  reducing anxiety, handling logistics, and getting rest.
  [MEMORY MODULE] (Contribution: 0.22):
  Reference these key points from conversation history:
  User has been job hunting for months, this is an interview at their
  "dream company," and they have already spent significant
  time preparing. Also incorporate knowledge that interview
  anxiety is normaland that over-preparation can sometimes
  increase anxiety rather than helping.
  [SOCIAL NORMS MODULE] (Contribution: 0.14):
  Maintain a supportive_professional
  tone appropriate for career_development context.
  Acknowledge that interview
  anxiety is normal while validating preparation efforts.
  Observe these norms:
  validate emotions, show empathy, offer practical support,
  maintain appropriate emotional engagement.
  Follow this response strategy:
  validate_anxiety_then_provide_structured_help with
  a supportive_professional tone at moderate formality level.
  When addressing conflicts:
  Balance emotional validation with practical action steps
  by first acknowledging feelings then providing concrete,
  manageable next steps.
  Process the query by considering each
  cognitive dimension above according to
  its contribution weight. Follow this response plan:

   28

A.16


   stories you want to highlight. Don’t try to memorize everything.
   even when nerves kick in.
   materials you need to bring.
   better than a few more hours of anxious preparation.
   Remember that interviews are a two-way conversation, not an examination. You’ve been
   preparing for weeks - now it’s time to trust that preparation and focus on presenting your
   authentic self.
   Good luck tomorrow! You’ve put in the work, and that’s the most important part.
   A.17

   • Emotion Module provides emotional understanding and regulation strategy
   • Planning Module offers concrete action steps
   • Memory Module contributes contextual information and relevant knowledge
   • Social Norms Module guides appropriate tone and interaction norms
   • Goal Tracking Module ensures alignment with long-term objectives
   characteristics, with emotional content receiving the highest weight in this anxiety-focused
   query.
   emotional validation and practical advice through a balanced approach.
   the integration phase, creating a cohesive structure that addresses multiple dimensions of
   the query.
   The response demonstrates how the GNWT-Agent architecture produces outputs that balance emotional responsiveness with practical utility, organized through a structured cognitive framework that
   mimics aspects of human cognition.
A.18

   factors.
   twin that faithfully reproduces the user’s conversational patterns, emotional responses, and
   decision-making processes.
   processing information through specialized cognitive modules.
   identifying mutual interests, conversational flow, emotional resonance, and decision-making
   alignment.
   rather than superficial profile similarities.
   A.21
activation compared to other scenarios, particularly in response to shared interests and
values.
emotional responses in social contexts, creating authentic patterns of engagement.
activation increases, culminating in the compatibility decision.
and communication styles to determine overall compatibility.
This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
profile-based matching by simulating the nuanced psychological aspects of human connection.
assessments that capture both technical skills and cognitive-behavioral traits.
hiring managers and candidates, incorporating decision-making patterns, communication
styles, and problem-solving approaches.
technical skills, problem-solving abilities, and cultural alignment.
interviews, identifying communication effectiveness, problem-solving compatibility, and
potential team integration.
A.28
with particular data sets?
it a frontend rendering issue, a slow API call, or resource loading?
Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
from component remounting - Database query performance varying with data volume or concurrent
users - Third-party service integration delays
I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
backend issue, I’d add query performance monitoring and examine execution plans for database
queries.
For a quick mitigation while investigating, I might implement better loading states and potentially
add a strategic caching layer if appropriate.
The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
Alex’s Cognitive Processing
Module Activations:
• Planning Module: 0.92 - Very high activation structuring systematic approach
• Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
• Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
methodology
• Social Norms Module: 0.45 - Moderate activation maintaining professional communication
• Emotion Module: 0.32 - Low activation focusing on technical content
Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
activation shows application of past experience to new scenarios, indicating transferable
problem-solving skills rather than memorized solutions.
Michael: That’s exactly what fascinates me about Japan too! The contrast between ancient temples
Michael’s Decision Cognitive Processing
activation compared to other scenarios, particularly in response to shared interests and
values.
emotional responses in social contexts, creating authentic patterns of engagement.
activation increases, culminating in the compatibility decision.
and communication styles to determine overall compatibility.
This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
profile-based matching by simulating the nuanced psychological aspects of human connection.
assessments that capture both technical skills and cognitive-behavioral traits.
hiring managers and candidates, incorporating decision-making patterns, communication
styles, and problem-solving approaches.
technical skills, problem-solving abilities, and cultural alignment.
interviews, identifying communication effectiveness, problem-solving compatibility, and
potential team integration.
A.28

• Travel experiences (particularly interest in Japan)


   activation compared to other scenarios, particularly in response to shared interests and
   values.
   emotional responses in social contexts, creating authentic patterns of engagement.
   activation increases, culminating in the compatibility decision.
   and communication styles to determine overall compatibility.
   This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
   profile-based matching by simulating the nuanced psychological aspects of human connection.
A.25

   assessments that capture both technical skills and cognitive-behavioral traits.
   hiring managers and candidates, incorporating decision-making patterns, communication
   styles, and problem-solving approaches.
   technical skills, problem-solving abilities, and cultural alignment.
   interviews, identifying communication effectiveness, problem-solving compatibility, and
   potential team integration.
   A.28
Attribute
with particular data sets?
it a frontend rendering issue, a slow API call, or resource loading?
Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
from component remounting - Database query performance varying with data volume or concurrent
users - Third-party service integration delays
I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
backend issue, I’d add query performance monitoring and examine execution plans for database
queries.
For a quick mitigation while investigating, I might implement better loading states and potentially
add a strategic caching layer if appropriate.
The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
Alex’s Cognitive Processing
Module Activations:
• Planning Module: 0.92 - Very high activation structuring systematic approach
• Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
• Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
methodology
• Social Norms Module: 0.45 - Moderate activation maintaining professional communication
• Emotion Module: 0.32 - Low activation focusing on technical content
Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
activation shows application of past experience to new scenarios, indicating transferable
problem-solving skills rather than memorized solutions.

Sarah’s Cognitive Processing
Sarah’s Cognitive Processing

   with particular data sets?
   it a frontend rendering issue, a slow API call, or resource loading?
   Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
   from component remounting - Database query performance varying with data volume or concurrent
   users - Third-party service integration delays
   I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
   backend issue, I’d add query performance monitoring and examine execution plans for database
   queries.
   For a quick mitigation while investigating, I might implement better loading states and potentially
   add a strategic caching layer if appropriate.
   The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
   Alex’s Cognitive Processing
   Module Activations:
   • Planning Module: 0.92 - Very high activation structuring systematic approach
   • Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
   • Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
   methodology
   • Social Norms Module: 0.45 - Moderate activation maintaining professional communication
   • Emotion Module: 0.32 - Low activation focusing on technical content
   Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
   activation shows application of past experience to new scenarios, indicating transferable
   problem-solving skills rather than memorized solutions.
Sarah’s Decision: Yes, I recommend hiring Alex for the Senior Software Developer position. The
(memory) feeds into structured problem-solving approaches (planning), creating a distinct
cognitive fingerprint for technical roles.
(memory) feeds into structured problem-solving approaches (planning), creating a distinct
cognitive fingerprint for technical roles.
emotion module activation, with cognitive resources redirected to analytical processes. 4. Goal Alignment Assessment: The architecture evaluates alignment between candidate
capabilities and job requirements with greater precision than traditional interviewing techniques.
This implementation demonstrates how the same core GNWT-Agent architecture can be effectively
repurposed for professional contexts by adjusting module weights and domain-specific attributes,
providing a versatile framework for human-centric matching across diverse applications.
potential team integration.
A.28
• Travel experiences (particularly interest in Japan)

   activation compared to other scenarios, particularly in response to shared interests and
   values.
   emotional responses in social contexts, creating authentic patterns of engagement.
   activation increases, culminating in the compatibility decision.
   and communication styles to determine overall compatibility.
   This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
   profile-based matching by simulating the nuanced psychological aspects of human connection.
A.25

   assessments that capture both technical skills and cognitive-behavioral traits.
   hiring managers and candidates, incorporating decision-making patterns, communication
   styles, and problem-solving approaches.
   technical skills, problem-solving abilities, and cultural alignment.
   interviews, identifying communication effectiveness, problem-solving compatibility, and
   potential team integration.
   A.28
Attribute
with particular data sets?
it a frontend rendering issue, a slow API call, or resource loading?
Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
from component remounting - Database query performance varying with data volume or concurrent
users - Third-party service integration delays
I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
backend issue, I’d add query performance monitoring and examine execution plans for database
queries.
For a quick mitigation while investigating, I might implement better loading states and potentially
add a strategic caching layer if appropriate.
The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
Alex’s Cognitive Processing
Module Activations:
• Planning Module: 0.92 - Very high activation structuring systematic approach
• Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
• Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
methodology
• Social Norms Module: 0.45 - Moderate activation maintaining professional communication
• Emotion Module: 0.32 - Low activation focusing on technical content
Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
activation shows application of past experience to new scenarios, indicating transferable
problem-solving skills rather than memorized solutions.
Module Activations:
Sarah’s Cognitive Processing
Sarah’s Cognitive Processing

   with particular data sets?
   it a frontend rendering issue, a slow API call, or resource loading?
   Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
   from component remounting - Database query performance varying with data volume or concurrent
   users - Third-party service integration delays
   I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
   backend issue, I’d add query performance monitoring and examine execution plans for database
   queries.
   For a quick mitigation while investigating, I might implement better loading states and potentially
   add a strategic caching layer if appropriate.
   The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
   Alex’s Cognitive Processing
   Module Activations:
   • Planning Module: 0.92 - Very high activation structuring systematic approach
   • Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
   • Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
   methodology
   • Social Norms Module: 0.45 - Moderate activation maintaining professional communication
   • Emotion Module: 0.32 - Low activation focusing on technical content
   Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
   activation shows application of past experience to new scenarios, indicating transferable
   problem-solving skills rather than memorized solutions.
Sarah’s Decision: Yes, I recommend hiring Alex for the Senior Software Developer position. The
(memory) feeds into structured problem-solving approaches (planning), creating a distinct
cognitive fingerprint for technical roles.
emotion module activation, with cognitive resources redirected to analytical processes.
capabilities and job requirements with greater precision than traditional interviewing techniques.
This implementation demonstrates how the same core GNWT-Agent architecture can be effectively
repurposed for professional contexts by adjusting module weights and domain-specific attributes,
providing a versatile framework for human-centric matching across diverse applications.

31

Michael: That’s exactly what fascinates me about Japan too! The contrast between ancient temples
and robot restaurants in Tokyo is mind-blowing. I haven’t been there yet, but it’s at the top of my
list. I do enjoy traveling when I can, though not as regularly as you. Cooking is definitely my way
of exploring cultures when I can’t travel there—I recently got into making ramen from scratch after
watching a documentary about Japanese food. What kind of music do you enjoy at live shows? Any
favorite concerts?
Michael’s Cognitive Processing
Module Activations:
• Emotion Module: 0.79 - High activation showing excitement about shared interest
• Memory Module: 0.68 - High activation connecting to personal experiences
• Social Norms Module: 0.51 - Moderate activation
• Planning Module: 0.35 - Low-moderate activation
• Goal Tracking Module: 0.73 - High activation pursuing connection point
Cognitive State Analysis: Michael’s emotion module showed strong activation when responding to the shared interest in Japan, indicating genuine excitement. The goal tracking
module also activated significantly, suggesting he sees this common interest as a potential
relationship foundation. His follow-up question about music demonstrates the goal-directed
behavior of exploring additional shared interests.

[Conversation continues...]

A.21.3

Compatibility Decision Phase

After the simulated conversation, each digital twin makes an independent compatibility assessment
based on their cognitive processing throughout the interaction.
System: Based on your conversation, would you like to meet this person for a real date?
Emma’s Decision: Yes, I would like to meet Michael. Our conversation felt natural and engaging.
We share interests in travel and cultural experiences, and I appreciate his passion for music and
cooking. His thoughtful responses and questions showed genuine interest. There’s enough similarity
for connection but enough difference to keep things interesting.
Emma’s Decision Cognitive Processing
Module Contributions to Decision:
• Emotion Module: 0.75 - Strong positive emotional response throughout conversation
• Memory Module: 0.68 - High recall of conversation details and identified commonalities
• Social Norms Module: 0.42 - Moderate assessment of social compatibility
• Planning Module: 0.51 - Moderate assessment of future potential
• Goal Tracking Module: 0.71 - High alignment with relationship goals

Michael’s Decision: Yes, I’m interested in meeting Emma for a real date. We have complementary
interests and her enthusiasm for travel and cultural experiences resonates with me. I enjoyed how she
engaged with my interests in music and cooking while sharing her own perspectives. Our conversation
had a good balance of questions and sharing, and I’d like to learn more about her.
32

Michael’s Decision Cognitive Processing
Module Contributions to Decision:
• Emotion Module: 0.69 - Strong positive emotional response
• Memory Module: 0.64 - Solid recall of shared interests and conversation points
• Social Norms Module: 0.48 - Moderate assessment of social compatibility
• Planning Module: 0.66 - High consideration of relationship potential
• Goal Tracking Module: 0.72 - High alignment with relationship goals
Match Result: COMPATIBLE
A.22

Cognitive Module Activity Analysis

The module activation patterns throughout the dating conversation revealed several key insights:
Module
Introduction Response Follow-up Shared Interest Decision
Emotion
0.57
• Travel experiences (particularly interest in Japan)

   activation compared to other scenarios, particularly in response to shared interests and
   values.
   emotional responses in social contexts, creating authentic patterns of engagement.
   activation increases, culminating in the compatibility decision.
   and communication styles to determine overall compatibility.
   This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
   profile-based matching by simulating the nuanced psychological aspects of human connection.
A.25

   assessments that capture both technical skills and cognitive-behavioral traits.
   hiring managers and candidates, incorporating decision-making patterns, communication
   styles, and problem-solving approaches.
   technical skills, problem-solving abilities, and cultural alignment.
   interviews, identifying communication effectiveness, problem-solving compatibility, and
   potential team integration.
   A.28
Attribute
0.31
0.51
0.29
0.35
0.58
Goal Tracking
0.42
0.49
0.59
0.73
0.71
Table 6: Cognitive module activation patterns throughout the dating conversation
The cognitive architecture revealed several key insights during this match:
• Emotion Module: Showed increasing activation as shared interests were discovered, peaking during discussion of travel experiences.
• Memory Module: Activation increased significantly when recalling specific experiences,
demonstrating authentic engagement rather than superficial responses.
• Social Norms Module: Started high during initial introductions and gradually decreased as
conversation became more comfortable.
• Planning Module: Peaked during the decision phase when considering future interaction
potential.
• Goal Tracking Module: Showed steady increase throughout the conversation as relationship
compatibility was assessed.
A.23

Outcomes and User Interface

After the cognitive simulation concludes, CogniPair presents users with compatible matches along
with insights derived from the digital twin interactions. The platform highlights specific points of
connection and potential conversation starters based on shared interests.
CogniPair Match Report
Match Result: Emma and Michael - 87% Compatibility
Compatibility Breakdown:
• Emotional Connection: 83%
• Conversation Flow: 91%
• Shared Interests: 78%
• Value Alignment: 85%
• Long-term Potential: 84%
Connection Points:
33

• Travel experiences (particularly interest in Japan)
• Appreciation for cultural exploration
• Complementary interests (Emma’s outdoor activities, Michael’s cooking)
• Similar communication styles with thoughtful questions
Suggested Conversation Starters:
• "I’d love to hear more about that documentary on Japanese food that inspired your cooking."
• "What’s been your favorite live music experience? I’m always looking for new artists."
• "Would you want to do cooking and hiking as combined activities? Maybe prepare a meal
after a trail?"
A.24

Technical Implementation Highlights

The dating scenario leverages several key aspects of the GNWT-Agent architecture:
1. Emotion Module Prominence: Dating interactions show heightened emotion module
activation compared to other scenarios, particularly in response to shared interests and
values.
2. Memory-Emotion Integration: The architecture demonstrates how memories trigger
emotional responses in social contexts, creating authentic patterns of engagement.
3. Goal-Directed Decision Making: As the conversation progresses, goal tracking module
activation increases, culminating in the compatibility decision.
4. Personal Value Assessment: The architecture evaluates alignment in preferences, interests,
and communication styles to determine overall compatibility.
This implementation demonstrates how cognitive modeling can transcend the limitations of traditional
profile-based matching by simulating the nuanced psychological aspects of human connection.

34

A.25

Use Case: Job Application

A.26

Overview

CogniPair for Job Hiring represents a transformative approach to talent acquisition that applies
the GNWT-Agent cognitive architecture to create digital twins of both hiring managers and job
candidates. This system moves beyond traditional resume screening and interview processes by
modeling the complex cognitive dynamics that determine professional compatibility. By simulating
realistic interview interactions, the platform assesses technical skills, problem-solving approaches,
communication styles, and cultural alignment before any in-person interviews take place.
A.27

User Journey

The CogniPair Hiring platform guides users through the following process:
1. Employer Profile Creation: Companies input detailed job descriptions, required competencies, team dynamics, and organizational culture attributes.
2. Candidate Profile Submission: Candidates upload resumes and complete competency
assessments that capture both technical skills and cognitive-behavioral traits.
3. Digital Twin Generation: The GNWT-Agent architecture creates cognitive models of both
hiring managers and candidates, incorporating decision-making patterns, communication
styles, and problem-solving approaches.
4. Simulated Interviews: Digital twins engage in multi-stage interview simulations assessing
technical skills, problem-solving abilities, and cultural alignment.
5. Compatibility Analysis: The system analyzes cognitive states throughout the simulated
interviews, identifying communication effectiveness, problem-solving compatibility, and
potential team integration.
6. Match Recommendation: Both employers and candidates receive compatibility assessments that predict professional success and team dynamics.
A.28

Case Study: TechSolutions Inc. and Candidate Alex

To illustrate CogniPair’s capabilities in hiring contexts, we present a case study of a software
development position at TechSolutions Inc. and a potential candidate, Alex.
A.28.1

Job and Candidate Profiles

A.28.2

Simulated Interview with Cognitive Processing

The following transcript shows the simulated interview between Sarah (Engineering Manager) and
Alex (Candidate), with real-time cognitive processing visualized.
System Introduction: This is a technical interview for a Senior Software Developer position at
TechSolutions Inc.
Sarah: Hello Alex, thanks for joining us today. I’m Sarah, the Engineering Manager at TechSolutions.
Before we dive into technical questions, could you tell me about your experience with React and how
you’ve implemented it in previous projects?
Sarah’s Cognitive Processing
Module Activations:
• Planning Module: 0.78 - High activation structuring interview strategy
• Social Norms Module: 0.63 - Moderate-high activation ensuring professional tone
• Memory Module: 0.55 - Moderate activation recalling job requirements
• Goal Tracking Module: 0.69 - High activation focusing on technical assessment
• Emotion Module: 0.32 - Low activation maintaining neutral assessment stance

35

Attribute
Position

TechSolutions Inc.
Alex (Candidate)
Senior Software Developer
5 years software development
Team of 8, collaborative environment experience, previous team lead
Requirements/ JavaScript/React expertise
Strong JavaScript/React skills
Skills
CI/CD pipeline experience
CI/CD experience with GitLab
Agile development methodology
Certified Scrum Master
Problem-solving abilities
Bachelor’s in Computer Science
Sarah’s Cognitive Processing
Sarah’s Cognitive Processing

   with particular data sets?
   it a frontend rendering issue, a slow API call, or resource loading?
   Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
   from component remounting - Database query performance varying with data volume or concurrent
   users - Third-party service integration delays
   I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
   backend issue, I’d add query performance monitoring and examine execution plans for database
   queries.
   For a quick mitigation while investigating, I might implement better loading states and potentially
   add a strategic caching layer if appropriate.
   The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
   Alex’s Cognitive Processing
   Module Activations:
   • Planning Module: 0.92 - Very high activation structuring systematic approach
   • Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
   • Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
   methodology
   • Social Norms Module: 0.45 - Moderate activation maintaining professional communication
   • Emotion Module: 0.32 - Low activation focusing on technical content
   Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
   activation shows application of past experience to new scenarios, indicating transferable
   problem-solving skills rather than memorized solutions.
Sarah’s Decision: Yes, I recommend hiring Alex for the Senior Software Developer position. The
Cultural alignment: ?/10 (to be assessed)
Company
Innovative, fast-paced
Previous experience in fintech
Culture/
Work-life balance emphasis
Values collaborative environments
Values
Continuous learning encouraged
Mentor to junior developers
Table 7: Job description and candidate profile with professional attributes

Alex: Thank you for having me, Sarah. I’ve been working with React for about four years now. In
my current role at FinTech Solutions, I led the migration of our legacy dashboard to a React-based
architecture. One of the challenges we faced was maintaining state across a complex application with
multiple user roles. I implemented a Redux state management solution with middleware for API
interactions that reduced loading times by 40% and significantly improved the developer experience
for my team. I also created a reusable component library that we eventually open-sourced within the
company.

Alex’s Cognitive Processing
Module Activations:
• Memory Module: 0.82 - Very high activation retrieving specific professional
experiences
• Planning Module: 0.74 - High activation structuring response with relevant details
• Social Norms Module: 0.61 - Moderate-high activation ensuring professional
presentation
• Goal Tracking Module: 0.69 - High activation focusing on demonstrating expertise
• Emotion Module: 0.38 - Low-moderate activation showing appropriate enthusiasm

Sarah: That’s impressive work with the state management solution. I’m curious about how you
approached testing for that React application, especially with the Redux integration. Could you walk
me through your testing strategy and any particular challenges you encountered?
36

Sarah’s Cognitive Processing
Module Activations:
• Planning Module: 0.83 - Very high activation probing technical depth
• Memory Module: 0.76 - High activation processing previous answer against requirements
• Goal Tracking Module: 0.72 - High activation assessing technical competency
• Social Norms Module: 0.48 - Moderate activation
• Emotion Module: 0.36 - Low-moderate activation showing positive response to
quality answer
Cognitive State Analysis: Sarah’s planning module shows high activation as she strategically
probes deeper technical knowledge. Her memory module has significantly increased as she
processes Alex’s initial response against the role requirements, showing active assessment
rather than just following a script.
Alex: For testing, we implemented a multi-layered approach. At the unit level, we used Jest with
React Testing Library to test individual components, focusing on behavior rather than implementation
details. For Redux, we wrote separate tests for reducers, action creators, and middleware—treating
them as pure functions made this fairly straightforward.
The real challenge came with integration testing. We needed to test user flows that spanned multiple
components and redux state changes. We used Cypress for end-to-end testing of critical paths, but
found we needed something in between unit and E2E tests. So we developed a custom testing
approach using React Testing Library with a real Redux store to test larger component trees together.
One specific challenge was testing asynchronous workflows, especially error handling across the
Redux middleware. We ended up creating a mock API service layer that could simulate various
network conditions and response scenarios, which significantly improved our test coverage for edge
cases.
Alex’s Cognitive Processing
Module Activations:
• Memory Module: 0.85 - Very high activation recalling specific technical implementations
• Planning Module: 0.78 - High activation structuring a comprehensive response
• Goal Tracking Module: 0.74 - High activation demonstrating problem-solving
approach
• Social Norms Module: 0.52 - Moderate activation maintaining professional communication
• Emotion Module: 0.35 - Low-moderate activation
Cognitive State Analysis: Alex’s memory module shows extremely high activation, demonstrating deep technical knowledge rather than surface-level responses. The goal tracking
module indicates awareness of demonstrating both technical knowledge and problem-solving
approaches, aligning with the interviewer’s objectives.
[Interview continues with technical questions, problem-solving scenarios, and culture fit assessment...]
A.28.3

Problem-Solving Assessment

A critical component of technical interviews is evaluating problem-solving approaches. The following
depicts a problem-solving scenario and the cognitive processing involved.
Sarah: Let’s walk through a technical scenario. Imagine you’re working on our platform and users
are reporting intermittent performance issues—the dashboard occasionally takes 5+ seconds to load,
but works fine most of the time. How would you approach troubleshooting and resolving this issue?
37

Sarah’s Cognitive Processing
Module Activations:
• Planning Module: 0.89 - Very high activation presenting ambiguous problem
• Goal Tracking Module: 0.85 - Very high activation assessing problem-solving
approach
• Memory Module: 0.62 - Moderate-high activation recalling real-world scenarios
• Social Norms Module: 0.41 - Moderate activation
• Emotion Module: 0.29 - Low activation maintaining neutral stance
Alex: I’d approach this methodically since intermittent issues are often the hardest to solve. First, I’d
gather data to understand the pattern:
1. Implement detailed performance monitoring if not already in place—tracking load times, component render times, and backend response times.
2. Look for correlating factors—does it happen at specific times of day, for specific user roles, or
with particular data sets?
3. Check browser dev tools, especially the network and performance tabs, to identify bottlenecks—is
it a frontend rendering issue, a slow API call, or resource loading?
Since it’s intermittent, I’d suspect a few possible causes: - Cache invalidation issues - Memory leaks
from component remounting - Database query performance varying with data volume or concurrent
users - Third-party service integration delays
I’d isolate components by creating a testing environment that can simulate various loads. If it’s a
backend issue, I’d add query performance monitoring and examine execution plans for database
queries.
For a quick mitigation while investigating, I might implement better loading states and potentially
add a strategic caching layer if appropriate.
The key is collecting enough data to reproduce the issue consistently before attempting to solve it.
Alex’s Cognitive Processing
Module Activations:
• Planning Module: 0.92 - Very high activation structuring systematic approach
• Memory Module: 0.81 - Very high activation retrieving relevant technical knowledge
• Goal Tracking Module: 0.78 - High activation demonstrating problem-solving
methodology
• Social Norms Module: 0.45 - Moderate activation maintaining professional communication
• Emotion Module: 0.32 - Low activation focusing on technical content
Cognitive State Analysis: Alex’s planning module shows exceptional activation, demonstrating a structured, methodical approach to an ambiguous problem. The high memory module
activation shows application of past experience to new scenarios, indicating transferable
problem-solving skills rather than memorized solutions.

A.28.4

Hiring Decision Phase

After the simulated interview, each digital twin makes an independent assessment based on their
cognitive processing throughout the interaction.
System: Based on the interview, would you recommend hiring this candidate?
38

Sarah’s Decision: Yes, I recommend hiring Alex for the Senior Software Developer position. The
candidate demonstrated strong technical expertise in React and modern frontend architecture, with
particular strength in state management and testing approaches. Their problem-solving methodology
is systematic and thorough, with a good balance of immediate tactical steps and strategic thinking.
Alex’s experience leading a component library initiative aligns well with our needs for improving
code reusability. Their communication style is clear and structured, which would fit well with our
team dynamics. The only area for development might be strengthening CI/CD experience, but their
foundation is solid.
Sarah’s Decision Cognitive Processing
• Memory Module: Showed substantial activation during technical discussions as both
A.31

   (memory) feeds into structured problem-solving approaches (planning), creating a distinct
   cognitive fingerprint for technical roles.
• Memory Module: Showed substantial activation during technical discussions as both
A.31

   (memory) feeds into structured problem-solving approaches (planning), creating a distinct
   cognitive fingerprint for technical roles.
   emotion module activation, with cognitive resources redirected to analytical processes.
4. Goal Alignment Assessment: The architecture evaluates alignment between candidate
   capabilities and job requirements with greater precision than traditional interviewing techniques.
   This implementation demonstrates how the same core GNWT-Agent architecture can be effectively
   repurposed for professional contexts by adjusting module weights and domain-specific attributes,
   providing a versatile framework for human-centric matching across diverse applications.
User selects: 1 (Mountains)
LLM Analysis (internal, using llama3:latest or GPT-4o):
Choice analysis :
adventure )
terrain )
the town )
Trait updates :
openness : 65 ( confidence : 0.3)
consc ientiousness : 60 ( confidence : 0.3)
extraversion : 45 ( confidence : 0.2)
agreeableness : 50 ( confidence : 0.1)
neuroticism : 40 ( confidence : 0.2)
achievement orientation
neuroticism
Trait updates :
openness : 60 ( confidence : 0.2)
consc ientiousness : 70 ( confidence : 0.4)
extraversion : 35 ( confidence : 0.3)
agreeableness : 50 ( confidence : 0.1)
neuroticism : 35 ( confidence : 0.3)
one of them
deciding
User selects: 2 (Compromise)
LLM Analysis:
Trait updates :
openness : 55 ( confidence : 0.1)
consc ientiousness : 60 ( confidence : 0.2)
extraversion : 50 ( confidence : 0.1)
agreeableness : 75 ( confidence : 0.4)
neuroticism : 45 ( confidence : 0.2)
User selects: 4 (Suggest breaking into smaller groups)
User selects: 3 (Ask for more details)
Profile after Scenario 4
• Openness: 59 (confidence: 0.9)
• Conscientiousness: 72 (confidence: 1.1)
• Extraversion: 34 (confidence: 0.9)
• Agreeableness: 70 (confidence: 0.8)
• Neuroticism: 39 (confidence: 0.9)
Scenario 5: The Creative Challenge
System: You’ve been invited to participate in a creative challenge where participants must
develop an innovative solution to a local environmental issue. What approach do you take?
Options: 5. Research extensively first, then develop a practical, proven solution 6. Brainstorm wildly creative ideas, even if they seem impractical at first 7. Seek out collaborators with different perspectives to develop ideas together 8. Focus on small, incremental improvements to existing approaches
User selects: 1 (Research extensively)
User selects: 2 (Listen to both sides and facilitate a conversation)
User selects: 3 (Find a quiet corner and wait for the host to introduce you)
User selects: 2 (Speak privately with the colleague about the situation)
User selects: 4 (Create a detailed pros/cons list and analyze all factors methodically)
User selects: 3 (Take a supportive role, helping organize resources and comfort others)
2 3. Learning a specific new skill following an established method
User selects: 1 (A structured project with clear goals and measurable outcomes)

User selects: 2 (Feel nervous but prepare extensively to manage anxiety)
environments, ethical dilemmas, and creative challenges 4. Trait interrelationships: The system identifies how patterns across scenarios reveal characteristic trait combinations 5. Adaptivity: The system selects scenarios to target traits with lower confidence values 6. Format variety: Scenarios present different types of choices to elicit a comprehensive range
A.33
Neuroticism
achievement orientation
neuroticism
Trait updates :
openness : 60 ( confidence : 0.2)
consc ientiousness : 70 ( confidence : 0.4)
extraversion : 35 ( confidence : 0.3)
agreeableness : 50 ( confidence : 0.1)
neuroticism : 35 ( confidence : 0.3)
one of them
deciding
User selects: 2 (Compromise)
LLM Analysis:
Trait updates :
openness : 55 ( confidence : 0.1)
consc ientiousness : 60 ( confidence : 0.2)
extraversion : 50 ( confidence : 0.1)
agreeableness : 75 ( confidence : 0.4)
neuroticism : 45 ( confidence : 0.2)
User selects: 4 (Suggest breaking into smaller groups)
User selects: 3 (Ask for more details)
Profile after Scenario 4
• Openness: 59 (confidence: 0.9)
• Conscientiousness: 72 (confidence: 1.1)
• Extraversion: 34 (confidence: 0.9)
• Agreeableness: 70 (confidence: 0.8)
• Neuroticism: 39 (confidence: 0.9)
Scenario 5: The Creative Challenge
System: You’ve been invited to participate in a creative challenge where participants must
develop an innovative solution to a local environmental issue. What approach do you take?
Options: 5. Research extensively first, then develop a practical, proven solution 6. Brainstorm wildly creative ideas, even if they seem impractical at first 7. Seek out collaborators with different perspectives to develop ideas together 8. Focus on small, incremental improvements to existing approaches
User selects: 1 (Research extensively)
User selects: 2 (Listen to both sides and facilitate a conversation)
User selects: 3 (Find a quiet corner and wait for the host to introduce you)
User selects: 2 (Speak privately with the colleague about the situation)
User selects: 4 (Create a detailed pros/cons list and analyze all factors methodically)
User selects: 3 (Take a supportive role, helping organize resources and comfort others)
User selects: 1 (A structured project with clear goals and measurable outcomes)
User selects: 2 (Feel nervous but prepare extensively to manage anxiety)

   User selects: 1 (Mountains)
   LLM Analysis (internal, using llama3:latest or GPT-4o):
   Choice analysis :

  adventure )
  terrain )
  the town )
  Trait updates :
  openness : 65 ( confidence : 0.3)
  consc ientiousness : 60 ( confidence : 0.3)
  extraversion : 45 ( confidence : 0.2)
  agreeableness : 50 ( confidence : 0.1)
  neuroticism : 40 ( confidence : 0.2)

  achievement orientation
  neuroticism
  Trait updates :
  openness : 60 ( confidence : 0.2)
  consc ientiousness : 70 ( confidence : 0.4)
  extraversion : 35 ( confidence : 0.3)
  agreeableness : 50 ( confidence : 0.1)
  neuroticism : 35 ( confidence : 0.3)
Intermediate Profile (after Scenario 1)

   one of them
   deciding
   User selects: 2 (Compromise)
   LLM Analysis:
   Trait updates :
   openness : 55 ( confidence : 0.1)
   consc ientiousness : 60 ( confidence : 0.2)
   extraversion : 50 ( confidence : 0.1)
   agreeableness : 75 ( confidence : 0.4)
   neuroticism : 45 ( confidence : 0.2)

   User selects: 4 (Suggest breaking into smaller groups)

Profile after Scenario 3

   User selects: 3 (Ask for more details)
   Profile after Scenario 4
   • Openness: 59 (confidence: 0.9)
   • Conscientiousness: 72 (confidence: 1.1)
   • Extraversion: 34 (confidence: 0.9)
   • Agreeableness: 70 (confidence: 0.8)
   • Neuroticism: 39 (confidence: 0.9)
   Scenario 5: The Creative Challenge
   System: You’ve been invited to participate in a creative challenge where participants must
   develop an innovative solution to a local environmental issue. What approach do you take?
   Options:
5. Research extensively first, then develop a practical, proven solution
6. Brainstorm wildly creative ideas, even if they seem impractical at first
7. Seek out collaborators with different perspectives to develop ideas together
8. Focus on small, incremental improvements to existing approaches
   User selects: 1 (Research extensively)
Scenario 6: The Conflict Resolution

   User selects: 2 (Listen to both sides and facilitate a conversation)

   User selects: 3 (Find a quiet corner and wait for the host to introduce you)
Scenario 8: The Ethical Dilemma

   User selects: 2 (Speak privately with the colleague about the situation)

   User selects: 4 (Create a detailed pros/cons list and analyze all factors methodically)

Scenario 10: The Unexpected Crisis

   User selects: 3 (Take a supportive role, helping organize resources and comfort others)

   2
3. Learning a specific new skill following an established method
   User selects: 1 (A structured project with clear goals and measurable outcomes)
Scenario 12: The Public Speaking Opportunity

   User selects: 2 (Feel nervous but prepare extensively to manage anxiety)
across scenarios
by the end
50
across scenarios
by the end
50 3. Domain coverage: Scenarios span diverse life domains including social situations, work
8. Focus on small, incremental improvements to existing approaches
   User selects: 1 (Research extensively)

Scenario 6: The Conflict Resolution

   User selects: 2 (Listen to both sides and facilitate a conversation)


   User selects: 3 (Find a quiet corner and wait for the host to introduce you)

Scenario 8: The Ethical Dilemma

   User selects: 2 (Speak privately with the colleague about the situation)

   User selects: 4 (Create a detailed pros/cons list and analyze all factors methodically)

Scenario 10: The Unexpected Crisis

   User selects: 3 (Take a supportive role, helping organize resources and comfort others)

   User selects: 1 (A structured project with clear goals and measurable outcomes)

Scenario 12: The Public Speaking Opportunity

   User selects: 2 (Feel nervous but prepare extensively to manage anxiety)
System: You find yourself at a crossroads at the edge of a vast, unexplored land. In the
distance, you can see mountains to the north, a forest to the east, a bustling town to the south,
and a quiet beach to the west. Where do you choose to go first?
Options:
1. Head north toward the mountains
2. Go east into the forest
3. Travel south to the town
4. Walk west to the beach
User selects: 1 (Mountains)
LLM Analysis (internal, using llama3:latest or GPT-4o):
Choice analysis :
- Selecting mountains suggests comfort with challenge and self reliance
- Indicates moderate to high openness to experience ( seeking
adventure )
- Suggests conscient iousness ( willing to tackle difficult
terrain )
- May indicate lower extraversion ( preference for solitude over
the town )
- Neutral on agreeableness
- Indicates low neuroticism ( comfortable with uncertainty )
Trait updates :
openness : 65 ( confidence : 0.3)
consc ientiousness : 60 ( confidence : 0.3)
extraversion : 45 ( confidence : 0.2)
agreeableness : 50 ( confidence : 0.1)
neuroticism : 40 ( confidence : 0.2)

System: As you begin your journey toward the mountains, you notice the path looks challenging. What are you most looking forward to about this mountain trek?
User responds: I’m excited about the view from the top and the sense of accomplishment.
I like pushing myself physically and seeing what I’m capable of. Also, I’m hoping to find
some quiet time to think and reflect away from everyday distractions.
LLM Analysis (internal, using deepseek-r1:latest or GPT-4o):
Text analysis :
- " Sense of accomplishment " and " pushing myself " indicates
achievement orientation
- " Quiet time to think " suggests introversion and reflectiveness
- Focus on physical challenge indicates conscientiousness
- No mention of social aspects reinforces lower extraversion
- Seeking accomplishment suggests growth mindset and low
neuroticism
Trait updates :
openness : 60 ( confidence : 0.2)
consc ientiousness : 70 ( confidence : 0.4)
extraversion : 35 ( confidence : 0.3)
agreeableness : 50 ( confidence : 0.1)
neuroticism : 35 ( confidence : 0.3)

43

Intermediate Profile (after Scenario 1)
• Openness: 63 (confidence: 0.5)
• Conscientiousness: 66 (confidence: 0.7)
• Extraversion: 39 (confidence: 0.5)
• Agreeableness: 50 (confidence: 0.2)
• Neuroticism: 37 (confidence: 0.5)
Scenario 2: The Dispute
System: As you continue your journey, you encounter two hikers in a heated argument over a
map. One claims they should follow the left path to reach the summit faster, while the other
insists the right path is safer. They notice you and ask for your opinion. How do you respond?
Options:
1. Carefully examine the map and give your honest opinion, even if it might disappoint
one of them
2. Suggest they compromise by checking out both paths for a short distance before
deciding
3. Support whoever seems more knowledgeable or confident
4. Offer to join them so you can all explore together and ensure everyone’s safety
User selects: 2 (Compromise)
LLM Analysis:
Trait updates :
openness : 55 ( confidence : 0.1)
consc ientiousness : 60 ( confidence : 0.2)
extraversion : 50 ( confidence : 0.1)
agreeableness : 75 ( confidence : 0.4)
neuroticism : 45 ( confidence : 0.2)

Profile after Scenario 2
• Openness: 62 (confidence: 0.6)
• Conscientiousness: 65 (confidence: 0.9)
• Extraversion: 40 (confidence: 0.5)
• Agreeableness: 78 (confidence: 0.6)
• Neuroticism: 37 (confidence: 0.7)
Scenario 3: The Team Project
System: You’ve joined a group working on an important project with a tight deadline. During
the first meeting, you notice that ideas are being suggested, but the discussion lacks structure.
What do you do?
Options:
1. Take charge and propose a clear plan for the group to follow
2. Let others lead and offer support where needed
3. Privately suggest improvements to whoever seems to be leading
4. Suggest breaking into smaller groups to tackle different aspects simultaneously
User selects: 4 (Suggest breaking into smaller groups)

44

Profile after Scenario 3
• Openness: 62 (confidence: 0.7)
• Conscientiousness: 67 (confidence: 1.0)
• Extraversion: 33 (confidence: 0.8)
• Agreeableness: 72 (confidence: 0.7)
• Neuroticism: 40 (confidence: 0.8)
Scenario 4: The Unexpected Opportunity
System: You receive an unexpected invitation to join a last-minute expedition to a remote
location. The trip leaves tomorrow and would require rearranging your schedule for the next
week. How do you respond?
Options:
1. Immediately accept - you love spontaneous adventures
2. Firmly decline - you prefer to stick to your plans
3. Ask for more details before deciding
4. Suggest postponing the trip to a more convenient time
User selects: 3 (Ask for more details)
Profile after Scenario 4
• Openness: 59 (confidence: 0.9)
• Conscientiousness: 72 (confidence: 1.1)
• Extraversion: 34 (confidence: 0.9)
• Agreeableness: 70 (confidence: 0.8)
• Neuroticism: 39 (confidence: 0.9)
Scenario 5: The Creative Challenge
System: You’ve been invited to participate in a creative challenge where participants must
develop an innovative solution to a local environmental issue. What approach do you take?
Options:
1. Research extensively first, then develop a practical, proven solution
2. Brainstorm wildly creative ideas, even if they seem impractical at first
3. Seek out collaborators with different perspectives to develop ideas together
4. Focus on small, incremental improvements to existing approaches
User selects: 1 (Research extensively)

Profile after Scenario 5
• Openness: 55 (confidence: 1.1)
• Conscientiousness: 78 (confidence: 1.3)
• Extraversion: 35 (confidence: 0.9)
• Agreeableness: 68 (confidence: 0.8)
• Neuroticism: 38 (confidence: 1.0)

45

Scenario 6: The Conflict Resolution
System: Two friends have had a serious disagreement and haven’t spoken in weeks. Both
have separately asked for your advice on repairing the relationship. What do you do?
Options:
1. Give each person advice separately based on their perspective
2. Listen to both sides and facilitate a conversation between them
3. Suggest they give each other space until emotions cool down
4. Tell them both to compromise and move on
User selects: 2 (Listen to both sides and facilitate a conversation)

Profile after Scenario 6
• Openness: 54 (confidence: 1.1)
• Conscientiousness: 77 (confidence: 1.3)
• Extraversion: 36 (confidence: 1.0)
• Agreeableness: 75 (confidence: 1.1)
• Neuroticism: 37 (confidence: 1.0)

Scenario 7: The Social Gathering
System: You arrive at a party where you only know the host. How do you typically approach
this situation?
Options:
1. Actively introduce yourself to new people and initiate conversations
2. Find a small group engaged in an interesting discussion and join in
3. Find a quiet corner and wait for the host to introduce you
4. Help the host with preparations or serving to feel more comfortable
User selects: 3 (Find a quiet corner and wait for the host to introduce you)

Profile after Scenario 7
• Openness: 53 (confidence: 1.1)
• Conscientiousness: 76 (confidence: 1.3)
• Extraversion: 30 (confidence: 1.3)
• Agreeableness: 74 (confidence: 1.1)
• Neuroticism: 42 (confidence: 1.2)

46

Scenario 8: The Ethical Dilemma
System: You discover that a colleague has taken credit for work you completed. The project
was successful and got positive attention from management. What do you do?
Options:
1. Confront the colleague publicly to ensure everyone knows the truth
2. Speak privately with the colleague about the situation
3. Report the issue to management or HR
4. Say nothing but ensure you get proper credit for future work
User selects: 2 (Speak privately with the colleague about the situation)

Profile after Scenario 8
• Openness: 52 (confidence: 1.1)
• Conscientiousness: 77 (confidence: 1.4)
• Extraversion: 32 (confidence: 1.3)
• Agreeableness: 70 (confidence: 1.3)
• Neuroticism: 40 (confidence: 1.2)

Scenario 9: The Life Change
System: You have the opportunity to move to a new city for a job that offers better pay but
would require leaving your established social network. How do you approach this decision?
Options:
1. Focus primarily on the career advancement opportunity
2. Prioritize your existing relationships and social connections
3. Take time to extensively research the new city and visit first
4. Create a detailed pros/cons list and analyze all factors methodically
User selects: 4 (Create a detailed pros/cons list and analyze all factors methodically)

Profile after Scenario 9
• Openness: 50 (confidence: 1.2)
• Conscientiousness: 80 (confidence: 1.5)
• Extraversion: 32 (confidence: 1.4)
• Agreeableness: 68 (confidence: 1.3)
• Neuroticism: 41 (confidence: 1.3)

47

Scenario 10: The Unexpected Crisis
System: While traveling, you encounter an unexpected emergency situation affecting several
people. Resources are limited and tensions are high. How do you respond?
Options:
1. Take charge and direct others to ensure efficiency
2. Find experts or authorities who can better handle the situation
3. Take a supportive role, helping organize resources and comfort others
4. Focus on solving one specific aspect of the problem thoroughly
User selects: 3 (Take a supportive role, helping organize resources and comfort others)

Profile after Scenario 10
• Openness: 51 (confidence: 1.3)
• Conscientiousness: 79 (confidence: 1.6)
• Extraversion: 35 (confidence: 1.5)
• Agreeableness: 72 (confidence: 1.5)
• Neuroticism: 38 (confidence: 1.4)

Scenario 11: The Creative Project
System: You have free time to pursue a personal project. What kind of activity are you most
likely to choose?
Options:
1. A structured project with clear goals and measurable outcomes
2. A creative, open-ended project with room for exploration
2
4. Learning a specific new skill following an established method
User selects: 1 (A structured project with clear goals and measurable outcomes)

Profile after Scenario 11
• Openness: 53 (confidence: 1.4)
• Conscientiousness: 82 (confidence: 1.7)
• Extraversion: 34 (confidence: 1.5)
• Agreeableness: 71 (confidence: 1.5)
• Neuroticism: 37 (confidence: 1.4)

48

Scenario 12: The Public Speaking Opportunity
System: You’ve been asked to give a presentation to a large group on a topic you’re knowledgeable about. How do you feel and prepare?
Options:
1. Feel excited and prepare a dynamic, engaging presentation
2. Feel nervous but prepare extensively to manage anxiety
3. Feel neutral and focus on delivering clear, accurate information
4. Feel reluctant but try to find ways to make the presentation more interactive
User selects: 2 (Feel nervous but prepare extensively to manage anxiety)

Profile after Scenario 12
• Openness: 52 (confidence: 1.4)
• Conscientiousness: 83 (confidence: 1.8)
• Extraversion: 32 (confidence: 1.6)
• Agreeableness: 70 (confidence: 1.5)
• Neuroticism: 42 (confidence: 1.6)

80

Trait Score

70
60
50
Openness
Conscientiousness
Extraversion
Agreeableness
Neuroticism

40
30
1

2

3

4

5

6
7
Scenario

8

9

10

11

Figure 7: Progression of personality trait scores across scenarios


   across scenarios
   by the end
   50


   across scenarios
   by the end
   50
3. Domain coverage: Scenarios span diverse life domains including social situations, work
environments, ethical dilemmas, and creative challenges 4. Trait interrelationships: The system identifies how patterns across scenarios reveal characteristic trait combinations 5. Adaptivity: The system selects scenarios to target traits with lower confidence values 6. Format variety: Scenarios present different types of choices to elicit a comprehensive range


   across scenarios
   by the end
   50

3. Domain coverage: Scenarios span diverse life domains including social situations, work
environments, ethical dilemmas, and creative challenges 4. Trait interrelationships: The system identifies how patterns across scenarios reveal characteristic trait combinations 5. Adaptivity: The system selects scenarios to target traits with lower confidence values 6. Format variety: Scenarios present different types of choices to elicit a comprehensive range

A.33

4

5

6
7
Scenario

8

9

10

11

12

Figure 8: Progression of confidence levels for each trait across scenarios
Final Personality Profile
Openness:
Balances practicality with some openness to new experiences
Conscientiousness:
Highly organized, disciplined, and detail-oriented
Extraversion:
Prefers quieter environments and one-on-one interactions
Agreeableness:
Cooperative, empathetic, values harmony
Neuroticism:
Generally emotionally stable with occasional anxiety

52 (Moderconservative) 83 (Very High) 32 (Introverted) 70 (High) 42 (Low-Moderate) -

Key Traits and Tendencies:
• Methodical approach to problem-solving (High C + Moderate O)
• Prefers researching before acting (High C)
• Values social harmony but not at the expense of principles (High A + High C)
• Reserved in social situations but empathetic (Low E + High A)
• Prefers structured environments with clear expectations (High C)
• Uncomfortable with sudden changes but adapts through planning (High C + Moderate N)
• Selective about social engagements but loyal in relationships (Low E + High A)
Figure 9: Complete adventure-based personality assessment session showing progressive trait refinement across 12 scenarios. Each scenario contributes to increasing confidence in trait measurements
and ultimately produces a stable, high-confidence personality profile.
This comprehensive example demonstrates how our adventure-based personality assessment system
builds a detailed psychological profile through multiple scenarios. The assessment process illustrates
several key aspects:
1. Progressive refinement: Trait estimates become increasingly stable as evidence accumulates
across scenarios
2. Confidence building: Confidence values steadily increase, reaching robust levels (1.4-1.8)
by the end
50

3. Domain coverage: Scenarios span diverse life domains including social situations, work
environments, ethical dilemmas, and creative challenges
4. Trait interrelationships: The system identifies how patterns across scenarios reveal characteristic trait combinations
5. Adaptivity: The system selects scenarios to target traits with lower confidence values
6. Format variety: Scenarios present different types of choices to elicit a comprehensive range
of behaviors
The final personality profile provides a nuanced psychological portrait that becomes the foundation
for initializing the participant’s GNWT-Agent digital twin. By capturing this level of psychological
detail, our system ensures that the agent’s behavior authentically represents the individual across
different social contexts.

51

A.33

Detailed Results
Table 9: Match decision accuracy using different preference models
Match Prediction
Human-Agent
Accuracy
Match Correlation
Static (Time 1 only)
Partial Evolution (Time 1+2)
Full Evolution (All time points)
Human (Ground Truth)

77.8% ± 2.0%
100%

0.53 ± 0.04
0.65 ± 0.03
0.73 ± 0.03
1.00

Table 10: Human verification experiment results across two social contexts
Metric
Speed Dating Study (n=20) Job Interview Study (n=10)
Behavioral fidelity rating
Decision concordance
Personality trait correlation
Conversational authenticity
Psychological state tracking
Overall agent realism

Evolution
Dimension

5.6/7.0 ± 0.8
74% ± 4.2%
0.83 ± 0.04
5.4/7.0 ± 0.9
5.7/7.0 ± 0.6
5.9/7.0 ± 0.5

5.8/7.0 ± 0.6
81% ± 5.3%
0.81 ± 0.05
5.6/7.0 ± 0.7
5.5/7.0 ± 0.8
5.6/7.0 ± 0.7

Table 11: Human-Agent correlation in social dynamics evolution
Human (T1→T2)
GNWT-Agent (T1→T2)
Change (%)
Correlation
Change (%)
Pattern Match

Partner Preference Evolution
Attractiveness
+39.0% ± 4.8%
Sincerity
-16.6% ± 3.4%
Intelligence
-24.8% ± 3.3%
Fun
+1.3% ± 2.0%
Ambition
-7.0% ± 2.7%
Shared Interests +9.8% ± 3.3%

0.73 ± 0.04


-10.5% ± 2.8%
-15.2% ± 2.7%
+5.8% ± 2.2%
-4.5% ± 1.9%


0.86 ± 0.03

0.81 ± 0.03

-0.5% ± 3.0%
-2.5% ± 2.7%
-1.2% ± 2.4%

-0.5% ± 2.1%
0.9→0.7

0.82 ± 0.04

External Evaluation Correlations (r-value)
Time 1
Time 2
Attractiveness
0.67 ± 0.01
-0.01 ± 0.02
Sincerity
0.52 ± 0.01
-0.02 ± 0.02
Intelligence
0.51 ± 0.01
0.02 ± 0.02
Fun
0.69 ± 0.01
0.07 ± 0.02
Ambition
0.44 ± 0.01
-0.01 ± 0.02
Shared Interests
0.66 ± 0.01
-0.06 ± 0.02
Overall Human-Agent Correlation: 0.72 ± 0.04

Time 1
0.65 ± 0.04
0.50 ± 0.05
0.48 ± 0.05
0.64 ± 0.05
0.40 ± 0.06
0.62 ± 0.05

Time 2
0.15 ± 0.03
0.12 ± 0.03
0.18 ± 0.04
0.20 ± 0.04
0.10 ± 0.05
0.08 ± 0.04

Self-Perception Evolution
Attractiveness
+0.3% ± 9.2%
Sincerity
-3.5% ± 12.3%
Intelligence
-1.9% ± 8.8%
Fun
-1.3% ± 10.8%
Ambition
-0.8% ± 11.8%
Self-Other Gap
0.8→0.7

52


