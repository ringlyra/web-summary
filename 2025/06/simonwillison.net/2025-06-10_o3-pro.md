<!-- metadata -->

- **title**: o3-pro
- **source**: https://simonwillison.net/2025/Jun/10/o3-pro/
- **author**: Simon Willison
- **published**: 2025-06-10T20:46:00+00:00
- **fetched**: 2025-06-11T09:27:41.510139+00:00
- **tags**: codex, openai, llm
- **image**: https://static.simonwillison.net/static/2025/o3-pro-pelican.jpg

## 要約

OpenAIが新モデル**o3-pro**を公開し、従来のo3を大規模計算で強化したバージョンとして紹介している。利用は**Responses API**に限定され、作例では`llm-openai-plugin`で画像生成を試したが124秒を要した。価格は入力100万トークン20ドル、出力100万トークン80ドルで、値下げ後のo3の10倍に相当する。**Ben Hylak**の初期レビューでは膨大なコンテキストを与えることで知能の高さを実感でき、具体的な計画や指示が得られると報告された。ツールと組み合わせることで真価を発揮すると考えられるが、現状では背景処理モードの活用が推奨されている。

## 本文

**[o3-pro](https://platform.openai.com/docs/models/o3-pro)**. OpenAI released o3-pro today, which they describe as a "version of o3 with more compute for better responses".

It's only available via the newer Responses API. I've added it to my [llm-openai-plugin](https://github.com/simonw/llm-openai-plugin) plugin which uses that new API, so you can try it out like this:

```
llm install -U llm-openai-plugin
llm -m openai/o3-pro "Generate an SVG of a pelican riding a bicycle"

```

![Description by o3-pro: The image is a playful, minimalist cartoon showing a white bird riding a bicycle. The bird has a simple oval body, a round head with a small black eye, and a yellow beak. Its orange feet are positioned on the bicycle’s pedals. The bicycle itself is drawn with thin black lines forming two large circular wheels and a straightforward frame. The scene has a light blue background with a soft gray oval shadow beneath the bicycle, giving the impression of ground. Overall, the illustration has a light, whimsical feel.](https://static.simonwillison.net/static/2025/o3-pro-pelican.jpg)

It's _slow_ - [generating this pelican](https://gist.github.com/simonw/6bc7dda9dbe07281d902d254e5fb6e33) took 124 seconds! OpenAI suggest using their [background mode](https://platform.openai.com/docs/guides/background) for o3 prompts, which I haven't tried myself yet.

o3-pro is priced at $20/million input tokens and $80/million output tokens - 10x the price of regular o3 after its [80% price drop](https://simonwillison.net/2025/Jun/10/o3-price-drop/) this morning.

Ben Hylak had early access and published his notes so far in [God is hungry for Context: First thoughts on o3 pro](https://www.latent.space/p/o3-pro). It sounds like this model needs to be applied very thoughtfully. It comparison to o3:

> It's smarter. _much smarter._
>
> **But in order to see that, you need to give it** **_a lot_** **more context. and I'm running out of context.** [...]
>
> My co-founder Alexis and I took the the time to assemble a history of all of our past planning meetings at Raindrop, all of our goals, even record voice memos: and then asked o3-pro to come up with a plan.
>
> We were blown away; it spit out the exact kind of concrete plan and analysis I've always wanted an LLM to create --- complete with target metrics, timelines, what to prioritize, and strict instructions on what to absolutely cut.
>
> The plan o3 gave us was plausible, reasonable; but the plan o3 Pro gave us was specific and rooted enough that **_it actually changed how we are thinking about our future._**
>
> This is hard to capture in an eval.

It sounds to me like o3-pro works best when combined with tools. I don't have tool support in `llm-openai-plugin` yet, [here's the relevant issue](https://github.com/simonw/llm-openai-plugin/issues/20).
