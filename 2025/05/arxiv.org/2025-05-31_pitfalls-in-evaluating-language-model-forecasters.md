<!-- metadata -->

- **title**: Pitfalls in Evaluating Language Model Forecasters
- **source**: https://arxiv.org/abs/2506.00723
- **author**: Paleka, Daniel, Goel, Shashwat, Geiping, Jonas, Tramèr, Florian
- **published**: 2025-05-31T00:00:00Z
- **fetched**: 2025-06-04T03:53:08Z
- **tags**: codex, ai, forecasting
- **image**: /static/browse/0.3.4/images/arxiv-logo-fb.png

## 要約

LLMの予測評価には**時系列リーク**や**実運用への外挿難**などの課題が存在。研究ではこうした問題点を整理し、より厳密な評価手法の確立を促している。

## 本文 / Article

[Submitted on 31 May 2025]

# Title:Pitfalls in Evaluating Language Model Forecasters

Authors:[Daniel Paleka](https://arxiv.org/search/cs?searchtype=author&query=Paleka,+D), [Shashwat Goel](https://arxiv.org/search/cs?searchtype=author&query=Goel,+S), [Jonas Geiping](https://arxiv.org/search/cs?searchtype=author&query=Geiping,+J), [Florian Tramèr](https://arxiv.org/search/cs?searchtype=author&query=Tram%C3%A8r,+F)

View a PDF of the paper titled Pitfalls in Evaluating Language Model Forecasters, by Daniel Paleka and Shashwat Goel and Jonas Geiping and Florian Tram\`er

[View PDF](/pdf/2506.00723)
[HTML (experimental)](https://arxiv.org/html/2506.00723v1)

> Abstract:Large language models (LLMs) have recently been applied to forecasting tasks, with some works claiming these systems match or exceed human performance. In this paper, we argue that, as a community, we should be careful about such conclusions as evaluating LLM forecasters presents unique challenges. We identify two broad categories of issues: (1) difficulty in trusting evaluation results due to many forms of temporal leakage, and (2) difficulty in extrapolating from evaluation performance to real-world forecasting. Through systematic analysis and concrete examples from prior work, we demonstrate how evaluation flaws can raise concerns about current and future performance claims. We argue that more rigorous evaluation methodologies are needed to confidently assess the forecasting abilities of LLMs.

|           |                                                                                               |
| --------- | --------------------------------------------------------------------------------------------- |
| Comments: | 20 pages, 8 figures                                                                           |
| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)      |
| Cite as:  | [arXiv:2506.00723](https://arxiv.org/abs/2506.00723) [cs.LG]                                  |
|           | (or [arXiv:2506.00723v1](https://arxiv.org/abs/2506.00723v1) [cs.LG] for this version)        |
|           | <https://doi.org/10.48550/arXiv.2506.00723> Focus to learn more arXiv-issued DOI via DataCite |
